<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>changsk&#39;s blogs</title>
  
  <subtitle>chang.sk@foxmail.com</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://changsk.top/"/>
  <updated>2019-06-29T11:15:14.612Z</updated>
  <id>http://changsk.top/</id>
  
  <author>
    <name>changsk</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>java之线程池</title>
    <link href="http://changsk.top/2019/06/29/java-ThreadPool/"/>
    <id>http://changsk.top/2019/06/29/java-ThreadPool/</id>
    <published>2019-06-29T08:13:59.000Z</published>
    <updated>2019-06-29T11:15:14.612Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转载自：<a href="https://www.cnblogs.com/dolphin0520/p/3932921.html" target="_blank" rel="noopener">Java并发编程：线程池的使用</a></p></blockquote><p>在前面的文章中，我们使用线程的时候就去创建一个线程，这样实现起来非常简便，但是就会有一个问题：</p><blockquote><p>如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。</p></blockquote><p>那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？</p><p>在Java中可以通过<strong>线程池</strong>来达到这样的效果。今天我们就来详细讲解一下Java的线程池，首先我们从最核心的<code>ThreadPoolExecutor</code>类中的方法讲起，然后再讲述它的实现原理，接着给出了它的使用示例，最后讨论了一下如何合理配置线程池的大小。</p><p>　<a id="more"></a></p><h2 id="Java中的ThreadPoolExecutor类"><a href="#Java中的ThreadPoolExecutor类" class="headerlink" title="Java中的ThreadPoolExecutor类"></a>Java中的ThreadPoolExecutor类</h2><p><code>java.uitl.concurrent.ThreadPoolExecutor</code>类是线程池中最核心的一个类，因此如果要透彻地了解Java中的线程池，必须先了解这个类。下面我们来看一下<code>ThreadPoolExecutor</code>类的具体实现源码。</p><p>在ThreadPoolExecutor类中提供了四个构造方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolExecutor</span> <span class="keyword">extends</span> <span class="title">AbstractExecutorService</span> </span>&#123;</span><br><span class="line">    .....</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,<span class="keyword">int</span> maximumPoolSize,<span class="keyword">long</span> keepAliveTime,TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">            BlockingQueue&lt;Runnable&gt; workQueue)</span></span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,<span class="keyword">int</span> maximumPoolSize,<span class="keyword">long</span> keepAliveTime,TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">            BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory)</span></span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,<span class="keyword">int</span> maximumPoolSize,<span class="keyword">long</span> keepAliveTime,TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">            BlockingQueue&lt;Runnable&gt; workQueue,RejectedExecutionHandler handler)</span></span>;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutor</span><span class="params">(<span class="keyword">int</span> corePoolSize,<span class="keyword">int</span> maximumPoolSize,<span class="keyword">long</span> keepAliveTime,TimeUnit unit,</span></span></span><br><span class="line"><span class="function"><span class="params">        BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler)</span></span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　从上面的代码可以得知，<code>ThreadPoolExecutor</code>继承了<code>AbstractExecutorService</code>类，并提供了四个构造器，事实上，通过观察每个构造器的源码具体实现，发现前面三个构造器都是调用的第四个构造器进行的初始化工作。</p><p> 　　下面解释下一下构造器中各个参数的含义：</p><ul><li>corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，<strong>默认情况下，线程池中并没有任何线程</strong>，而是等待有任务到来才创建线程去执行任务，除非调用了<code>prestartAllCoreThreads()</code>或者<code>prestartCoreThread()</code>方法，从这2个方法的名字就可以看出，是预创建线程的意思，<strong>即在没有任务到来之前就创建corePoolSize个线程或者一个线程</strong>。<strong>默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中；</strong></li><li>maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程；</li><li>keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，<strong>只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用</strong>，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了<code>allowCoreThreadTimeOut(boolean)</code>方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0；</li><li>unit：参数keepAliveTime的时间单位，有7种取值，在<code>TimeUnit</code>类中有7种静态属性：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">TimeUnit.DAYS;               <span class="comment">//天</span></span><br><span class="line">TimeUnit.HOURS;             <span class="comment">//小时</span></span><br><span class="line">TimeUnit.MINUTES;           <span class="comment">//分钟</span></span><br><span class="line">TimeUnit.SECONDS;           <span class="comment">//秒</span></span><br><span class="line">TimeUnit.MILLISECONDS;      <span class="comment">//毫秒</span></span><br><span class="line">TimeUnit.MICROSECONDS;      <span class="comment">//微妙</span></span><br><span class="line">TimeUnit.NANOSECONDS;       <span class="comment">//纳秒</span></span><br></pre></td></tr></table></figure><ul><li>workQueue：一个阻塞队列，用来存储等待执行的任务，这个参数的选择也很重要，会对线程池的运行过程产生重大影响，一般来说，这里的阻塞队列有以下几种选择：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ArrayBlockingQueue;</span><br><span class="line">LinkedBlockingQueue;</span><br><span class="line">SynchronousQueue;</span><br></pre></td></tr></table></figure><p><code>ArrayBlockingQueue</code>和<code>PriorityBlockingQueue</code>使用较少，一般使用<code>LinkedBlockingQueue</code>和<code>Synchronous</code>。线程池的排队策略与<code>BlockingQueue</code>有关。</p><ul><li>threadFactory：线程工厂，主要用来创建线程；</li><li>handler：表示当拒绝处理任务时的策略，有以下四种取值：</li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">ThreadPoolExecutor</span><span class="selector-class">.AbortPolicy</span>:丢弃任务并抛出<span class="selector-tag">RejectedExecutionException</span>异常。 </span><br><span class="line"><span class="selector-tag">ThreadPoolExecutor</span><span class="selector-class">.DiscardPolicy</span>：也是丢弃任务，但是不抛出异常。 </span><br><span class="line"><span class="selector-tag">ThreadPoolExecutor</span><span class="selector-class">.DiscardOldestPolicy</span>：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）</span><br><span class="line"><span class="selector-tag">ThreadPoolExecutor</span><span class="selector-class">.CallerRunsPolicy</span>：由调用线程处理该任务</span><br></pre></td></tr></table></figure><p> 具体参数的配置与线程池的关系将在下一节讲述。</p><p>从上面给出的<code>hreadPoolExecutor</code>类的代码可以知道，ThreadPoolExecutor继承了<code>AbstractExecutorService</code>，我们来看一下AbstractExecutorService的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">AbstractExecutorService</span> <span class="keyword">implements</span> <span class="title">ExecutorService</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">     </span><br><span class="line">    <span class="keyword">protected</span> &lt;T&gt; <span class="function">RunnableFuture&lt;T&gt; <span class="title">newTaskFor</span><span class="params">(Runnable runnable, T value)</span> </span>&#123; &#125;;</span><br><span class="line">    <span class="keyword">protected</span> &lt;T&gt; <span class="function">RunnableFuture&lt;T&gt; <span class="title">newTaskFor</span><span class="params">(Callable&lt;T&gt; callable)</span> </span>&#123; &#125;;</span><br><span class="line">    <span class="keyword">public</span> Future&lt;?&gt; submit(Runnable task) &#123;&#125;;</span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">Future&lt;T&gt; <span class="title">submit</span><span class="params">(Runnable task, T result)</span> </span>&#123; &#125;;</span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">Future&lt;T&gt; <span class="title">submit</span><span class="params">(Callable&lt;T&gt; task)</span> </span>&#123; &#125;;</span><br><span class="line">    <span class="keyword">private</span> &lt;T&gt; <span class="function">T <span class="title">doInvokeAny</span><span class="params">(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,</span></span></span><br><span class="line"><span class="function"><span class="params">                            <span class="keyword">boolean</span> timed, <span class="keyword">long</span> nanos)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException, ExecutionException, TimeoutException </span>&#123;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">invokeAny</span><span class="params">(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException, ExecutionException </span>&#123;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; <span class="function">T <span class="title">invokeAny</span><span class="params">(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">long</span> timeout, TimeUnit unit)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException, ExecutionException, TimeoutException </span>&#123;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)</span><br><span class="line">        <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="keyword">public</span> &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,</span><br><span class="line">                                         <span class="keyword">long</span> timeout, TimeUnit unit)</span><br><span class="line">        <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">    &#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　AbstractExecutorService是一个抽象类，它实现了<code>ExecutorService</code>接口。</p><p>我们接着看ExecutorService接口的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ExecutorService</span> <span class="keyword">extends</span> <span class="title">Executor</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isShutdown</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isTerminated</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">awaitTermination</span><span class="params">(<span class="keyword">long</span> timeout, TimeUnit unit)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException</span>;</span><br><span class="line">    &lt;T&gt; <span class="function">Future&lt;T&gt; <span class="title">submit</span><span class="params">(Callable&lt;T&gt; task)</span></span>;</span><br><span class="line">    &lt;T&gt; <span class="function">Future&lt;T&gt; <span class="title">submit</span><span class="params">(Runnable task, T result)</span></span>;</span><br><span class="line">    Future&lt;?&gt; submit(Runnable task);</span><br><span class="line">    &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)</span><br><span class="line">        <span class="keyword">throws</span> InterruptedException;</span><br><span class="line">    &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,</span><br><span class="line">                                  <span class="keyword">long</span> timeout, TimeUnit unit)</span><br><span class="line">        <span class="keyword">throws</span> InterruptedException;</span><br><span class="line"> </span><br><span class="line">    &lt;T&gt; <span class="function">T <span class="title">invokeAny</span><span class="params">(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException, ExecutionException</span>;</span><br><span class="line">    &lt;T&gt; <span class="function">T <span class="title">invokeAny</span><span class="params">(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks,</span></span></span><br><span class="line"><span class="function"><span class="params">                    <span class="keyword">long</span> timeout, TimeUnit unit)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> InterruptedException, ExecutionException, TimeoutException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 而ExecutorService又是继承了<code>Executor</code>接口，我们看一下Executor接口的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Executor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">execute</span><span class="params">(Runnable command)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　到这里，大家应该明白了ThreadPoolExecutor、AbstractExecutorService、ExecutorService和Executor几个之间的关系了。</p><p>　　<code>Executor是一个顶层接口</code>，在它里面只声明了一个方法<strong>execute(Runnable)</strong>，返回值为void，参数为Runnable类型，从字面意思可以理解，就是用来执行传进去的任务的；</p><p>　　然后<code>ExecutorService</code>接口继承了Executor接口，并声明了一些方法：<strong>submit、invokeAll、invokeAny以及shutDown等；</strong></p><p>　　抽象类<code>AbstractExecutorService</code>实现了ExecutorService接口，基本实现了ExecutorService中声明的所有方法；</p><p>　　然后ThreadPoolExecutor继承了类AbstractExecutorService。</p><p>　　在ThreadPoolExecutor类中有几个非常重要的方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">execute()</span><br><span class="line">submit()</span><br><span class="line">shutdown()</span><br><span class="line">shutdownNow()</span><br></pre></td></tr></table></figure><p> 　　<strong>execute()方法实际上是Executor中声明的方法</strong>，在ThreadPoolExecutor进行了具体的实现，这个方法是ThreadPoolExecutor的核心方法，<strong>通过这个方法可以向线程池提交一个任务，交由线程池去执行。</strong></p><p>　　submit()方法是在ExecutorService中声明的方法，在AbstractExecutorService就已经有了具体的实现，在ThreadPoolExecutor中并没有对其进行重写，<strong>这个方法也是用来向线程池提交任务的，但是它和execute()方法不同，它能够返回任务执行的结果，去看submit()方法的实现，会发现它实际上还是调用的execute()方法，只不过它利用了Future来获取任务执行结果</strong>（Future相关内容将在下一篇讲述）。</p><p>　　<code>shutdown()</code>和<code>shutdownNow()</code>是用来关闭线程池的。</p><p>　　还有很多其他的方法：</p><p>　　比如：getQueue() 、getPoolSize() 、getActiveCount()、getCompletedTaskCount()等获取与线程池相关属性的方法，有兴趣的朋友可以自行查阅API。</p><h2 id="深入剖析线程池实现原理"><a href="#深入剖析线程池实现原理" class="headerlink" title="深入剖析线程池实现原理"></a>深入剖析线程池实现原理</h2><p>　　在上一节我们从宏观上介绍了ThreadPoolExecutor，下面我们来深入解析一下线程池的具体实现原理，将从下面几个方面讲解：</p><p>　　<strong>1.线程池状态</strong></p><p>　　<strong>2.任务的执行</strong></p><p>　　<strong>3.线程池中的线程初始化</strong></p><p>　　<strong>4.任务缓存队列及排队策略</strong></p><p>　　<strong>5.任务拒绝策略</strong></p><p>　　<strong>6.线程池的关闭</strong></p><p>　　<strong>7.线程池容量的动态调整</strong></p><h3 id="线程池状态"><a href="#线程池状态" class="headerlink" title="线程池状态"></a>线程池状态</h3><p>　　在ThreadPoolExecutor中定义了一个<code>volatile</code>变量，另外定义了几个static final变量表示线程池的各个状态：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">volatile</span> <span class="keyword">int</span> runState;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> RUNNING    = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> SHUTDOWN   = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> STOP       = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TERMINATED = <span class="number">3</span>;</span><br></pre></td></tr></table></figure><p> 　　runState表示当前线程池的状态，它是一个<strong>volatile变量用来保证线程之间的可见性；</strong></p><p>　　下面的几个static final变量表示runState可能的几个取值。</p><ol><li><p>当创建线程池后，初始时，线程池处于RUNNING状态；</p></li><li><p>如果调用了shutdown()方法，则线程池处于SHUTDOWN状态，<strong>此时线程池不能够接受新的任务，它会等待所有任务执行完毕；</strong></p></li><li><p>如果调用了shutdownNow()方法，则线程池处于STOP状态，<strong>此时线程池不能接受新的任务，并且会去尝试终止正在执行的任务；</strong></p></li><li><p>当线程池处于SHUTDOWN或STOP状态，并且所有工作线程已经销毁，任务缓存队列已经清空或执行结束后，线程池被设置为TERMINATED状态。</p></li></ol><h3 id="任务的执行"><a href="#任务的执行" class="headerlink" title="任务的执行"></a>任务的执行</h3><p>　　在了解将任务提交给线程池到任务执行完毕整个过程之前，我们先来看一下ThreadPoolExecutor类中其他的一些比较重要成员变量：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> BlockingQueue&lt;Runnable&gt; workQueue;              <span class="comment">//任务缓存队列，用来存放等待执行的任务</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">new</span> ReentrantLock();   <span class="comment">//线程池的主要状态锁，对线程池状态（比如线程池大小</span></span><br><span class="line">                                                              <span class="comment">//、runState等）的改变都要使用这个锁</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> HashSet&lt;Worker&gt; workers = <span class="keyword">new</span> HashSet&lt;Worker&gt;();  <span class="comment">//用来存放工作集</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">long</span>  keepAliveTime;    <span class="comment">//线程存货时间   </span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> allowCoreThreadTimeOut;   <span class="comment">//是否允许为核心线程设置存活时间</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span>   corePoolSize;     <span class="comment">//核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span>   maximumPoolSize;   <span class="comment">//线程池最大能容忍的线程数</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">int</span>   poolSize;       <span class="comment">//线程池中当前的线程数</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> RejectedExecutionHandler handler; <span class="comment">//任务拒绝策略</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> ThreadFactory threadFactory;   <span class="comment">//线程工厂，用来创建线程</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> largestPoolSize;   <span class="comment">//用来记录线程池中曾经出现过的最大线程数</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> completedTaskCount;   <span class="comment">//用来记录已经执行完毕的任务个数</span></span><br></pre></td></tr></table></figure><p> 　　每个变量的作用都已经标明出来了，这里要重点解释一下corePoolSize、maximumPoolSize、largestPoolSize三个变量。</p><p>​        corePoolSize在很多地方被翻译成核心池大小，其实我的理解这个就是线程池的大小。举个简单的例子：</p><p>　　假如有一个工厂，工厂里面有10个工人，每个工人同时只能做一件任务。</p><p>　　因此只要当10个工人中有工人是空闲的，来了任务就分配给空闲的工人做；</p><p>　　当10个工人都有任务在做时，如果还来了任务，<strong>就把任务进行排队等待；</strong></p><p>　　如果说新任务数目增长的速度远远大于工人做任务的速度，那么此时工厂主管可能会想补救措施，比如重新招   4个临时工人进来；</p><p>　　然后就将任务也分配给这4个临时工人做；</p><p>　　如果说着14个工人做任务的速度还是不够，此时工厂主管可能就要考虑不再接收新的任务或者抛弃前面的一些任务了。</p><p>　　当这14个工人当中有人空闲时，而新任务增长的速度又比较缓慢，工厂主管可能就考虑辞掉4个临时工了，只保持原来的10个工人，毕竟请额外的工人是要花钱的。</p><p> 这个例子中的corePoolSize就是10，而maximumPoolSize就是14（10+4）。</p><p>　　也就是说corePoolSize就是线程池大小，maximumPoolSize在我看来是线程池的一种补救措施，即任务量突然过大时的一种补救措施。</p><p>　　不过为了方便理解，在本文后面还是将corePoolSize翻译成核心池大小。</p><p>​        largestPoolSize只是一个用来起记录作用的变量，用来记录线程池中曾经有过的最大线程数目，跟线程池的容量没有任何关系。</p><p>　　下面我们进入正题，看一下任务从提交到最终执行完毕经历了哪些过程。</p><p>　　在ThreadPoolExecutor类中，<strong>最核心的任务提交方法是execute()方法</strong>，虽然通过submit也可以提交任务，但是实际上<strong>submit方法里面最终调用的还是execute()方法</strong>，所以我们只需要研究execute()方法的实现原理即可：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Runnable command)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (command == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="keyword">if</span> (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command)) &#123;</span><br><span class="line">        <span class="keyword">if</span> (runState == RUNNING &amp;&amp; workQueue.offer(command)) &#123;</span><br><span class="line">            <span class="keyword">if</span> (runState != RUNNING || poolSize == <span class="number">0</span>)</span><br><span class="line">                ensureQueuedTaskHandled(command);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (!addIfUnderMaximumPoolSize(command))</span><br><span class="line">            reject(command); <span class="comment">// is shutdown or saturated</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　上面的代码可能看起来不是那么容易理解，下面我们一句一句解释：</p><p>　　首先，判断提交的任务command是否为null，若是null，则抛出空指针异常；</p><p>　　接着是这句，这句要好好理解一下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (poolSize &gt;= corePoolSize || !addIfUnderCorePoolSize(command))</span><br></pre></td></tr></table></figure><p> 　　由于是或条件运算符，所以先计算前半部分的值，如果线程池中当前线程数不小于核心池大小，那么就会直接进入下面的if语句块了。</p><p>　　如果线程池中当前线程数小于核心池大小，则接着执行后半部分，也就是执行</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">addIfUnderCorePoolSize(command)</span><br></pre></td></tr></table></figure><p>　　如果执行完<code>addIfUnderCorePoolSize</code>这个方法返回false，则继续执行下面的if语句块，否则整个方法就直接执行完毕了。</p><p>　　如果执行完addIfUnderCorePoolSize这个方法返回false，然后接着判断：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (runState == RUNNING &amp;&amp; workQueue.offer(command))</span><br></pre></td></tr></table></figure><p> 　　<strong>如果当前线程池处于RUNNING状态，则将任务放入任务缓存队列</strong>；如果当前线程池不处于RUNNING状态或者任务放入缓存队列失败，则执行：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">addIfUnderMaximumPoolSize(command)</span><br></pre></td></tr></table></figure><p>　　如果执行addIfUnderMaximumPoolSize方法失败，则执行reject()方法进行任务拒绝处理。</p><p>　　回到前面：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (runState == RUNNING &amp;&amp; workQueue.offer(command))</span><br></pre></td></tr></table></figure><p> 　　这句的执行，如果说当前线程池处于RUNNING状态且将任务放入任务缓存队列成功，则继续进行判断：</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">if (<span class="name">runState</span> != RUNNING || poolSize == <span class="number">0</span>)</span><br></pre></td></tr></table></figure><p> 　　这句判断是为了防止在将此任务添加进任务缓存队列的同时其他线程突然调用shutdown或者shutdownNow方法关闭了线程池的一种应急措施。如果是这样就执行：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ensureQueuedTaskHandled(command)</span><br></pre></td></tr></table></figure><p> 　　进行应急处理，从名字可以看出是<strong>保证添加到任务缓存队列中的任务得到处理。</strong></p><p>　　我们接着看2个关键方法的实现：<code>addIfUnderCorePoolSize</code>和<code>addIfUnderMaximumPoolSize</code>：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">addIfUnderCorePoolSize</span><span class="params">(Runnable firstTask)</span> </span>&#123;</span><br><span class="line">    Thread t = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">    mainLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (poolSize &lt; corePoolSize &amp;&amp; runState == RUNNING)</span><br><span class="line">            t = addThread(firstTask);        <span class="comment">//创建线程去执行firstTask任务   </span></span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (t == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    t.start();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　这个是addIfUnderCorePoolSize方法的具体实现，从名字可以看出它的意图就是当低于核心池大小时执行的方法。下面看其具体实现，首先获取到锁，因为这地方涉及到线程池状态的变化，先通过if语句判断当前线程池中的线程数目是否小于核心池大小，有朋友也许会有疑问：前面在execute()方法中不是已经判断过了吗，只有线程池当前线程数目小于核心池大小才会执行addIfUnderCorePoolSize方法的，为何这地方还要继续判断？原因很简单，<strong>前面的判断过程中并没有加锁，因此可能在execute方法判断的时候poolSize小于corePoolSize，而判断完之后，在其他线程中又向线程池提交了任务，就可能导致poolSize不小于corePoolSize了</strong>，所以需要在这个地方继续判断。然后接着判断线程池的状态是否为RUNNING，原因也很简单，<strong>因为有可能在其他线程中调用了shutdown或者shutdownNow方法</strong>。然后就是执行</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t = addThread(firstTask);</span><br></pre></td></tr></table></figure><p> 　　这个方法也非常关键，传进去的参数为提交的任务，返回值为Thread类型。然后接着在下面判断t是否为空，为空则表明创建线程失败（即poolSize&gt;=corePoolSize或者runState不等于RUNNING），否则调用t.start()方法启动线程。</p><p>　　我们来看一下addThread方法的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Thread <span class="title">addThread</span><span class="params">(Runnable firstTask)</span> </span>&#123;</span><br><span class="line">    Worker w = <span class="keyword">new</span> Worker(firstTask);</span><br><span class="line">    Thread t = threadFactory.newThread(w);  <span class="comment">//创建一个线程，执行任务   </span></span><br><span class="line">    <span class="keyword">if</span> (t != <span class="keyword">null</span>) &#123;</span><br><span class="line">        w.thread = t;            <span class="comment">//将创建的线程的引用赋值为w的成员变量       </span></span><br><span class="line">        workers.add(w);</span><br><span class="line">        <span class="keyword">int</span> nt = ++poolSize;     <span class="comment">//当前线程数加1       </span></span><br><span class="line">        <span class="keyword">if</span> (nt &gt; largestPoolSize)</span><br><span class="line">            largestPoolSize = nt;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> t;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　在addThread方法中，首先用提交的任务创建了一个Worker对象，然后调用线程工厂threadFactory创建了一个新的线程t，然后将线程t的引用赋值给了Worker对象的成员变量thread，接着通过workers.add(w)将Worker对象添加到工作集当中。</p><p>　　下面我们看一下Worker类的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Worker</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ReentrantLock runLock = <span class="keyword">new</span> ReentrantLock();</span><br><span class="line">    <span class="keyword">private</span> Runnable firstTask;</span><br><span class="line">    <span class="keyword">volatile</span> <span class="keyword">long</span> completedTasks;</span><br><span class="line">    Thread thread;</span><br><span class="line">    Worker(Runnable firstTask) &#123;</span><br><span class="line">        <span class="keyword">this</span>.firstTask = firstTask;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isActive</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> runLock.isLocked();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">interruptIfIdle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ReentrantLock runLock = <span class="keyword">this</span>.runLock;</span><br><span class="line">        <span class="keyword">if</span> (runLock.tryLock()) &#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (thread != Thread.currentThread())</span><br><span class="line">        thread.interrupt();</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                runLock.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">interruptNow</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        thread.interrupt();</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">runTask</span><span class="params">(Runnable task)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> ReentrantLock runLock = <span class="keyword">this</span>.runLock;</span><br><span class="line">        runLock.lock();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (runState &lt; STOP &amp;&amp;</span><br><span class="line">                Thread.interrupted() &amp;&amp;</span><br><span class="line">                runState &gt;= STOP)</span><br><span class="line">            <span class="keyword">boolean</span> ran = <span class="keyword">false</span>;</span><br><span class="line">            beforeExecute(thread, task);   <span class="comment">//beforeExecute方法是ThreadPoolExecutor类的一个方法，没有具体实现，用户可以根据</span></span><br><span class="line">            <span class="comment">//自己需要重载这个方法和后面的afterExecute方法来进行一些统计信息，比如某个任务的执行时间等           </span></span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                task.run();</span><br><span class="line">                ran = <span class="keyword">true</span>;</span><br><span class="line">                afterExecute(task, <span class="keyword">null</span>);</span><br><span class="line">                ++completedTasks;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (RuntimeException ex) &#123;</span><br><span class="line">                <span class="keyword">if</span> (!ran)</span><br><span class="line">                    afterExecute(task, ex);</span><br><span class="line">                <span class="keyword">throw</span> ex;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            runLock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Runnable task = firstTask;</span><br><span class="line">            firstTask = <span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">while</span> (task != <span class="keyword">null</span> || (task = getTask()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                runTask(task);</span><br><span class="line">                task = <span class="keyword">null</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            workerDone(<span class="keyword">this</span>);   <span class="comment">//当任务队列中没有任务时，进行清理工作       </span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　它实际上实现了Runnable接口，因此上面的Thread t = threadFactory.newThread(w);效果跟下面这句的效果基本一样：</p><figure class="highlight autohotkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Thread</span> t = <span class="keyword">new</span> <span class="keyword">Thread</span>(w)<span class="comment">;</span></span><br></pre></td></tr></table></figure><p> 　　相当于传进去了一个Runnable任务，在线程t中执行这个Runnable。</p><p>　　既然Worker实现了Runnable接口，那么自然最核心的方法便是run()方法了：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Runnable task = firstTask;</span><br><span class="line">        firstTask = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">while</span> (task != <span class="keyword">null</span> || (task = getTask()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            runTask(task);</span><br><span class="line">            task = <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        workerDone(<span class="keyword">this</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　从run方法的实现可以看出，它首先执行的是通过构造器传进来的任务firstTask，在调用runTask()执行完firstTask之后，在while循环里面不断通过getTask()去取新的任务来执行，那么去哪里取呢？自然是从<strong>任务缓存队列里面去取</strong>，getTask是ThreadPoolExecutor类中的方法，并不是Worker类中的方法，下面是getTask方法的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Runnable <span class="title">getTask</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">int</span> state = runState;</span><br><span class="line">            <span class="keyword">if</span> (state &gt; SHUTDOWN)</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">            Runnable r;</span><br><span class="line">            <span class="keyword">if</span> (state == SHUTDOWN)  <span class="comment">// Help drain queue</span></span><br><span class="line">                r = workQueue.poll();</span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (poolSize &gt; corePoolSize || allowCoreThreadTimeOut) <span class="comment">//如果线程数大于核心池大小或者允许为核心池线程设置空闲时间，</span></span><br><span class="line">                <span class="comment">//则通过poll取任务，若等待一定的时间取不到任务，则返回null</span></span><br><span class="line">                r = workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS);</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                r = workQueue.take();</span><br><span class="line">            <span class="keyword">if</span> (r != <span class="keyword">null</span>)</span><br><span class="line">                <span class="keyword">return</span> r;</span><br><span class="line">            <span class="keyword">if</span> (workerCanExit()) &#123;    <span class="comment">//如果没取到任务，即r为null，则判断当前的worker是否可以退出</span></span><br><span class="line">                <span class="keyword">if</span> (runState &gt;= SHUTDOWN) <span class="comment">// Wake up others</span></span><br><span class="line">                    interruptIdleWorkers();   <span class="comment">//中断处于空闲状态的worker</span></span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// Else retry</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException ie) &#123;</span><br><span class="line">            <span class="comment">// On interruption, re-check runState</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　在getTask中，先判断当前线程池状态，如果<strong>runState大于SHUTDOWN（即为STOP或者TERMINATED），</strong>则直接返回null。</p><p>　　如果runState为SHUTDOWN或者RUNNING，则从<strong>任务缓存队列取任务。</strong></p><p>　　如果当前线程池的线程数大于核心池大小corePoolSize或者允许为核心池中的线程设置空闲存活时间，<strong>则调用poll(time,timeUnit)来取任务，这个方法会等待一定的时间，如果取不到任务就返回null。</strong></p><p>　　然后判断取到的任务r是否为null，为null则通过调用workerCanExit()方法来判断当前worker是否可以退出，我们看一下workerCanExit()的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">workerCanExit</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">    mainLock.lock();</span><br><span class="line">    <span class="keyword">boolean</span> canExit;</span><br><span class="line">    <span class="comment">//如果runState大于等于STOP，或者任务缓存队列为空了</span></span><br><span class="line">    <span class="comment">//或者  允许为核心池线程设置空闲存活时间并且线程池中的线程数目大于1</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        canExit = runState &gt;= STOP ||</span><br><span class="line">            workQueue.isEmpty() ||</span><br><span class="line">            (allowCoreThreadTimeOut &amp;&amp;</span><br><span class="line">             poolSize &gt; Math.max(<span class="number">1</span>, corePoolSize));</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> canExit;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　也就是说如果<strong>线程池处于STOP状态</strong>、或者<strong>任务队列已为空</strong>或者<strong>允许为核心池线程设置空闲存活时间并且线程数大于1</strong>时，允许worker退出。如果允许worker退出，则调用interruptIdleWorkers()中断处于空闲状态的worker，我们看一下interruptIdleWorkers()的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">oid <span class="title">interruptIdleWorkers</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">    mainLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (Worker w : workers)  <span class="comment">//实际上调用的是worker的interruptIfIdle()方法</span></span><br><span class="line">            w.interruptIfIdle();</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　从实现可以看出，它实际上调用的是worker的interruptIfIdle()方法，在worker的interruptIfIdle()方法中：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">interruptIfIdle</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock runLock = <span class="keyword">this</span>.runLock;</span><br><span class="line">    <span class="keyword">if</span> (runLock.tryLock()) &#123;    <span class="comment">//注意这里，是调用tryLock()来获取锁的，因为如果当前worker正在执行任务，锁已经被获取了，是无法获取到锁的</span></span><br><span class="line">                                <span class="comment">//如果成功获取了锁，说明当前worker处于空闲状态</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (thread != Thread.currentThread())  </span><br><span class="line">    thread.interrupt();</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            runLock.unlock();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>  　　这里有一个非常巧妙的设计方式，假如我们来设计线程池，可能会有一个任务分派线程，当发现有线程空闲时，就从任务缓存队列中取一个任务交给空闲线程执行。但是在这里，并没有采用这样的方式，因为这样会要额外地对任务分派线程进行管理，无形地会增加难度和复杂度，<strong>这里直接让执行完任务的线程去任务缓存队列里面取任务来执行。</strong></p><p> 　　我们再看<code>addIfUnderMaximumPoolSize</code>方法的实现，这个方法的实现思想和addIfUnderCorePoolSize方法的实现思想非常相似，<strong>唯一的区别在于addIfUnderMaximumPoolSize方法是在线程池中的线程数达到了核心池大小并且往任务队列中添加任务失败的情况下执行的：</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">addIfUnderMaximumPoolSize</span><span class="params">(Runnable firstTask)</span> </span>&#123;</span><br><span class="line">    Thread t = <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">final</span> ReentrantLock mainLock = <span class="keyword">this</span>.mainLock;</span><br><span class="line">    mainLock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (poolSize &lt; maximumPoolSize &amp;&amp; runState == RUNNING)</span><br><span class="line">            t = addThread(firstTask);</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        mainLock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (t == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    t.start();</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　看到没有，其实它和addIfUnderCorePoolSize方法的实现基本一模一样，只是if语句判断条件中的poolSize &lt; maximumPoolSize不同而已。</p><p>　　到这里，大部分朋友应该对任务提交给线程池之后到被执行的整个过程有了一个基本的了解，下面总结一下：</p><ol><li><p>首先，要清楚corePoolSize和maximumPoolSize的含义；</p></li><li><p>其次，要知道Worker是用来起到什么作用的；</p></li><li><p>要知道任务提交给线程池之后的处理策略，这里总结一下主要有4点：</p></li></ol><ul><li>如果当前线程池中的线程数目小于corePoolSize，则每来一个任务，就会创建一个线程去执行这个任务；</li><li>如果当前线程池中的线程数目&gt;=corePoolSize，则每来一个任务，会尝试将其添加到任务缓存队列当中，若添加成功，则该任务会等待空闲线程将其取出去执行；若添加失败（一般来说是任务缓存队列已满），则会尝试创建新的线程去执行这个任务；</li><li>如果当前线程池中的线程数目达到maximumPoolSize，则会采取任务拒绝策略进行处理；</li><li>如果线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止，直至线程池中的线程数目不大于corePoolSize；如果允许为核心池中的线程设置存活时间，那么核心池中的线程空闲时间超过keepAliveTime，线程也会被终止。</li></ul><h3 id="线程池中的线程初始化"><a href="#线程池中的线程初始化" class="headerlink" title="线程池中的线程初始化"></a>线程池中的线程初始化</h3><p>　　<strong>默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。</strong></p><p>　　在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到：</p><ul><li>prestartCoreThread()：初始化一个核心线程；</li><li>prestartAllCoreThreads()：初始化所有核心线程</li></ul><p>　　下面是这2个方法的实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">prestartCoreThread</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> addIfUnderCorePoolSize(<span class="keyword">null</span>); <span class="comment">//注意传进去的参数是null</span></span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">prestartAllCoreThreads</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (addIfUnderCorePoolSize(<span class="keyword">null</span>))<span class="comment">//注意传进去的参数是null</span></span><br><span class="line">        ++n;</span><br><span class="line">    <span class="keyword">return</span> n;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　注意上面传进去的参数是null，根据第2小节的分析可知如果传进去的参数为null，则最后执行线程会阻塞在getTask方法中的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r = workQueue.take();</span><br></pre></td></tr></table></figure><p> 　　即等待任务队列中有任务。</p><p><strong>### 任务缓存队列及排队策略</strong></p><p>　　在前面我们多次提到了任务缓存队列，即workQueue，它用来存放等待执行的任务。</p><p>　　workQueue的类型为<code>BlockingQueue&lt;Runnable&gt;</code>，通常可以取下面三种类型：</p><p>　　1）ArrayBlockingQueue：基于数组的先进先出队列，<strong>此队列创建时必须指定大小；</strong></p><p>　　2）LinkedBlockingQueue：基于链表的先进先出队列，如果创建时没有指定此队列大小，则默认为Integer.MAX_VALUE；</p><p>　　3）synchronousQueue：这个队列比较特殊，<strong>它不会保存提交的任务，而是将直接新建一个线程来执行新来的任务。</strong></p><h3 id="任务拒绝策略"><a href="#任务拒绝策略" class="headerlink" title="任务拒绝策略"></a>任务拒绝策略</h3><p>　　当线程池的任务缓存队列已满并且线程池中的线程数目达到maximumPoolSize，如果还有任务到来就会采取任务拒绝策略，通常有以下四种策略：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ThreadPoolExecutor.AbortPolicy:丢弃任务并抛出RejectedExecutionException异常。</span><br><span class="line">ThreadPoolExecutor.DiscardPolicy：也是丢弃任务，但是不抛出异常。</span><br><span class="line">ThreadPoolExecutor.DiscardOldestPolicy：丢弃队列最前面的任务，然后重新尝试执行任务（重复此过程）</span><br><span class="line">ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务</span><br></pre></td></tr></table></figure><h3 id="线程池的关闭"><a href="#线程池的关闭" class="headerlink" title="线程池的关闭"></a>线程池的关闭</h3><p>　　ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中：</p><ul><li>shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务</li><li>shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务</li></ul><h3 id="线程池容量的动态调整"><a href="#线程池容量的动态调整" class="headerlink" title="线程池容量的动态调整"></a>线程池容量的动态调整</h3><p>　　ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()，</p><ul><li>setCorePoolSize：设置核心池大小</li><li>setMaximumPoolSize：设置线程池最大能创建的线程数目大小</li></ul><p>　　当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。</p><h2 id="使用示例"><a href="#使用示例" class="headerlink" title="使用示例"></a>使用示例</h2><p>　　前面我们讨论了关于线程池的实现原理，这一节我们来看一下它的具体使用：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line">     <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;   </span><br><span class="line">         ThreadPoolExecutor executor = <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">5</span>, <span class="number">10</span>, <span class="number">200</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                 <span class="keyword">new</span> ArrayBlockingQueue&lt;Runnable&gt;(<span class="number">5</span>));</span><br><span class="line">          </span><br><span class="line">         <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;<span class="number">15</span>;i++)&#123;</span><br><span class="line">             MyTask myTask = <span class="keyword">new</span> MyTask(i);</span><br><span class="line">             executor.execute(myTask);</span><br><span class="line">             System.out.println(<span class="string">"线程池中线程数目："</span>+executor.getPoolSize()+<span class="string">"，队列中等待执行的任务数目："</span>+</span><br><span class="line">             executor.getQueue().size()+<span class="string">"，已执行玩别的任务数目："</span>+executor.getCompletedTaskCount());</span><br><span class="line">         &#125;</span><br><span class="line">         executor.shutdown();</span><br><span class="line">     &#125;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyTask</span> <span class="keyword">implements</span> <span class="title">Runnable</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> taskNum;</span><br><span class="line">     </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MyTask</span><span class="params">(<span class="keyword">int</span> num)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.taskNum = num;</span><br><span class="line">    &#125;</span><br><span class="line">     </span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"正在执行task "</span>+taskNum);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.currentThread().sleep(<span class="number">4000</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        System.out.println(<span class="string">"task "</span>+taskNum+<span class="string">"执行完毕"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> 　　执行结果：</p><blockquote><p>正在执行task 0<br>线程池中线程数目：1，队列中等待执行的任务数目：0，已执行玩别的任务数目：0<br>线程池中线程数目：2，队列中等待执行的任务数目：0，已执行玩别的任务数目：0<br>正在执行task 1<br>线程池中线程数目：3，队列中等待执行的任务数目：0，已执行玩别的任务数目：0<br>正在执行task 2<br>线程池中线程数目：4，队列中等待执行的任务数目：0，已执行玩别的任务数目：0<br>正在执行task 3<br>线程池中线程数目：5，队列中等待执行的任务数目：0，已执行玩别的任务数目：0<br>正在执行task 4<br>线程池中线程数目：5，队列中等待执行的任务数目：1，已执行玩别的任务数目：0<br>线程池中线程数目：5，队列中等待执行的任务数目：2，已执行玩别的任务数目：0<br>线程池中线程数目：5，队列中等待执行的任务数目：3，已执行玩别的任务数目：0<br>线程池中线程数目：5，队列中等待执行的任务数目：4，已执行玩别的任务数目：0<br>线程池中线程数目：5，队列中等待执行的任务数目：5，已执行玩别的任务数目：0<br>线程池中线程数目：6，队列中等待执行的任务数目：5，已执行玩别的任务数目：0<br>正在执行task 10<br>线程池中线程数目：7，队列中等待执行的任务数目：5，已执行玩别的任务数目：0<br>正在执行task 11<br>线程池中线程数目：8，队列中等待执行的任务数目：5，已执行玩别的任务数目：0<br>正在执行task 12<br>线程池中线程数目：9，队列中等待执行的任务数目：5，已执行玩别的任务数目：0<br>正在执行task 13<br>线程池中线程数目：10，队列中等待执行的任务数目：5，已执行玩别的任务数目：0<br>正在执行task 14<br>task 3执行完毕<br>task 0执行完毕<br>task 2执行完毕<br>task 1执行完毕<br>正在执行task 8<br>正在执行task 7<br>正在执行task 6<br>正在执行task 5<br>task 4执行完毕<br>task 10执行完毕<br>task 11执行完毕<br>task 13执行完毕<br>task 12执行完毕<br>正在执行task 9<br>task 14执行完毕<br>task 8执行完毕<br>task 5执行完毕<br>task 7执行完毕<br>task 6执行完毕<br>task 9执行完毕</p></blockquote><p>　　从执行结果可以看出，当线程池中线程的数目大于5时，便将任务放入任务缓存队列里面，当任务缓存队列满了之后，便创建新的线程。如果上面程序中，将for循环中改成执行20个任务，就会抛出任务拒绝异常了。</p><p>　　不过在java doc中，并不提倡我们直接使用ThreadPoolExecutor，而是使用Executors类中提供的几个静态方法来创建线程池：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Executors.newCachedThreadPool();        <span class="comment">//创建一个缓冲池，缓冲池容量大小为Integer.MAX_VALUE</span></span><br><span class="line">Executors.newSingleThreadExecutor();   <span class="comment">//创建容量为1的缓冲池</span></span><br><span class="line">Executors.newFixedThreadPool(<span class="keyword">int</span>);    <span class="comment">//创建固定容量大小的缓冲池</span></span><br></pre></td></tr></table></figure><p> 　　下面是这三个静态方法的具体实现;</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newFixedThreadPool</span><span class="params">(<span class="keyword">int</span> nThreads)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(nThreads, nThreads,</span><br><span class="line">                                  <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                  <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;());</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newSingleThreadExecutor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> FinalizableDelegatedExecutorService</span><br><span class="line">        (<span class="keyword">new</span> ThreadPoolExecutor(<span class="number">1</span>, <span class="number">1</span>,</span><br><span class="line">                                <span class="number">0L</span>, TimeUnit.MILLISECONDS,</span><br><span class="line">                                <span class="keyword">new</span> LinkedBlockingQueue&lt;Runnable&gt;()));</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> ExecutorService <span class="title">newCachedThreadPool</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> ThreadPoolExecutor(<span class="number">0</span>, Integer.MAX_VALUE,</span><br><span class="line">                                  <span class="number">60L</span>, TimeUnit.SECONDS,</span><br><span class="line">                                  <span class="keyword">new</span> SynchronousQueue&lt;Runnable&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>　　从它们的具体实现来看，它们实际上也是调用了ThreadPoolExecutor，只不过参数都已配置好了。</p><ul><li><p>newFixedThreadPool创建的线程池corePoolSize和maximumPoolSize值是相等的，它使用的LinkedBlockingQueue；</p><blockquote><p>创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。FixedThreadPool是一个典型且优秀的线程池，它具有线程池提高程序效率和节省创建线程时所耗的开销的优点。但是，在线程池空闲时，即线程池中没有可运行任务时，它不会释放工作线程，还会占用一定的系统资源。</p></blockquote></li><li><p>newSingleThreadExecutor将corePoolSize和maximumPoolSize都设置为1，也使用的LinkedBlockingQueue；</p><blockquote><p>创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO,LIFO, 优先级)执行。如果这个线程异常结束，会有另一个取代它，保证顺序执行。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。</p></blockquote></li><li><p>newCachedThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的SynchronousQueue，<strong>也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。</strong></p><blockquote><p>创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。这种类型的线程池特点是：</p><ul><li>工作线程的创建数量几乎没有限制(其实也有限制的,数目为Interger.MAX_VALUE), 这样可灵活的往线程池中添加线程。</li><li>如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间(默认为1分钟)，则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。</li><li>在使用CachedThreadPool时，一定要注意控制任务的数量，否则，由于大量线程同时运行，很有会造成系统瘫痪。</li></ul></blockquote></li></ul><p>　　实际中，如果Executors提供的三个静态方法能满足要求，就尽量使用它提供的三个方法，因为自己去手动配置ThreadPoolExecutor的参数有点麻烦，要根据实际任务的类型和数量来进行配置。</p><p>　　另外，如果ThreadPoolExecutor达不到要求，可以自己继承ThreadPoolExecutor类进行重写。</p><h2 id="如何合理配置线程池的大小"><a href="#如何合理配置线程池的大小" class="headerlink" title="如何合理配置线程池的大小"></a>如何合理配置线程池的大小</h2><p>　　本节来讨论一个比较重要的话题：如何合理配置线程池大小，仅供参考。</p><p>　　一般需要根据任务的类型来配置线程池大小：</p><ul><li>如果是CPU密集型任务，就需要尽量压榨CPU，参考值可以设为 <em>N</em>CPU+1</li><li>如果是IO密集型任务，参考值可以设置为2<em>*N</em>CPU</li></ul><p>　　当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。</p><p>　　参考资料：</p><p>　　<a href="http://ifeve.com/java-threadpool/" target="_blank" rel="noopener">http://ifeve.com/java-threadpool/</a></p><p>　　<a href="http://blog.163.com/among_1985/blog/static/275005232012618849266/" target="_blank" rel="noopener">http://blog.163.com/among_1985/blog/static/275005232012618849266/</a></p><p>　　<a href="http://developer.51cto.com/art/201203/321885.htm" target="_blank" rel="noopener">http://developer.51cto.com/art/201203/321885.htm</a></p><p>　　<a href="http://blog.csdn.net/java2000_wl/article/details/22097059" target="_blank" rel="noopener">http://blog.csdn.net/java2000_wl/article/details/22097059</a></p><p>　　<a href="http://blog.csdn.net/cutesource/article/details/6061229" target="_blank" rel="noopener">http://blog.csdn.net/cutesource/article/details/6061229</a></p><p>　　<a href="http://blog.csdn.net/xieyuooo/article/details/8718741" target="_blank" rel="noopener">http://blog.csdn.net/xieyuooo/article/details/8718741</a></p><p>　　《JDK API 1.6》</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转载自：&lt;a href=&quot;https://www.cnblogs.com/dolphin0520/p/3932921.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Java并发编程：线程池的使用&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在前面的文章中，我们使用线程的时候就去创建一个线程，这样实现起来非常简便，但是就会有一个问题：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？&lt;/p&gt;
&lt;p&gt;在Java中可以通过&lt;strong&gt;线程池&lt;/strong&gt;来达到这样的效果。今天我们就来详细讲解一下Java的线程池，首先我们从最核心的&lt;code&gt;ThreadPoolExecutor&lt;/code&gt;类中的方法讲起，然后再讲述它的实现原理，接着给出了它的使用示例，最后讨论了一下如何合理配置线程池的大小。&lt;/p&gt;
&lt;p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://changsk.top/categories/Java/"/>
    
    
      <category term="java" scheme="http://changsk.top/tags/java/"/>
    
      <category term="线程池" scheme="http://changsk.top/tags/%E7%BA%BF%E7%A8%8B%E6%B1%A0/"/>
    
  </entry>
  
  <entry>
    <title>初识ALS</title>
    <link href="http://changsk.top/2019/06/28/ALS/"/>
    <id>http://changsk.top/2019/06/28/ALS/</id>
    <published>2019-06-27T16:17:43.000Z</published>
    <updated>2019-06-29T08:17:06.523Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>Spark平台推出至今已经地带到2.4.x版本，很多地方都有了重要的更新，加入了很多新的东西。<br>但是在协同过滤这一块却一直以来都只有ALS一种算法。<br>同样是大规模计算平台，Hadoop中的机器学习算法库Mahout就集成了多种推荐算法，不但有<code>user-cf</code>和<code>item-cf</code>这种经典算法，还有KNN、SVD，Slope one这些，可谓随意挑选，简繁由君。<br>ALS算法是2008年以来，用的比较多的协同过滤算法。它已经集成到<code>Spark</code>的<code>Mllib</code>库中，使用起来比较方便。</p><a id="more"></a><h1 id="ALS算法"><a href="#ALS算法" class="headerlink" title="ALS算法"></a>ALS算法</h1><h2 id="算法介绍"><a href="#算法介绍" class="headerlink" title="算法介绍"></a>算法介绍</h2><p>ALS的意思是<strong>交替最小二乘法</strong>（Alternating Least Squares），它只是一种优化算法的名字，被用在求解spark中所提供的推荐系统模型的最优解。spark中协同过滤的文档中一开始就说了。<br><img src="11.jpg" alt><br>从协同过滤的分类来说，ALS算法属于<code>User-Item CF</code>，也叫做混合CF。它同时考虑了User和Item两个方面。<br>用户和商品的关系，可以抽象为如下的三元组：<code>&lt;User,Item,Rating&gt;</code>。其中，Rating是用户对商品的评分，表征用户对该商品的喜好程度。</p><p>这是一个<strong>基于模型</strong>的协同过滤（model-based CF），其实它是一种近几年推荐系统界大火的隐语义模型中的一种。它的基本思想是对<code>稀疏矩阵进行模型分解，评估出缺失项的值，以此来得到一个基本的训练模型。然后依照此模型可以针对新的用户和物品数据进行评估。ALS是采用交替的最小二乘法来算出缺失项的</code>。交替的最小二乘法是在最小二乘法的基础上发展而来的。</p><blockquote><p>隐语义模型又叫潜在因素模型，它试图通过数量相对少的未被观察到的底层原因，来解释大量用户和产品之间可观察到的交互。</p></blockquote><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><h3 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h3><p>基于模型的协同过滤算法操作起来就是通过<strong>降维</strong>的方法来补全<code>用户-物品矩阵</code>，<strong>对矩阵中没有出现的值进行估计</strong>。基于这种思想的早期推荐系统常用的一种方法是<code>SVD</code>（奇异值分解）。<br>该方法在矩阵分解之前需要先把评分矩阵R缺失值补全，补全之后稀疏矩阵R表示成稠密矩阵R’，然后将R’分解成如下形式：</p><p><strong>R’ = U<sup>T</sup>SV</strong><br>然后再选取U中的K列和V中的S行作为隐特征的个数，达到降维的目的。<strong>K的选取通常用启发式策略。</strong></p><p>这种方法有两个缺点</p><ul><li>补全成稠密矩阵之后需要耗费巨大的存储空间，在实际中，用户对物品的行为信息何止千万，对这样的稠密矩阵的存储是不现实的。</li><li>SVD的计算复杂度很高，更不用说这样的大规模稠密矩阵了。所以关于SVD的研究很多都是在小数据集上进行的。</li></ul><h3 id="ALS"><a href="#ALS" class="headerlink" title="ALS"></a>ALS</h3><p>隐语义模型也是基于矩阵分解的，但是和SVD不同，它是把原始矩阵分解成两个矩阵相乘而不是三个。</p><p>假设我们有一批用户数据，其中包含m个User和n个Item，则我们定义Rating矩阵，其中的元素表示第u个User对第i个Item的评分。</p><p>在实际使用中，由于<code>n和m的数量都十分巨大</code>，因此R矩阵的规模很容易就会突破1亿项。这时候，传统的矩阵分解方法对于这么大的数据量已经是很难处理了。</p><p>另一方面，一个用户也不可能给所有商品评分，因此，<code>R矩阵注定是个稀疏矩阵</code>。矩阵中所缺失的评分，又叫做<code>missing item</code>。</p><p><img src="1.jpg" alt></p><p>针对这样的特点，我们可以假设<code>用户和商品之间存在若干关联维度</code>（比如用户年龄、性别、受教育程度和商品的外观、价格等），我们只需要将R矩阵投射到这些维度上即可。这个投射的数学表示是：</p><blockquote><p>R<sub>m×n</sub>=U<sub>m×k</sub>×V<sub>k×n</sub></p></blockquote><p>这里的表明这个投射只是一个近似的空间变换。</p><p>不懂这个空间变换的同学，可参见《机器学习（十二）》中的“奇异值分解”的内容，或是本节中的“主成分分析”的内容。</p><p>现在的问题就变成了确定U和V ，我们把</p><blockquote><p>U叫做用户因子矩阵<br>V叫做物品因子矩阵</p></blockquote><p>一般情况下，<code>k的值远小于n和m的值</code>，从而达到了<strong>数据降维</strong>的目的。</p><p>幸运的是，我们<strong>并不需要显式的定义这些关联维度，而只需要假定它们存在即可</strong>，因此这里的关联维度又被称为<code>Latent factor</code>。k的典型取值一般是<strong>20～200</strong>。</p><p>这种方法被称为<code>概率矩阵分解算法</code>(probabilistic matrix factorization，PMF)。ALS算法是PMF在数值计算方面的应用。</p><p>通常上式不能达到精确相等的程度，我们要做的就是要<strong>最小化他们之间的差距</strong>，从而又变成了一个最优化问题。</p><p>求解最优化问题我们很容易就想到了<strong>随机梯度下降</strong>，其中有一种方法就是这样，通过优化如下损失函数来找到X和Y中合适的参数：</p><p><img src="22.jpg" alt></p><p>其中puk就是U矩阵中u行k列的参数，度量了用户u和第k个隐类的关系；qik是V矩阵中i行k列的参数，度量了物品i和第k个隐类的关系。这种方式也是一种很流行的方法，有很多对它的相关扩展，比如加上偏置项的LFM。</p><p>然而ALS用的是另一种求解方法，它先用<strong>随机初始化</strong>的方式固定一个矩阵，例如Y<br><img src="33.jpg" alt><br>然后通过最小化等式两边差的平方来更新另一个矩阵X。</p><p>得到X之后，又可以固定X用相同的方法求Y，如此交替进行，直到<strong>最后收敛</strong>或者<strong>达到用户指定的迭代次数</strong>为止，是为“交替”是也。</p><p>因为这个迭代过程，<strong>交替优化X和Y</strong>，因此又被称作交替最小二乘算法（Alternating Least Squares，ALS）。</p><p>从上式可以看出，X的第i行是A的第i行和Y的函数，因此可以很容易地分开计算X的每一行，这就为并行计算提供了很大的便捷，也正是如此，Spark这种面向大规模计算的平台选择了这个算法。</p><p>在<a href="https://www.cnblogs.com/mooba/p/6539142.html" target="_blank" rel="noopener">Intro to Implicit Matrix Factorization: Classic ALS with Sketchfab Models</a>中，作者用了<code>embarrassingly parallel</code>来形容这个算法，意思是<strong>高度易并行化</strong>的——它的每个子任务之间没有什么依赖关系。</p><p>在现实中，不可能每个用户都和所有的物品都有行为关系，事实上，有交互关系的用户-物品对只占很小的一部分，换句话说，<strong>用户-物品关系列表是非常稀疏的。</strong><br>和SVD这种矩阵分解不同，ALS所用的矩阵分解技术在分解之前不用把系数矩阵填充成稠密矩阵之后再分解，这不但大大减少了存储空间，而且spark可以利用这种稀疏性用简单的线性代数计算求解。<br>这几点使得本算法在大规模数据上计算非常快，解释了为什么spark mllib目前只有ALS一种推荐算法。</p><h2 id="ALS算法的缺点"><a href="#ALS算法的缺点" class="headerlink" title="ALS算法的缺点"></a>ALS算法的缺点</h2><blockquote><ol><li>它是一个离线算法。</li><li>无法准确评估新加入的用户或商品。这个问题也被称为<code>Cold Start</code>问题。</li></ol></blockquote><h2 id="显性反馈和隐性反馈"><a href="#显性反馈和隐性反馈" class="headerlink" title="显性反馈和隐性反馈"></a>显性反馈和隐性反馈</h2><p>基于矩阵分解的协同过滤的标准方法将用户项矩阵中的条目视为由用户给予该项的明确偏好，例如，给予电影评级的用户。<br>在许多真实世界的用例中，通常只能访问隐式反馈（例如查看，点击，购买，喜欢，共享等）。</p><blockquote><p>隐式反馈：<br>用户给商品评分是个非常简单粗暴的用户行为。在实际的电商网站中，还有大量的用户行为，同样能够间接反映用户的喜好，比如用户的购买记录、搜索关键字，甚至是鼠标的移动。我们将这些间接用户行为称之为隐式反馈（implicit feedback），以区别于评分这样的显式反馈（explicit feedback）。</p></blockquote><blockquote><p>隐式反馈有以下几个特点：<br>1.没有负面反馈（negative feedback）。用户一般会直接忽略不喜欢的商品，而不是给予负面评价。<br>2.隐式反馈包含大量噪声。比如，电视机在某一时间播放某一节目，然而用户已经睡着了，或者忘了换台。<br>3.显式反馈表现的是用户的喜好（preference），而隐式反馈表现的是用户的信任（confidence）。比如用户最喜欢的一般是电影，但观看时间最长的却是连续剧。大米购买的比较频繁，量也大，但未必是用户最想吃的食物。<br>4.隐式反馈非常难以量化。</p></blockquote><p>用于<code>spark.ml</code>处理这些数据的方法取自隐式反馈数据集的协作过滤。<br>本质上，这种方法不是直接对收视率矩阵进行建模，而是将数据视为代表实力的数字观察用户操作（例如点击次数或某人观看电影的累计持续时间）。然后，<strong>这些数字与观察到的用户偏好的信心水平相关，而不是给予项目的明确评分</strong>。该模型然后试图找出可用于预测用户对物品的预期偏好的潜在因素。</p><p>在推荐系统中用户和物品的交互数据分为显性反馈和隐性反馈数据。<br>在ALS中这两种情况也是被考虑了进来的，分别可以训练如下两种模型：</p><h3 id="显性反馈模型"><a href="#显性反馈模型" class="headerlink" title="显性反馈模型"></a>显性反馈模型</h3><p><code>val model1 = ALS.train(ratings, rank, numIterations, lambda)</code></p><h3 id="隐性反馈模型"><a href="#隐性反馈模型" class="headerlink" title="隐性反馈模型"></a>隐性反馈模型</h3><p><code>val model2 = ALS.trainImplicit(ratings, rank, numIterations, lambda, alpha)</code></p><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><blockquote><p>numBlocks是为了并行化计算而将用户和项目划分到的块的数量（默认为10）。<br>rank是模型中潜在因素的数量（默认为10）。<br>maxIter是要运行的最大迭代次数（默认为10）。<br>regParam指定ALS中的正则化参数（默认为1.0）。<br>implicitPrefs指定是使用显式反馈 ALS变体还是使用 隐式反馈数据（默认为false使用显式反馈的手段）。<br>alpha是一个适用于ALS的隐式反馈变量的参数，该变量管理偏好观察值的 基线置信度（默认值为1.0)<br>nonnegative指定是否对最小二乘使用非负约束（默认为false）。<br>注意： ALS的基于DataFrame的API目前仅支持用户和项目ID的整数。用户和项目ID列支持其他数字类型，但ID必须在整数值范围内。</p></blockquote><p>从上面可以看到，隐式模型多了一个<strong>置信参数</strong>，这就涉及到ALS中对于隐式反馈模型的处理方式了——有的文章称为“加权的正则化矩阵分解”，它的损失函数如下：</p><p><img src="44.jpg" alt></p><p>我们知道，在隐反馈模型中是没有评分的，所以在式子中<code>rui</code>被<code>pui</code>所取代，<strong>pui是偏好的表示，仅仅表示用户和物品之间有没有交互，而不表示评分高低或者喜好程度</strong>。比如用户和物品之间有交互就让pui等于1，没有就等于0。函数中还有一个cui的项，它用来表示用户偏爱某个商品的置信程度，<strong>比如交互次数多的权重就会增加</strong>。如果我们用dui来表示交互次数的话，那么就可以把置信程度表示成如下公式：</p><p><img src="55.jpg" alt></p><blockquote><p>参考：<br><a href="https://blog.csdn.net/nieson2012/article/details/79898676" target="_blank" rel="noopener">【推荐系统系列6】ALS推荐算法原理</a><br><a href="https://blog.csdn.net/qq_33589510/article/details/89888383" target="_blank" rel="noopener">ALS算法解析</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;Spark平台推出至今已经地带到2.4.x版本，很多地方都有了重要的更新，加入了很多新的东西。&lt;br&gt;但是在协同过滤这一块却一直以来都只有ALS一种算法。&lt;br&gt;同样是大规模计算平台，Hadoop中的机器学习算法库Mahout就集成了多种推荐算法，不但有&lt;code&gt;user-cf&lt;/code&gt;和&lt;code&gt;item-cf&lt;/code&gt;这种经典算法，还有KNN、SVD，Slope one这些，可谓随意挑选，简繁由君。&lt;br&gt;ALS算法是2008年以来，用的比较多的协同过滤算法。它已经集成到&lt;code&gt;Spark&lt;/code&gt;的&lt;code&gt;Mllib&lt;/code&gt;库中，使用起来比较方便。&lt;/p&gt;
    
    </summary>
    
      <category term="推荐算法" scheme="http://changsk.top/categories/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="ALS" scheme="http://changsk.top/tags/ALS/"/>
    
  </entry>
  
  <entry>
    <title>mysql最左匹配原则</title>
    <link href="http://changsk.top/2019/06/27/mysql-leftmost-matching-principle/"/>
    <id>http://changsk.top/2019/06/27/mysql-leftmost-matching-principle/</id>
    <published>2019-06-27T13:36:56.000Z</published>
    <updated>2019-06-27T13:57:43.062Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自：<a href="https://www.zhihu.com/question/36996520/answer/93256153" target="_blank" rel="noopener">mysql索引最左匹配原则的理解?</a><br>作者：沈杰</p></blockquote><p>下面是一个表结构，有三个字段，分别是<code>id,name,cid</code></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE `student` (</span><br><span class="line">  `id` int(11) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  `name` varchar(255) DEFAULT NULL,</span><br><span class="line">  `cid` int(11) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`id`),</span><br><span class="line">  KEY `name_cid_INX` (`name`,`cid`),</span><br><span class="line">) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=utf8</span><br></pre></td></tr></table></figure><p>索引方面：<code>id</code>是主键，<code>(name,cid)</code>是一个多列索引。</p><a id="more"></a><p>先看下面两条SQL语句的执行计划：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM student WHERE   cid=1;</span><br></pre></td></tr></table></figure><p><img src="1.jpg" alt="img"><img src="https://pic2.zhimg.com/80/d3086a6c81bb2c77796cfc2249b610bc_hd.jpg" alt="img"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM student WHERE   cid=1 AND name=&apos;小红&apos;;</span><br></pre></td></tr></table></figure><p><img src="2.jpg" alt="img"><img src="https://pic3.zhimg.com/80/53ab2cdea64b7e58e66c4ef86aa6b06a_hd.jpg" alt="img"></p><p>sql查询用到索引的条件是必须要遵守最左前缀原则，为什么上面两个查询还能用到索引？<br>-————————————————————————————————————————–</p><p>讲上面问题之前，我先补充一些知识，因为我觉得你对索引理解是狭隘的：<br>上述你的两个查询的explain结果中显示用到索引的情况类型是不一样的。,可观察explain结果中的type字段。你的查询中分别是：</p><blockquote><p>type: index<br>type: ref  </p></blockquote><p><strong>解释：</strong></p><ul><li>index：这种类型表示是mysql会对<strong>整个该索引进行扫描</strong>。要想用到这种类型的索引，对这个索引并无特别要求，<strong>只要是索引，或者某个复合索引的一部分</strong>，mysql都可能会采用index类型的方式扫描。但是呢，缺点是效率不高，mysql会从索引中的第一个数据一个个的查找到最后一个数据，直到找到符合判断条件的某个索引。</li></ul><p><strong>所以：</strong>对于第一条语句：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM student WHERE   cid=1;</span><br></pre></td></tr></table></figure><p>判断条件是cid=1,而cid是(name,cid)复合索引的一部分，没有问题，<strong>可以进行index类型的索引扫描方式</strong>。explain显示结果使用到了索引，是index类型的方式。</p><p>-————————————————————————————————————————–</p><ul><li>ref：这种类型表示mysql会根据特定的算法快速查找到某个符合条件的索引，而不是会对索引中每一个数据都进行一 一的扫描判断，也就是所谓你平常理解的使用索引查询会更快的取出数据。而要想实现这种查找，索引却是有要求的，要实现这种能快速查找的算法，索引就要满足特定的数据结构。<strong>简单说，也就是索引字段的数据必须是有序的，才能实现这种类型的查找，才能利用到索引。</strong></li></ul><p>有些了解的人可能会问，索引不都是一个有序排列的数据结构么。不过答案说的还不够完善，那只是针对单个索引，而复合索引的情况有些同学可能就不太了解了。</p><p><strong>下面就说下复合索引：</strong></p><p>以该表的<code>(name,cid)</code>复合索引为例,它内部结构简单说就是下面这样排列的：</p><p><img src="3.jpg" alt="img"></p><p>mysql创建复合索引的规则是首先会对复合索引的最左边的，也就是第一个name字段的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个的cid字段进行排序。其实就相当于实现了类似 order by name cid这样一种排序规则。</p><p>所以：<strong>第一个name字段是绝对有序的</strong>，而第二字段就是无序的了。所以通常情况下，直接使用第二个cid字段进行条件判断是用不到索引的，当然，可能会出现上面的使用index类型的索引。这就是所谓的mysql为什么要强调最左前缀原则的原因。</p><p><strong>那么什么时候才能用到呢?</strong></p><p>当然是cid字段的索引数据也是有序的情况下才能使用咯，什么时候才是有序的呢？观察可知，当然是在name字段是等值匹配的情况下，cid才是有序的。发现没有，观察两个name名字为 c 的cid字段是不是有序的呢。从上往下分别是4  5。</p><p>这也就是mysql索引规则中要求复合索引要想使用第二个索引，必须先使用第一个索引的原因。（而且<strong>第一个索引必须是等值匹配</strong>）。</p><p>-————————————————————————————————————————–</p><p>所以对于这条sql查询：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPLAIN SELECT * FROM student WHERE   cid=1 AND name=&apos;小红&apos;;</span><br></pre></td></tr></table></figure><p>没有错，而且复合索引中的两个索引字段都能很好的利用到了！因为语句中最左面的name字段进行了等值匹配，所以cid是有序的，也可以利用到索引了。</p><p><strong>你可能会问</strong>：我建的索引是(name,cid)。而我查询的语句是cid=1 AND name=’小红’; 我是先查询cid，再查询name的，不是先从最左面查的呀？</p><p>好吧，我再解释一下这个问题：首先可以肯定的是把条件判断反过来变成这样 name=’小红’ and cid=1; 最后所查询的结果是一样的。<br>那么问题产生了？既然结果是一样的，到底以何种顺序的查询方式最好呢？</p><p><strong>所以</strong>，而此时那就是我们的mysql查询优化器该登场了，mysql查询优化器会判断纠正这条sql语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。所以，当然是我们能尽量的利用到索引时的查询顺序效率最高咯，所以mysql查询优化器会最终以这种顺序进行查询执行。</p><p>在最左前缀匹配原则，有一个非常重要的原则：mysql会一直向右匹配直到遇到<code>范围查询</code>(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。</p><blockquote><p>作者：Jokerone_</p><p>链接：<a href="https://www.jianshu.com/p/b7911e0394b0" target="_blank" rel="noopener">https://www.jianshu.com/p/b7911e0394b0</a></p><p>来源：简书简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;转载自：&lt;a href=&quot;https://www.zhihu.com/question/36996520/answer/93256153&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;mysql索引最左匹配原则的理解?&lt;/a&gt;&lt;br&gt;作者：沈杰&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;下面是一个表结构，有三个字段，分别是&lt;code&gt;id,name,cid&lt;/code&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;CREATE TABLE `student` (&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `id` int(11) NOT NULL AUTO_INCREMENT,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `name` varchar(255) DEFAULT NULL,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  `cid` int(11) DEFAULT NULL,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  PRIMARY KEY (`id`),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;  KEY `name_cid_INX` (`name`,`cid`),&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=utf8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;p&gt;索引方面：&lt;code&gt;id&lt;/code&gt;是主键，&lt;code&gt;(name,cid)&lt;/code&gt;是一个多列索引。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://changsk.top/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="Mysql" scheme="http://changsk.top/tags/Mysql/"/>
    
      <category term="最左匹配原则" scheme="http://changsk.top/tags/%E6%9C%80%E5%B7%A6%E5%8C%B9%E9%85%8D%E5%8E%9F%E5%88%99/"/>
    
  </entry>
  
  <entry>
    <title>Collaborative-Filtering协同过滤详解</title>
    <link href="http://changsk.top/2019/06/27/Collaborative-Filtering/"/>
    <id>http://changsk.top/2019/06/27/Collaborative-Filtering/</id>
    <published>2019-06-27T12:11:58.000Z</published>
    <updated>2019-06-27T13:25:18.482Z</updated>
    
    <content type="html"><![CDATA[<h1 id="基本思想"><a href="#基本思想" class="headerlink" title="基本思想"></a>基本思想</h1><p><code>基于用户的协同过滤算法</code>是通过用户的<code>历史行为数据</code>发现用户对商品或内容的喜欢(如商品<strong>购买</strong>，<strong>收藏</strong>，<strong>内容评论</strong>或<strong>分享</strong>)，并对这些喜好进行度量和<strong>打分</strong>。根据不同用户对相同商品或内容的态度和偏好程度计算用户之间的关系。在有相同喜好的用户间进行商品推荐。简单的说就是如果A,B两个用户都购买了x、y、z三本图书，并且给出了5星的好评。那么A和B就属于同一类用户。可以将A看过的图书w也推荐给用户B。</p> <a id="more"></a><p><img src="1.jpg" alt></p><p><strong>基于用户协同过滤算法的原理图</strong></p><p>所以，协同过滤算法主要分为两个步骤：</p><p>1、寻找相似的用户集合；</p><p>2、寻找集合中用户喜欢的且目标用户没有的进行推荐。</p><h1 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h1><h2 id="寻找用户间的相似度"><a href="#寻找用户间的相似度" class="headerlink" title="寻找用户间的相似度"></a>寻找用户间的相似度</h2><h3 id="Jaccard公式"><a href="#Jaccard公式" class="headerlink" title="Jaccard公式"></a>Jaccard公式</h3><p><code>Jaccard</code>系数主要用于计算符号度量或布尔值度量的个体间的相似度，因为个体的特征属性都是由符号度量或者布尔值标识，因此无法衡量差异具体值的大小，只能获得“是否相同”这个结果，所以<code>Jaccard系数只关心个体间共同具有的特征是否一致</code>这个问题。如果比较X与Y的Jaccard相似系数，只比较xn和yn中相同的个数。</p><p> <img src="2.jpg" alt></p><p><strong>Jaccard公式</strong></p><h3 id="皮尔逊相关系数"><a href="#皮尔逊相关系数" class="headerlink" title="皮尔逊相关系数"></a>皮尔逊相关系数</h3><p>皮尔逊相关系统是比欧几里德距离更加复杂的可以判断人们兴趣相似度的一种方法。<code>它在数据不是很规范时，会倾向于给出更好的结果。</code><br>假定有两个变量X、Y，那么两变量间的皮尔逊相关系数可通过以下公式计算：</p><p>公式一：</p><p><img src="3.jpg" alt></p><p>皮尔逊相关系数公式一<br>公式二：</p><p><img src="4.jpg" alt></p><p>皮尔逊相关系数公式二<br>公式三：</p><p><img src="5.jpg" alt></p><p>皮尔逊相关系数公式三<br>公式四：</p><p><img src="6.jpg" alt></p><p>皮尔逊相关系数公式四</p><blockquote><p>上述四个公式等价，其中E是数学期望，cov表示协方差，N表示变量取值的个数。</p></blockquote><h3 id="欧几里德距离"><a href="#欧几里德距离" class="headerlink" title="欧几里德距离"></a>欧几里德距离</h3><p>假定两个用户X、Y，均为n维向量，表示用户对n个商品的评分，那么X与Y的欧几里德距离就是：</p><p> <img src="7.jpg" alt></p><p>多维欧几里德距离公式<br>数值越小则代表相似度越高，但是对于不同的n，计算出来的距离不便于控制，所以需要进行如下转换：</p><p> <img src="8.jpg" alt></p><p>相似度公式<br>使得结果分布在(0,1]上，数值越大，相似度越高。</p><h3 id="余弦距离"><a href="#余弦距离" class="headerlink" title="余弦距离"></a>余弦距离</h3><p><code>余弦距离</code>，也称为<code>余弦相似度</code>，是用向量空间中两个向量余弦值作为衡量两个个体间差异大小的度量值。</p><p>与前面的欧几里德距离相似，用户X、Y为两个n维向量，套用余弦公式，其余弦距离表示为：</p><p> <img src="8.jpg" alt></p><p>余弦距离公式<br>即两个向量夹角的余弦值。但是相比欧式距离，余弦距离更加注意两个向量在方向上的相对差异，而不是在空间上的绝对距离，具体可以借助下图来感受两者间的区别：</p><p> <img src="10.jpg" alt></p><p>余弦距离与欧式距离的区别</p><h2 id="推荐物品"><a href="#推荐物品" class="headerlink" title="推荐物品"></a>推荐物品</h2><p>在选取上述方法中的一种得到各个<code>用户相似度</code>后，针对目标用户u，我们<strong>选出最相似的k个用户</strong>，用集合S(u,k)表示，<code>将S中所有用户喜欢的物品提取出来并去除目标用户u已经喜欢的物品</code>。然后对余下的物品进行评分与相似度加权，得到的结果进行排序。最后由排序结果对目标用户u进行推荐。其中，对于每个可能推荐的物品i，用户u对其的感兴趣的程度可以用如下公式计算：</p><p> <img src="11.jpg" alt></p><p>用户u对物品i感兴趣的程度<br>rvi表示用户v对i的喜欢程度，即对i的评分，wuv表示用户u和v之间的相似度。</p><h2 id="收集用户偏好"><a href="#收集用户偏好" class="headerlink" title="收集用户偏好"></a>收集用户偏好</h2><p>要从<code>用户的行为和偏好</code>中发现规律，并基于此给予推荐，<strong>如何收集用户的偏好信息成为系统推荐效果最基础的决定因素</strong>。用户有很多方式向系统提供自己的偏好信息，而且不同的应用也可能大不相同，下面举例进行介绍：</p><p><strong>表 1 用户行为和用户偏好</strong></p><table><thead><tr><th>用户行为</th><th align="center">类型</th><th>特征</th><th>作用</th></tr></thead><tbody><tr><td>评分</td><td align="center">显式</td><td>整数量化的偏好，可能的取值是 [0, n]；n 一般取值为 5 或者是 10</td><td>通过用户对物品的评分，可以精确的得到用户的偏好</td></tr><tr><td>投票</td><td align="center">显式</td><td>布尔量化的偏好，取值是 0 或 1</td><td>通过用户对物品的投票，可以较精确的得到用户的偏好</td></tr><tr><td>转发</td><td align="center">显式</td><td>布尔量化的偏好，取值是 0 或 1</td><td>通过用户对物品的投票，可以精确的得到用户的偏好,如果是站内，同时可以推理得到被转发人的偏好（不精确）</td></tr><tr><td>保存书签</td><td align="center">显示</td><td>布尔量化的偏好，取值是 0 或 1</td><td>通过用户对物品的投票，可以精确的得到用户的偏好</td></tr><tr><td>标记标签(Tag)</td><td align="center">显示</td><td>一些单词，需要对单词进行分析，得到偏好</td><td>通过分析用户的标签，可以得到用户对项目的理解，同时可以分析出用户的情感：喜欢还是讨厌</td></tr><tr><td>评论</td><td align="center">显示</td><td>一段文字，需要进行文本分析，得到偏好</td><td>通过分析用户的评论，可以得到用户的情感：喜欢还是讨厌</td></tr><tr><td>点击流( 查看 )</td><td align="center">隐式</td><td>一组用户的点击，用户对物品感兴趣，需要进行分析，得到偏好</td><td>用户的点击一定程度上反映了用户的注意力，所以它也可以从一定程度上反映用户的喜好</td></tr><tr><td>页面停留时间</td><td align="center">隐式</td><td>一组时间信息，噪音大，需要进行去噪，分析，得到偏好</td><td>用户的页面停留时间一定程度上反映了用户的注意力和喜好，但噪音偏大，不好利用</td></tr><tr><td>购买</td><td align="center">隐式</td><td>布尔量化的偏好，取值是 0 或 1</td><td>用户的购买是很明确的说明这个项目它感兴趣</td></tr></tbody></table><p>以上列举的用户行为都是比较通用的，推荐引擎设计人员可以根据自己应用的特点添加特殊的用户行为，并用他们表示用户对物品的喜好|</p><p>在一般应用中，我们提取的用户行为一般都多于一种，关于如何组合这些不同的用户行为，基本上有以下两种方式：</p><ul><li>将不同的行为分组：一般可以分为“<strong>查看</strong>”和“<strong>购买</strong>”等等，然后基于不同的行为，计算不同的用户 / 物品相似度。类似于当当网或者 Amazon 给出的“<code>购买了该图书的人还购买了 …</code>”，“<code>查看了图书的人还查看了 …</code>”</li><li>根据不同行为反映用户喜好的程度将它们进行<strong>加权</strong>，得到用户对于物品的总体喜好。一般来说，<strong>显式的用户反馈比隐式的权值大</strong>，<strong>但比较稀疏，毕竟进行显示反馈的用户是少数；同时相对于“查看”，“购买”行为反映用户喜好的程度更大，但这也因应用而异。</strong></li></ul><p>收集了用户行为数据，我们还需要对数据进行一定的预处理，其中最核心的工作就是：<strong>减噪</strong>和<strong>归一化</strong>。</p><ul><li>减噪：用户行为数据是用户在使用应用过程中产生的，它可能存在大量的噪音和<strong>用户的误操作</strong>，我们可以<strong>通过经典的数据挖掘算法过滤掉行为数据中的噪音</strong>，这样可以是我们的分析更加精确。</li><li>归一化：如前面讲到的，在<code>计算用户对物品的喜好程度时，可能需要对不同的行为数据进行加权</code>。但可以想象，<code>不同行为的数据取值可能相差很大</code>，比如，<code>用户的查看数据必然比购买数据大的多</code>，<strong>如何将各个行为的数据统一在一个相同的取值范围中</strong>，从而使得加权求和得到的总体喜好更加精确，就需要我们进行归一化处理。最简单的归一化处理，就是将<strong>各类数据除以此类中的最大值</strong>，以保证归一化后的数据取值在 [0,1] 范围中</li></ul><p>进行了预处理后，根据不同应用的行为分析方法，可以选择分组或者加权处理，之后我们可以得到一个用户偏好的二维矩阵，一维是用户列表，另一维是物品列表，值是用户对物品的偏好，一般是 [0,1] 或者 [-1, 1] 的浮点数值。</p><h2 id="基于用户的-CF（User-CF）"><a href="#基于用户的-CF（User-CF）" class="headerlink" title="基于用户的 CF（User CF）"></a>基于用户的 CF（User CF）</h2><p>基于用户的协同过滤(user-basedCF)是基于这样一个事实：<code>每个用户都有与其具有相似兴趣爱好和购买行为的用户群，这些相似用户(邻居用户)的购买项目可以作为对当前用户(目标用户)进行项目推荐的基础。因此，这种方法也被称为基于邻居的协同过滤或最近邻居算法。</code></p><p>基于用户的 CF 的基本思想相当简单，<code>基于用户对物品的偏好找到相邻邻居用户，然后将邻居用户喜欢的推荐给当前用户</code>。计算上，<strong>就是将一个用户对所有物品的偏好作为一个向量来计算用户之间的相似度，找到 K 邻居后，根据邻居的相似度权重以及他们对物品的偏好，预测当前用户没有偏好的未涉及物品，计算得到一个排序的物品列表作为推荐</strong>。图 2 给出了一个例子，对于用户 A，根据用户的历史偏好，这里只计算得到一个邻居 – 用户 C，然后将用户 C 喜欢的物品 D 推荐给用户 A。</p><p><img src="12.jpg" alt></p><p>图 2 基于用户的 CF 的基本原理</p><h2 id="基于物品的-CF（Item-CF）"><a href="#基于物品的-CF（Item-CF）" class="headerlink" title="基于物品的 CF（Item CF）"></a>基于物品的 CF（Item CF）</h2><p>基于物品的 CF 的原理和基于用户的 CF 类似，<code>只是在计算邻居时采用物品本身，而不是从用户的角度，即基于用户对物品的偏好找到相似的物品，然后根据用户的历史偏好，推荐相似的物品给他</code>。从计算的角度看，<strong>就是将所有用户对某个物品的偏好作为一个向量来计算物品之间的相似度，得到物品的相似物品后，根据用户历史的偏好预测当前用户还没有表示偏好的物品，计算得到一个排序的物品列表作为推荐</strong>。图 3 给出了一个例子，对于物品 A，根据所有用户的历史偏好，喜欢物品 A 的用户都喜欢物品 C，得出物品 A 和物品 C 比较相似，而用户 C 喜欢物品 A，那么可以推断出用户 C 可能也喜欢物品 C。</p><p>基于物品的协同过滤的一个优点是容易解释推荐原因，第二个是电商网站中<strong>物品的相似度是相对不变的</strong>，<strong>物品相似度的矩阵维护起来相对容易。</strong></p><p><img src="13.jpg" alt></p><p>图 3 基于物品的 CF 的基本原理</p><h2 id="User-CF-vs-Item-CF"><a href="#User-CF-vs-Item-CF" class="headerlink" title="User CF vs. Item CF"></a>User CF vs. Item CF</h2><p>前面介绍了<code>User CF</code> 和<code>Item CF</code> 的基本原理，下面我们分几个不同的角度深入看看它们各自的优缺点和适用场景：</p><h3 id="计算复杂度"><a href="#计算复杂度" class="headerlink" title="计算复杂度"></a>计算复杂度</h3><p>Item CF 和 User CF 是基于协同过滤推荐的两个最基本的算法，User CF 是很早以前就提出来了，Item CF 是从 Amazon 的论文和专利发表之后（2001 年左右）开始流行，大家都觉得 Item CF 从性能和复杂度上比 User CF 更优，其中的一个主要原因就是对于一个在线网站，<code>用户的数量往往大大超过物品的数量</code>，<code>同时物品的数据相对稳定</code>，<strong>因此计算物品的相似度不但计算量较小，同时也不必频繁更新</strong>。但我们往往忽略了这种情况只适应于提供商品的电子商务网站，<strong>对于新闻，博客或者微内容的推荐系统，情况往往是相反的，物品的数量是海量的，同时也是更新频繁的，所以单从复杂度的角度，这两个算法在不同的系统中各有优势，推荐引擎的设计者需要根据自己应用的特点选择更加合适的算法。</strong></p><h3 id="适用场景"><a href="#适用场景" class="headerlink" title="适用场景"></a>适用场景</h3><p>在非社交网络的网站中，内容内在的联系是很重要的推荐原则，它比基于相似用户的推荐原则更加有效。比如在购书网站上，当你看一本书的时候，推荐引擎会给你推荐相关的书籍，这个推荐的重要性远远超过了网站首页对该用户的综合推荐。可以看到，在这种情况下，Item CF 的推荐成为了引导用户浏览的重要手段。同时 Item CF 便于为推荐做出解释，<strong>在一个非社交网络的网站中，给某个用户推荐一本书，同时给出的解释是某某和你有相似兴趣的人也看了这本书，这很难让用户信服，因为用户可能根本不认识那个人；但如果解释说是因为这本书和你以前看的某本书相似，用户可能就觉得合理而采纳了此推荐。</strong></p><p><strong>相反的，在现今很流行的社交网络站点中，User CF 是一个更不错的选择，User CF 加上社会网络信息，可以增加用户对推荐解释的信服程度。</strong></p><h3 id="推荐多样性和精度"><a href="#推荐多样性和精度" class="headerlink" title="推荐多样性和精度"></a>推荐多样性和精度</h3><p>研究推荐引擎的学者们在相同的数据集合上分别用 <code>User CF</code> 和<code>Item CF</code>计算推荐结果，发现推荐列表中，只有 50% 是一样的，还有 50% 完全不同。但是这两个算法确有相似的精度，所以可以说，这两个算法是很互补的。</p><p>关于推荐的多样性，有两种度量方法：</p><ul><li><p>第一种度量方法是从单个用户的角度度量，就是说给定一个用户，查看系统给出的推荐列表是否多样，也就是要<strong>比较推荐列表中的物品之间两两的相似度</strong>，不难想到，对这种度量方法，Item CF 的多样性显然不如 User CF 的好，因为 Item CF 的推荐就是和以前看的东西最相似的。</p></li><li><p>第二种度量方法是考虑系统的多样性，也被称为覆盖率 (Coverage)，它是指<strong>一个推荐系统是否能够提供给所有用户丰富的选择</strong>。在这种指标下，Item CF 的多样性要远远好于 User CF, 因为 <strong>User CF 总是倾向于推荐热门的</strong>，从另一个侧面看，也就是说，<strong>Item CF 的推荐有很好的新颖性，很擅长推荐长尾里的物品</strong>。所以，尽管大多数情况，<strong>Item CF 的精度略小于 User CF， 但如果考虑多样性，Item CF 却比 User CF 好很多。</strong></p></li></ul><p>如果你对推荐的多样性还心存疑惑，那么下面我们再举个实例看看 User CF 和 Item CF 的多样性到底有什么差别。首先，假设每个用户兴趣爱好都是广泛的，喜欢好几个领域的东西，不过每个用户肯定也有一个主要的领域，对这个领域会比其他领域更加关心。给定一个用户，假设他喜欢 3 个领域 A,B,C，A 是他喜欢的主要领域，这个时候我们来看 User CF 和 Item CF 倾向于做出什么推荐：如果用 User CF, 它会将 A,B,C 三个领域中比较热门的东西推荐给用户；而如果用 ItemCF，它会基本上只推荐 A 领域的东西给用户。所以我们看到<strong>因为 User CF 只推荐热门的</strong>，<strong>所以它在推荐长尾里项目方面的能力不足</strong>；而 Item CF 只推荐 A 领域给用户，这样他有限的推荐列表中就可能包含了一定数量的不热门的长尾物品，同时 Item CF 的推荐对这个用户而言，显然多样性不足。但是对整个系统而言，因为不同的用户的主要兴趣点不同，所以系统的覆盖率会比较好。</p><blockquote><p>从人们需求的角度来看，大多数的需求会集中在头部，而这部分我们可以称之为流行，而分布在尾部的需求是个性化的，零散的小量的需求。而这部分差异化的、少量的需求会在<a href="https://baike.baidu.com/item/需求曲线/3351682" target="_blank" rel="noopener">需求曲线</a>上面形成一条长长的“尾巴”，而所谓长尾效应就在于它的数量上，将所有非流行的市场累加起来就会形成一个比流行市场还大的市场。</p></blockquote><p>从上面的分析，可以很清晰的看到，这两种推荐都有其合理性，但都不是最好的选择，因此他们的精度也会有损失。其实对这类系统的最好选择是，如果系统给这个用户推荐 30 个物品，既不是每个领域挑选 10 个最热门的给他，也不是推荐 30 个 A 领域的给他，而是比如推荐 15 个 A 领域的给他，剩下的 15 个从 B,C 中选择。所以<code>结合 User CF 和 Item CF 是最优的选择</code>，结合的基本原则就是<strong>当采用 Item CF 导致系统对个人推荐的多样性不足时，我们通过加入 User CF 增加个人推荐的多样性，从而提高精度，而当因为采用 User CF 而使系统的整体多样性不足时，我们可以通过加入 Item CF 增加整体的多样性，同样同样可以提高推荐的精度。</strong></p><h3 id="用户对推荐算法的适应度"><a href="#用户对推荐算法的适应度" class="headerlink" title="用户对推荐算法的适应度"></a>用户对推荐算法的适应度</h3><p>前面我们大部分都是从推荐引擎的角度考虑哪个算法更优，但其实我们更多的应该考虑作为推荐引擎的最终使用者 — 应用用户对推荐算法的适应度。</p><p><strong>对于 User CF，推荐的原则是假设用户会喜欢那些和他有相同喜好的用户喜欢的东西，但如果一个用户没有相同喜好的朋友，那 User CF 的算法的效果就会很差，所以一个用户对的 CF 算法的适应度是和他有多少共同喜好用户成正比的。</strong></p><p><strong>Item CF 算法也有一个基本假设，就是用户会喜欢和他以前喜欢的东西相似的东西，那么我们可以计算一个用户喜欢的物品的自相似度。一个用户喜欢物品的自相似度大，就说明他喜欢的东西都是比较相似的，也就是说他比较符合 Item CF 方法的基本假设，那么他对 Item CF 的适应度自然比较好；反之，如果自相似度小，就说明这个用户的喜好习惯并不满足 Item CF 方法的基本假设，那么对于这种用户，用 Item CF 方法做出好的推荐的可能性非常低。</strong></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><table><thead><tr><th></th><th>UserCF</th><th>ItemCF</th></tr></thead><tbody><tr><td>性能</td><td>适用于用户较少的场合，如果用户很多，计算用户相似度矩阵代价很大</td><td>适用于物品数明显小于用户数的场合，如果物品很多（网页），计算物品相似度矩阵代价很大</td></tr><tr><td>领域</td><td>时效性较强，用户个性化兴趣不太明显的领域</td><td>长尾物品丰富，用户个性化需求强烈的领域</td></tr><tr><td>实时性</td><td>用户有新行为，不一定造成推荐结果的立即变化</td><td>用户有新行为，一定会导致推荐结果的实时变化</td></tr><tr><td>冷启动</td><td>在新用户对很少的物品产生行为后，不能立即对他进行个性化推荐，因为用户相似度表是每隔一段时间离线计算的</td><td>新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品</td></tr><tr><td></td><td>新物品上线后一段时间，一旦有用户对物品产生行为，就可以将新物品推荐给和对它产生行为的用户兴趣相似的其他用户</td><td>但没有办法在不离线更新物品相似度表的情况下将新物品推荐给用户</td></tr><tr><td>推荐理由</td><td>很难提供令用户信服的推荐解释</td><td>利用用户的历史行为给用户做推荐解释，可以令用户比较信服</td></tr></tbody></table><h2 id="矩阵分解"><a href="#矩阵分解" class="headerlink" title="矩阵分解　　　　　　　　　　　　"></a>矩阵分解　　　　　　　　　　　　</h2><p>Spark推荐模型库当前只包含基于矩阵分解（matrix factorization）的实现，由此我们也将重点关注这类模型。它们有吸引人的地方。首先，这些模型在协同过滤中的表现十分出色。而在Netflix Prize等知名比赛中的表现也很拔尖</p><h3 id="显式矩阵分解"><a href="#显式矩阵分解" class="headerlink" title="显式矩阵分解　　　　"></a>显式矩阵分解　　　　</h3><p>要找到和“用户物品”矩阵近似的k维（低阶）矩阵，最终要求出如下两个矩阵：一个用于表示用户的U × k维矩阵，以及一个表征物品的I × k维矩阵。</p><p>这两个矩阵也称作因子矩阵。它们的乘积便是原始评级矩阵的一个近似。值得注意的是，原始评级矩阵通常很稀疏，但因子矩阵却是稠密的。</p><p>特点：因子分解类模型的好处在于，一旦建立了模型，对推荐的求解便相对容易。但也有弊端，即当用户和物品的数量很多时，其对应的物品或是用户的因子向量可能达到数以百万计。</p><p>这将在存储和计算能力上带来挑战。另一个好处是，这类模型的表现通常都很出色。</p><h3 id="隐式矩阵分解（关联因子分确定，可能随时会变化）"><a href="#隐式矩阵分解（关联因子分确定，可能随时会变化）" class="headerlink" title="隐式矩阵分解（关联因子分确定，可能随时会变化）"></a>隐式矩阵分解（关联因子分确定，可能随时会变化）</h3><p>隐式模型仍然会创建一个用户因子矩阵和一个物品因子矩阵。但是，模型所求解的是偏好矩阵而非评级矩阵的近似。类似地，此时用户因子向量和物品因子向量的点积所得到的分数</p><p>也不再是一个对评级的估值，而是对某个用户对某一物品偏好的估值（该值的取值虽并不严格地处于0到1之间，但十分趋近于这个区间）</p><h3 id="最小二乘法（Alternating-Least-Squares-ALS）：解决矩阵分解的最优化方法"><a href="#最小二乘法（Alternating-Least-Squares-ALS）：解决矩阵分解的最优化方法" class="headerlink" title="最小二乘法（Alternating Least Squares    ALS）：解决矩阵分解的最优化方法"></a>最小二乘法（Alternating Least Squares    ALS）：解决矩阵分解的最优化方法</h3><p><code>ALS</code>的实现原理是迭代式求解一系列最小二乘回归问题。在每一次迭代时，固定用户因子矩阵或是物品因子矩阵中的一个，然后用固定的这个矩阵以及评级数据来更新另一个矩阵。</p><p>之后，被更新的矩阵被固定住，再更新另外一个矩阵。如此迭代，<strong>直到模型收敛（或是迭代了预设好的次数）。</strong></p><blockquote><p>参考：<br><a href="https://www.cnblogs.com/ECJTUACM-873284962/p/8729010.html" target="_blank" rel="noopener">Collaborative Filtering(协同过滤)算法详解</a><br><a href="https://www.imooc.com/article/39466" target="_blank" rel="noopener">协同过滤算法：基于用户和基于物品的优缺点比较</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;基本思想&quot;&gt;&lt;a href=&quot;#基本思想&quot; class=&quot;headerlink&quot; title=&quot;基本思想&quot;&gt;&lt;/a&gt;基本思想&lt;/h1&gt;&lt;p&gt;&lt;code&gt;基于用户的协同过滤算法&lt;/code&gt;是通过用户的&lt;code&gt;历史行为数据&lt;/code&gt;发现用户对商品或内容的喜欢(如商品&lt;strong&gt;购买&lt;/strong&gt;，&lt;strong&gt;收藏&lt;/strong&gt;，&lt;strong&gt;内容评论&lt;/strong&gt;或&lt;strong&gt;分享&lt;/strong&gt;)，并对这些喜好进行度量和&lt;strong&gt;打分&lt;/strong&gt;。根据不同用户对相同商品或内容的态度和偏好程度计算用户之间的关系。在有相同喜好的用户间进行商品推荐。简单的说就是如果A,B两个用户都购买了x、y、z三本图书，并且给出了5星的好评。那么A和B就属于同一类用户。可以将A看过的图书w也推荐给用户B。&lt;/p&gt;
    
    </summary>
    
      <category term="推荐算法" scheme="http://changsk.top/categories/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
    
      <category term="协同过滤" scheme="http://changsk.top/tags/%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4/"/>
    
      <category term="推荐算法" scheme="http://changsk.top/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>初识ElasticSearch</title>
    <link href="http://changsk.top/2019/06/27/es-introduce/"/>
    <id>http://changsk.top/2019/06/27/es-introduce/</id>
    <published>2019-06-27T08:15:31.000Z</published>
    <updated>2019-06-27T09:05:46.560Z</updated>
    
    <content type="html"><![CDATA[<h1 id="没有ES之前"><a href="#没有ES之前" class="headerlink" title="没有ES之前"></a>没有ES之前</h1><h2 id="思考：大规模数据如何检索？"><a href="#思考：大规模数据如何检索？" class="headerlink" title="思考：大规模数据如何检索？"></a>思考：大规模数据如何检索？</h2><p>当系统数据量上了10亿、100亿条的时候，我们在做系统架构的时候通常会从以下角度去考虑问题：<br>1）用什么数据库好？(mysql、sybase、oracle、达梦、神通、mongodb、hbase…)<br>2）如何解决单点故障；(lvs、F5、A10、Zookeeper、MQ)<br>3）如何保证数据安全性；(热备、冷备、异地多活)<br>4）如何解决检索难题；(数据库代理中间件：mysql-proxy、Cobar、MaxScale等;)<br>5）如何解决统计分析问题；(离线、近实时)</p><a id="more"></a><h2 id="传统数据库的应对解决方案"><a href="#传统数据库的应对解决方案" class="headerlink" title="传统数据库的应对解决方案"></a>传统数据库的应对解决方案</h2><p>对于关系型数据，我们通常采用以下或类似架构去解决查询瓶颈和写入瓶颈：<br>解决要点：<br>1）<strong>通过主从备份解决数据安全性问题；</strong><br>2）<strong>通过数据库代理中间件心跳监测，解决单点故障问题；</strong><br>3）<strong>通过代理中间件将查询语句分发到各个slave节点进行查询，并汇总结果</strong><br><img src="1.jpg" alt="这里写图片描述"></p><h2 id="非关系型数据库的解决方案"><a href="#非关系型数据库的解决方案" class="headerlink" title="非关系型数据库的解决方案"></a>非关系型数据库的解决方案</h2><p>对于Nosql数据库，以mongodb为例，其它原理类似：<br>解决要点：<br>1）<strong>通过副本备份保证数据安全性；</strong><br>2）<strong>通过节点竞选机制解决单点问题；</strong><br>3）<strong>先从配置库检索分片信息，然后将请求分发到各个节点，最后由路由节点合并汇总结果</strong><br><img src="2.jpg" alt="这里写图片描述"></p><h2 id="另辟蹊径——完全把数据放入内存怎么样？"><a href="#另辟蹊径——完全把数据放入内存怎么样？" class="headerlink" title="另辟蹊径——完全把数据放入内存怎么样？"></a>另辟蹊径——完全把数据放入内存怎么样？</h2><p>我们知道，完全把数据放在内存中是不可靠的，实际上也不太现实，当我们的数据达到PB级别时，按照每个节点96G内存计算，在内存完全装满的数据情况下，我们需要的机器是：1PB=1024T=1048576G<br>节点数=1048576/96=10922个<br>实际上，考虑到数据备份，节点数往往在2.5万台左右。成本巨大决定了其不现实！</p><p>从前面讨论我们了解到，把数据放在内存也好，不放在内存也好，都不能完完全全解决问题。<br>全部放在内存速度问题是解决了，但成本问题上来了。<br>为解决以上问题，从源头着手分析，通常会从以下方式来寻找方法：<br>1、存储数据时按有序存储；<br>2、将数据和索引分离；<br>3、压缩数据；<br>这就引出了Elasticsearch。</p><h1 id="Elasticsearch的概述"><a href="#Elasticsearch的概述" class="headerlink" title="Elasticsearch的概述"></a>Elasticsearch的概述</h1><h2 id="Elasticsearch-是什么"><a href="#Elasticsearch-是什么" class="headerlink" title="Elasticsearch 是什么"></a>Elasticsearch 是什么</h2><p>Elasticsearch（ES）是一个基于<code>Lucene</code>构建的<strong>开源</strong>、<strong>分布式</strong>、<strong>RESTful接口</strong>的<strong>全文搜索引擎</strong>。Elasticsearch还是一个<strong>分布式文档数据库</strong>，其中<strong>每个字段均可被索引</strong>，而且<strong>每个字段的数据均可被搜索</strong>，ES能够横向扩展至数以百计的服务器存储以及处理PB级的数据。可以在极短的时间内存储、搜索和分析大量的数据。通常作为具有复杂搜索场景情况下的核心发动机。Elasticsearch也使用Java开发并使用<code>Lucene</code>作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的<code>RESTful API</code>来<strong>隐藏Lucene的复杂性</strong>，从而让全文搜索变得简单。</p><p><img src="3.jpg" alt></p><p>ElasticSearch就是为<code>高可用</code>和<code>可扩展</code>而生的。可以通过购置性能更强的服务器或者升级硬件来完成系统扩展，称为<strong>垂直或向上扩展</strong>（Vertical Scale/Scaling Up）。另一方面，增加更多的服务器来完成系统扩展，称为<strong>水平扩展或者向外扩展</strong>（Horizontal Scale/Scaling Out）。尽管ES能够利用更强劲的硬件，垂直扩展毕竟还是有它的极限。真正的可扩展性来自于水平扩展，通过向集群中添加更多的节点来分担负载，增加可靠性。ES天生就是分布式的：它知道如何管理多个节点来完成扩展和实现高可用性。这也意味你的应用不需要做任何的改动。</p><h2 id="Lucene与ES关系"><a href="#Lucene与ES关系" class="headerlink" title="Lucene与ES关系"></a>Lucene与ES关系</h2><ol><li>Lucene只是一个库。想要使用它，你必须使用Java来作为开发语言并将其直接集成到你的应用中，更糟糕的是，Lucene非常复杂，你需要深入了解检索的相关知识来理解它是如何工作的。</li><li>Elasticsearch也使用Java开发并使用Lucene作为其核心来实现所有索引和搜索的功能，但是它的目的是通过简单的RESTful API来隐藏Lucene的复杂性，从而让全文搜索变得简单。</li></ol><h2 id="ES主要解决问题"><a href="#ES主要解决问题" class="headerlink" title="ES主要解决问题"></a>ES主要解决问题</h2><p>1）检索相关数据；<br>2）返回统计结果；<br>3）速度要快。</p><h2 id="ES工作原理"><a href="#ES工作原理" class="headerlink" title="ES工作原理"></a>ES工作原理</h2><p>当ElasticSearch的节点启动后，它会利用多播(multicast)(或者单播，如果用户更改了配置)寻找集群中的其它节点，并与之建立连接。这个过程如下图所示：<br><img src="4.jpg" alt="这里写图片描述"></p><h2 id="ES数据架构的主要概念（与关系数据库Mysql对比）"><a href="#ES数据架构的主要概念（与关系数据库Mysql对比）" class="headerlink" title="ES数据架构的主要概念（与关系数据库Mysql对比）"></a>ES数据架构的主要概念（与关系数据库Mysql对比）</h2><p><img src alt="这里写图片描述"><br>（1）关系型数据库中的数据库（DataBase），等价于ES中的索引（Index）<br>（2）一个数据库下面有N张表（Table），等价于1个索引Index下面有N多类型（Type），<br>（3）一个数据库表（Table）下的数据由多行（ROW）多列（column，属性）组成，等价于1个Type由多个文档（Document）和多Field组成。<br>（4）在一个关系型数据库里面，schema定义了表、每个表的字段，还有表和字段之间的关系。 与之对应的，在ES中：Mapping定义索引下的Type的字段处理规则，即索引如何建立、索引类型、是否保存原始索引JSON文档、是否压缩原始JSON文档、是否需要分词处理、如何进行分词处理等。<br>（5）在数据库中的增insert、删delete、改update、查search操作等价于ES中的增PUT/POST、删Delete、改_update、查GET.</p><h2 id="ES核心概念"><a href="#ES核心概念" class="headerlink" title="ES核心概念"></a>ES核心概念</h2><h3 id="Near-Realtime-NRT-几乎实时"><a href="#Near-Realtime-NRT-几乎实时" class="headerlink" title="Near Realtime(NRT) 几乎实时"></a>Near Realtime(NRT) 几乎实时</h3><p>Elasticsearch是一个几乎实时的搜索平台。意思是，从索引一个文档到这个文档可被搜索只需要一点点的延迟，这个时间一般为毫秒级。</p><h3 id="Cluster：集群"><a href="#Cluster：集群" class="headerlink" title="Cluster：集群"></a>Cluster：集群</h3><p>ES可以作为一个独立的单个搜索服务器。不过，为了处理大型数据集，实现容错和高可用性，ES可以运行在许多互相合作的服务器上。这些服务器的集合称为集群。</p><p>群集是一个或多个节点（服务器）的集合， 这些节点共同保存整个数据，并在所有节点上提供联合索引和搜索功能。一个集群由一个唯一集群ID确定，并指定一个集群名（默认为“elasticsearch”）。该集群名非常重要，因为节点可以通过这个集群名加入群集，一个节点只能是群集的一部分。</p><p>确保在不同的环境中不要使用相同的群集名称，否则可能会导致连接错误的群集节点。例如，你可以使用logging-dev、logging-stage、logging-prod分别为开发、阶段产品、生产集群做记录。</p><h3 id="Node：节点"><a href="#Node：节点" class="headerlink" title="Node：节点"></a>Node：节点</h3><p>形成集群的每个服务器称为节点。</p><p>节点是单个服务器实例，它是群集的一部分，可以存储数据，并参与群集的<strong>索引</strong>和<strong>搜索</strong>功能。就像一个集群，节点的名称默认为一个随机的通用唯一标识符（UUID），确定在启动时分配给该节点。如果不希望默认，可以定义任何节点名。这个名字对管理很重要，目的是要确定你的网络服务器对应于你的ElasticSearch群集节点。</p><p>我们可以通过群集名配置节点以连接特定的群集。默认情况下，每个节点设置加入名为“<code>elasticSearch</code>”的集群。这意味着如果你启动多个节点在网络上，假设他们能发现彼此都会自动形成和加入一个名为“elasticsearch”的集群。</p><p>在单个群集中，您可以拥有尽可能多的节点。此外，如果“elasticsearch”在同一个网络中，没有其他节点正在运行，从单个节点的默认情况下会形成一个新的单节点名为”elasticsearch”的集群。</p><h3 id="Shard：分片-amp-Replia：副本"><a href="#Shard：分片-amp-Replia：副本" class="headerlink" title="Shard：分片 &amp; Replia：副本"></a>Shard：分片 &amp; Replia：副本</h3><p>索引可以存储大量的数据，这些数据可能超过单个节点的硬件限制。例如，十亿个文件占用磁盘空间1TB的单指标可能不适合对单个节点的磁盘或可能太慢服务仅从单个节点的搜索请求。</p><p>为了解决这一问题，Elasticsearch提供细分你的指标分成多个块称为分片的能力。<strong>当你创建一个索引，你可以简单地定义你想要的分片数量</strong>。每个分片本身是一个全功能的、独立的“指数”，可以托管在集群中的任何节点。</p><p>Shards分片的重要性主要体现在以下两个特征：</p><ul><li>分片允许您水平拆分或缩放内容的大小</li><li>分片允许你分配和并行操作的碎片（可能在多个节点上）从而提高性能/吞吐量</li></ul><p>这个机制中的碎片是分布式的以及其文件汇总到搜索请求是完全由ElasticSearch管理，对用户来说是透明的。</p><p>在同一个集群网络或云环境上，故障是任何时候都会出现的，拥有一个故障转移机制以防分片和结点因为某些原因离线或消失是非常有用的，并且被强烈推荐。为此，Elasticsearch允许你创建一个或多个拷贝，你的索引分片进入所谓的副本或称作复制品的分片，简称Replicas。</p><p>Replicas的重要性主要体现在以下两个特征：</p><ul><li>副本为分片或节点失败提供了高可用性。为此，需要注意的是，一个副本的分片不会分配在同一个节点作为原始的或主分片，副本是从主分片那里复制过来的。</li><li>副本允许用户扩展你的搜索量或吞吐量，因为搜索可以在所有副本上并行执行。</li></ul><blockquote><p>当有大量的文档时，由于内存的限制、磁盘处理能力不足、无法足够快的响应客户端的请求等，一个节点可能不够。这种情况下，数据可以分为较小的分片。每个分片放到不同的服务器上。<br>当你查询的索引分布在多个分片上时，ES会把查询发送给每个相关的分片，并将结果组合在一起，而应用程序并不知道分片的存在。即：这个过程对用户来说是透明的。</p><p>为提高查询吞吐量或实现高可用性，可以使用分片副本。<br>副本是一个分片的精确复制，每个分片可以有零个或多个副本。ES中可以有许多相同的分片，其中之一被选择更改索引操作，这种特殊的分片称为主分片。<br>当主分片丢失时，如：该分片所在的数据不可用时，集群将副本提升为新的主分片。</p></blockquote><h3 id="全文检索"><a href="#全文检索" class="headerlink" title="全文检索"></a>全文检索</h3><p>全文检索就是对一篇文章进行索引，可以根据关键字搜索，类似于mysql里的like语句。<br>全文索引就是把内容根据词的意义进行分词，然后分别创建索引，例如”你们的激情是因为什么事情来的” 可能会被分词成：“你们“，”激情“，“什么事情“，”来“ 等token，这样当你搜索“你们” 或者 “激情” 都会把这句搜出来。</p><h3 id="Index索引"><a href="#Index索引" class="headerlink" title="Index索引"></a>Index索引</h3><p><strong>索引是具有相似特性的文档集合</strong>。例如，可以为客户数据提供索引，为产品目录建立另一个索引，以及为订单数据建立另一个索引。索引由名称（必须全部为小写）标识，该名称用于在对其中的文档执行索引、搜索、更新和删除操作时引用索引。在单个群集中，您可以定义尽可能多的索引。</p><h3 id="Type类型"><a href="#Type类型" class="headerlink" title="Type类型"></a>Type类型</h3><p>在索引中，可以定义一个或多个类型。类型是索引的逻辑类别/分区，其语义完全取决于您。一般来说，类型定义为具有公共字段集的文档。例如，假设你运行一个博客平台，并将所有数据存储在一个索引中。在这个索引中，您可以为用户数据定义一种类型，为博客数据定义另一种类型，以及为注释数据定义另一类型。</p><h3 id="Document文档"><a href="#Document文档" class="headerlink" title="Document文档"></a>Document文档</h3><p><strong>文档是可以被索引的信息的基本单位</strong>。例如，您可以为单个客户提供一个文档，单个产品提供另一个文档，以及单个订单提供另一个文档。本文件的表示形式为JSON（JavaScript Object Notation）格式，这是一种非常普遍的互联网数据交换格式。</p><p>在索引/类型中，您可以存储尽可能多的文档。请注意，尽管文档物理驻留在索引中，文档实际上必须索引或分配到索引中的类型。</p><h2 id="Elasticsearch可以做什么"><a href="#Elasticsearch可以做什么" class="headerlink" title="Elasticsearch可以做什么?"></a>Elasticsearch可以做什么?</h2><p>当你经营一家网上商店，你可以让你的客户搜索你卖的商品。在这种情况下，你可以使用ElasticSearch来存储你的整个产品目录和库存信息，为客户提供精准搜索，可以为客户推荐相关商品。</p><p>当你想收集日志或者交易数据的时候，需要分析和挖掘这些数据，寻找趋势，进行统计，总结，或发现异常。在这种情况下，你可以使用Logstash或者其他工具来进行收集数据，当这引起数据存储到ElasticsSearch中。你可以搜索和汇总这些数据，找到任何你感兴趣的信息。</p><p>对于程序员来说，比较有名的案例是<strong>GitHub</strong>，GitHub的搜索是基于ElasticSearch构建的，在github.com/search页面，你可以搜索项目、用户、issue、pull request，还有代码。共有40~50个索引库，分别用于索引网站需要跟踪的各种数据。虽然只索引项目的主分支（master），但这个数据量依然巨大，包括20亿个索引文档，30TB的索引文件。</p><h2 id="ELK是什么？"><a href="#ELK是什么？" class="headerlink" title="ELK是什么？"></a>ELK是什么？</h2><p><code>ELK=elasticsearch+Logstash+kibana</code><br>elasticsearch：<strong>后台分布式存储以及全文检索</strong><br>logstash: 日志加工、“搬运工”<br>kibana：数据可视化展示。<br>ELK架构为数据分布式存储、可视化查询和日志解析创建了一个功能强大的管理链。 三者相互配合，取长补短，共同完成分布式大数据处理工作。</p><h1 id="ES特点和优势"><a href="#ES特点和优势" class="headerlink" title="ES特点和优势"></a>ES特点和优势</h1><p>1）<strong>分布式实时文件存储</strong>，可将每一个字段存入索引，使其可以被检索到。<br>2）实时分析的分布式搜索引擎。 </p><blockquote><p>分布式：索引分拆成多个分片，每个分片可有零个或多个副本。集群中的每个数据节点都可承载一个或多个分片，并且协调和处理各种操作；<br>负载再平衡和路由在大多数情况下自动完成。 </p></blockquote><p>3）可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。也可以运行在单台PC上（已测试）<br>4）支持插件机制，分词插件、同步插件、Hadoop插件、可视化插件等。</p><blockquote><p>参考：<br><a href="https://blog.csdn.net/makang110/article/details/80596017" target="_blank" rel="noopener">Elasticsearch学习，请先看这一篇！</a><br><a href="https://blog.csdn.net/deliciousion/article/details/78050251" target="_blank" rel="noopener">ElasticSearch介绍和基本概念</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;没有ES之前&quot;&gt;&lt;a href=&quot;#没有ES之前&quot; class=&quot;headerlink&quot; title=&quot;没有ES之前&quot;&gt;&lt;/a&gt;没有ES之前&lt;/h1&gt;&lt;h2 id=&quot;思考：大规模数据如何检索？&quot;&gt;&lt;a href=&quot;#思考：大规模数据如何检索？&quot; class=&quot;headerlink&quot; title=&quot;思考：大规模数据如何检索？&quot;&gt;&lt;/a&gt;思考：大规模数据如何检索？&lt;/h2&gt;&lt;p&gt;当系统数据量上了10亿、100亿条的时候，我们在做系统架构的时候通常会从以下角度去考虑问题：&lt;br&gt;1）用什么数据库好？(mysql、sybase、oracle、达梦、神通、mongodb、hbase…)&lt;br&gt;2）如何解决单点故障；(lvs、F5、A10、Zookeeper、MQ)&lt;br&gt;3）如何保证数据安全性；(热备、冷备、异地多活)&lt;br&gt;4）如何解决检索难题；(数据库代理中间件：mysql-proxy、Cobar、MaxScale等;)&lt;br&gt;5）如何解决统计分析问题；(离线、近实时)&lt;/p&gt;
    
    </summary>
    
    
      <category term="ElasticSearch" scheme="http://changsk.top/tags/ElasticSearch/"/>
    
      <category term="搜索" scheme="http://changsk.top/tags/%E6%90%9C%E7%B4%A2/"/>
    
  </entry>
  
  <entry>
    <title>Java中遍历HashMap的5种方式</title>
    <link href="http://changsk.top/2019/06/27/java-HashMap-access/"/>
    <id>http://changsk.top/2019/06/27/java-HashMap-access/</id>
    <published>2019-06-27T05:08:50.000Z</published>
    <updated>2019-06-27T05:18:33.006Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文转载自：<a href="https://blog.csdn.net/w605283073/article/details/80708943" target="_blank" rel="noopener">Java中遍历HashMap的5种方式</a></p></blockquote><p>本教程将为你展示Java中<code>HashMap</code>的几种典型遍历方式。</p><p>如果你使用<code>Java8</code>，由于该版本<code>JDK</code>支持<code>lambda</code>表达式，可以采用第5种方式来遍历。</p><p>如果你想使用泛型，可以参考方法3。如果你使用旧版JDK不支持泛型可以参考方法4。</p><a id="more"></a><h3 id="通过ForEach循环进行遍历"><a href="#通过ForEach循环进行遍历" class="headerlink" title="通过ForEach循环进行遍历"></a>通过ForEach循环进行遍历</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mport java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line">map.put(<span class="number">1</span>, <span class="number">10</span>);</span><br><span class="line">map.put(<span class="number">2</span>, <span class="number">20</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// Iterating entries using a For Each loop</span></span><br><span class="line"><span class="keyword">for</span> (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123;</span><br><span class="line">System.out.println(<span class="string">"Key = "</span> + entry.getKey() + <span class="string">", Value = "</span> + entry.getValue());</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ForEach迭代键值对方式"><a href="#ForEach迭代键值对方式" class="headerlink" title="ForEach迭代键值对方式"></a>ForEach迭代键值对方式</h3><p>如果你只想使用键或者值，推荐使用如下方式</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line">map.put(<span class="number">1</span>, <span class="number">10</span>);</span><br><span class="line">map.put(<span class="number">2</span>, <span class="number">20</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 迭代键</span></span><br><span class="line"><span class="keyword">for</span> (Integer key : map.keySet()) &#123;</span><br><span class="line">System.out.println(<span class="string">"Key = "</span> + key);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 迭代值</span></span><br><span class="line"><span class="keyword">for</span> (Integer value : map.values()) &#123;</span><br><span class="line">System.out.println(<span class="string">"Value = "</span> + value);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用带泛型的迭代器进行遍历"><a href="#使用带泛型的迭代器进行遍历" class="headerlink" title="使用带泛型的迭代器进行遍历"></a>使用带泛型的迭代器进行遍历</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line">map.put(<span class="number">1</span>, <span class="number">10</span>);</span><br><span class="line">map.put(<span class="number">2</span>, <span class="number">20</span>);</span><br><span class="line"> </span><br><span class="line">Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; entries = map.entrySet().iterator();</span><br><span class="line"><span class="keyword">while</span> (entries.hasNext()) &#123;</span><br><span class="line">Map.Entry&lt;Integer, Integer&gt; entry = entries.next();</span><br><span class="line">System.out.println(<span class="string">"Key = "</span> + entry.getKey() + <span class="string">", Value = "</span> + entry.getValue());</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="使用不带泛型的迭代器进行遍历"><a href="#使用不带泛型的迭代器进行遍历" class="headerlink" title="使用不带泛型的迭代器进行遍历"></a>使用不带泛型的迭代器进行遍历</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"> </span><br><span class="line">Map map = <span class="keyword">new</span> HashMap();</span><br><span class="line">map.put(<span class="number">1</span>, <span class="number">10</span>);</span><br><span class="line">map.put(<span class="number">2</span>, <span class="number">20</span>);</span><br><span class="line"> </span><br><span class="line">Iterator&lt;Map.Entry&gt; entries = map.entrySet().iterator();</span><br><span class="line"><span class="keyword">while</span> (entries.hasNext()) &#123;</span><br><span class="line">Map.Entry entry = (Map.Entry) entries.next();</span><br><span class="line">Integer key = (Integer) entry.getKey();</span><br><span class="line">Integer value = (Integer) entry.getValue();</span><br><span class="line">System.out.println(<span class="string">"Key = "</span> + key + <span class="string">", Value = "</span> + value);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="通过Java8-Lambda表达式遍历"><a href="#通过Java8-Lambda表达式遍历" class="headerlink" title="通过Java8 Lambda表达式遍历"></a>通过Java8 Lambda表达式遍历</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;</span><br><span class="line"><span class="keyword">import</span> java.util.Map;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"> </span><br><span class="line">Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line">map.put(<span class="number">1</span>, <span class="number">10</span>);</span><br><span class="line">map.put(<span class="number">2</span>, <span class="number">20</span>);</span><br><span class="line">map.forEach((k, v) -&gt; System.out.println(<span class="string">"key: "</span> + k + <span class="string">" value:"</span> + v));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p> <strong>输出</strong> </p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">key</span>: 1 <span class="selector-tag">value</span><span class="selector-pseudo">:10</span></span><br><span class="line"><span class="selector-tag">key</span>: 2 <span class="selector-tag">value</span><span class="selector-pseudo">:20</span></span><br></pre></td></tr></table></figure><p>英文原文：<a href="https://www.javatips.net/blog/iterate-hashmap-using-java" target="_blank" rel="noopener">https://www.javatips.net/blog/iterate-hashmap-using-java</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;本文转载自：&lt;a href=&quot;https://blog.csdn.net/w605283073/article/details/80708943&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Java中遍历HashMap的5种方式&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本教程将为你展示Java中&lt;code&gt;HashMap&lt;/code&gt;的几种典型遍历方式。&lt;/p&gt;
&lt;p&gt;如果你使用&lt;code&gt;Java8&lt;/code&gt;，由于该版本&lt;code&gt;JDK&lt;/code&gt;支持&lt;code&gt;lambda&lt;/code&gt;表达式，可以采用第5种方式来遍历。&lt;/p&gt;
&lt;p&gt;如果你想使用泛型，可以参考方法3。如果你使用旧版JDK不支持泛型可以参考方法4。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://changsk.top/categories/Java/"/>
    
    
      <category term="HashMap" scheme="http://changsk.top/tags/HashMap/"/>
    
      <category term="java" scheme="http://changsk.top/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>数据库范式</title>
    <link href="http://changsk.top/2019/06/26/database-paradigms/"/>
    <id>http://changsk.top/2019/06/26/database-paradigms/</id>
    <published>2019-06-26T14:04:21.000Z</published>
    <updated>2019-06-27T06:02:29.712Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自：<a href="https://blog.csdn.net/tkzc_csk/article/details/88684166" target="_blank" rel="noopener">[数据库] 理解数据库范式-通俗易懂</a></p></blockquote><p>​        <strong>数据库范式</strong>是数据库设计中必不可少的知识，没有对范式的理解，就无法设计出<code>高效率</code>、<code>优雅</code>的数据库。甚至设计出错误的数据库。而想要理解并掌握范式却并不是那么容易。教科书中一般以<strong>关系代数</strong>的方法来解释数据库范式。这样做虽然能够<strong>十分准确</strong>的表达数据库范式，但<strong>比较抽象</strong>，<strong>不太直观，不便于理解，更难以记忆</strong>。　　本文用较为<strong>直白</strong>的语言介绍范式，旨在<strong>便于理解和记忆</strong>，这样做可能会出现一些<strong>不精确的表述</strong>。但对于初学者应该是个不错的入门。我写下这些的目的主要是为了<strong>加强记忆</strong>，其实我也比较菜，我希望当我对一些概念生疏的时候，回过头来看看自己写的笔记，可以快速地进入状态。如果你发现其中用错误，请指正。</p><a id="more"></a><p>下面开始进入正题：</p><h2 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h2><p>要理解范式，首先必须对知道什么是关系数据库，如果你不知道，我可以简单的不能再简单的说一下：<strong>关系数据库就是用二维表来保存数据</strong>。表和表之间可以……（省略10W字）。</p><p>然后你应该理解以下概念：</p><p><strong>实体</strong>：现实世界中客观存在并可以被区别的事物。比如“一个学生”、“一本书”、“一门课”等等。值得强调的是这里所说的“事物”不仅仅是看得见摸得着的“东西”，它也可以是虚拟的，比如说“老师与学校的关系”。</p><p><strong>属性</strong>：教科书上解释为：“实体所具有的某一特性”，由此可见，属性一开始是个逻辑概念，比如说，“性别”是“人”的一个属性。在关系数据库中，属性又是个物理概念，<strong>属性可以看作是“表的一列”</strong>。</p><p><strong>元组</strong>：<strong>表中的一行就是一个元组。</strong></p><p><strong>分量</strong>：<strong>元组的某个属性值</strong>。在一个关系数据库中，它是一个操作原子，即关系数据库在做任何操作的时候，属性是“<strong>不可分的</strong>”。否则就不是关系数据库了。</p><p><strong>码</strong>：<strong>表中可以唯一确定一个元组的某个属性（或者属性组）</strong>，如果这样的码有不止一个，那么大家都叫<strong>候选码</strong>，我们从候选码中挑一个出来做老大，它就叫<strong>主码</strong>。</p><p><strong>全码</strong>：如果一个码包含了所有的属性，这个码就是全码。</p><p><strong>主属性</strong>：<strong>一个属性只要在任何一个候选码中出现过，这个属性就是主属性</strong>。</p><p><strong>非主属性</strong>：与上面相反，没有在任何候选码中出现过，这个属性就是非主属性。</p><p><strong>外码</strong>：一个属性（或属性组），它不是码，但是它别的表的码，它就是外码。</p><h2 id="六个范式"><a href="#六个范式" class="headerlink" title="六个范式"></a>六个范式</h2><p>好了，上面已经介绍了我们掌握范式所需要的全部基础概念，下面我们就来讲范式。首先要明白，范式的包含关系。一个数据库设计如果符合第二范式，一定也符合第一范式。如果符合第三范式，一定也符合第二范式……</p><h3 id="第一范式（1NF）：属性不可分"><a href="#第一范式（1NF）：属性不可分" class="headerlink" title="第一范式（1NF）：属性不可分"></a>第一范式（1NF）：属性不可分</h3><p>在前面已经介绍了属性值的概念，我们说，它是“<strong>不可分的</strong>”。而第一范式要求<strong>属性也不可分</strong>。那么它和属性值不可分有什么区别呢？给一个例子：</p><p><img src="1.jpg" alt="在这里插入图片描述"></p><p>这个表中，属性值“分”了。“电话”这个属性里对于“小明”属性值分成了两个。<br><img src="2.jpg" alt="在这里插入图片描述"></p><p>这两种情况都不满足第一范式。<strong>不满足第一范式的数据库，不是关系数据库！</strong>所以，我们在任何关系数据库管理系统中，做不出这样的“表”来。针对上述情况可以做成这样的表：这个表中，属性 “分”了。也就是“电话”分为了“手机”和“座机”两个属性。</p><p><img src="3.jpg" alt="在这里插入图片描述"></p><h3 id="第二范式（2NF）：符合1NF，并且，非主属性完全依赖于码。（注意是完全依赖不能是部分依赖，设有函数依赖W→A，若存在XW，有X→A成立，那么称W→A是局部依赖，否则就称W→A是完全函数依赖）"><a href="#第二范式（2NF）：符合1NF，并且，非主属性完全依赖于码。（注意是完全依赖不能是部分依赖，设有函数依赖W→A，若存在XW，有X→A成立，那么称W→A是局部依赖，否则就称W→A是完全函数依赖）" class="headerlink" title="第二范式（2NF）：符合1NF，并且，非主属性完全依赖于码。（注意是完全依赖不能是部分依赖，设有函数依赖W→A，若存在XW，有X→A成立，那么称W→A是局部依赖，否则就称W→A是完全函数依赖）"></a>第二范式（2NF）：符合1NF，并且，非主属性完全依赖于码。（注意是完全依赖不能是部分依赖，设有函数依赖W→A，若存在XW，有X→A成立，那么称W→A是局部依赖，否则就称W→A是完全函数依赖）</h3><p><img src="4.jpg" alt="在这里插入图片描述"></p><p>一个学生上一门课，一定是特定某个老师教。所以有（学生，课程）－&gt;老师；</p><p>一个学生上一门课，一定在特定某个教室。所以有（学生，课程）－&gt;教室；</p><p>一个学生上一门课，他老师的职称可以确定。所以有（学生，课程）－&gt;老师职称；</p><p>一个学生上一门课，一定是特定某个教材。所以有（学生，课程）－&gt;教材</p><p>一个学生上一门课，一定在特定时间。所以有（学生，课程）－&gt;上课时间</p><p>因此（学生，课程）是一个码。</p><p>然而，一个课程，一定指定了某个教材，一年级语文肯定用的是《小学语文1》，那么就有课程－&gt;教材。（学生，课程）是个码，课程却决定了教材，这就叫做不完全依赖，或者说部分依赖。出现这样的情况，就不满足第二范式！</p><p>有什么不好吗？你可以想想：</p><p>1、校长要新增加一门课程叫“微积分”，教材是《大学数学》，怎么办？学生还没选课，而学生又是主属性，主属性不能空，课程怎么记录呢，教材记到哪呢? ……郁闷了吧?(插入异常)</p><p>2、下学期没学生学一年级语文（上）了，学一年级语文（下）去了，那么表中将不存在一年级语文（上），也就没了《小学语文1》。这时候，校长问：一年级语文（上）用的什么教材啊？……郁闷了吧?(删除异常)</p><p>3、校长说：一年级语文（上）换教材，换成《大学语文》。有10000个学生选了这门课，改动好大啊！改累死了……郁闷了吧？（修改/更新异常，在这里你可能觉得直接把教材《小学语文1》替换成《大学语文》不就可以了，但是替换操作虽然计算机运行速度很快，但是毕竟也要替换10000次，造成了很大的时间开销）</p><p>那应该怎么解决呢？投影分解，将一个表分解成两个或若干个表</p><p><img src="5.jpg" alt="在这里插入图片描述"><br><img src="6.jpg" alt="在这里插入图片描述"></p><h3 id="第三范式（3NF）：符合2NF，并且，消除传递依赖（也就是每个非主属性都不传递依赖于候选键，判断传递函数依赖，指的是如果存在”A-→-B-→-C”的决定关系，则C传递函数依赖于A。）"><a href="#第三范式（3NF）：符合2NF，并且，消除传递依赖（也就是每个非主属性都不传递依赖于候选键，判断传递函数依赖，指的是如果存在”A-→-B-→-C”的决定关系，则C传递函数依赖于A。）" class="headerlink" title="第三范式（3NF）：符合2NF，并且，消除传递依赖（也就是每个非主属性都不传递依赖于候选键，判断传递函数依赖，指的是如果存在”A → B → C”的决定关系，则C传递函数依赖于A。）"></a>第三范式（3NF）：符合2NF，并且，消除传递依赖（也就是每个非主属性都不传递依赖于候选键，判断传递函数依赖，指的是如果存在”A → B → C”的决定关系，则C传递函数依赖于A。）</h3><p>上面的“学生上课新表”符合2NF，但是它有传递依赖！在哪呢？问题就出在“老师”和“老师职称”这里。一个老师一定能确定一个老师职称。（学生，课程）-&gt;老师-&gt;职称。</p><p>有什么问题吗？想想：</p><p>1、老师升级了，变教授了，要改数据库，表中有N条，改了N次……（修改异常）<br>2、没人选这个老师的课了，老师的职称也没了记录……（删除异常）<br>3、新来一个老师，还没分配教什么课，他的职称记到哪？……（插入异常）<br>那应该怎么解决呢？和上面一样，投影分解：</p><p><img src="7.jpg" alt="在这里插入图片描述"><br><img src="8.jpg" alt="在这里插入图片描述"></p><h3 id="BC范式（BCNF）：符合3NF，并且，主属性不依赖于主属性-也就是不存在任何字段对任一候选关键字段的传递函数依赖"><a href="#BC范式（BCNF）：符合3NF，并且，主属性不依赖于主属性-也就是不存在任何字段对任一候选关键字段的传递函数依赖" class="headerlink" title="BC范式（BCNF）：符合3NF，并且，主属性不依赖于主属性(也就是不存在任何字段对任一候选关键字段的传递函数依赖)"></a>BC范式（BCNF）：符合3NF，并且，主属性不依赖于主属性(也就是不存在任何字段对任一候选关键字段的传递函数依赖)</h3><p><strong>BC范式既检查非主属性，又检查主属性。</strong>当只检查非主属性时，就成了第三范式。满足BC范式的关系都必然满足第三范式。</p><p>还可以这么说：<strong>若一个关系达到了第三范式，并且它只有一个候选码，或者它的每个候选码都是单属性，则该关系自然达到BC范式</strong>。</p><p>给你举个例子：假设仓库管理关系表 (仓库ID, 存储物品ID, 管理员ID, 数量)，且有一个管理员只在一个仓库工作；一个仓库可以存储多种物品。</p><p>这个数据库表中存在如下决定关系：</p><p>(仓库ID, 存储物品ID) →(管理员ID, 数量)</p><p>(管理员ID, 存储物品ID) → (仓库ID, 数量)</p><p>所以，(仓库ID, 存储物品ID)和(管理员ID, 存储物品ID)都是StorehouseManage的候选关键字，表中的唯一非关键字段为数量，它是符合第三范式的。但是，由于存在如下决定关系：</p><p>(仓库ID) → (管理员ID)</p><p>(管理员ID) → (仓库ID)</p><p>即存在<strong>关键字段决定关键字段</strong>的情况，所以其不符合BCNF范式。它会出现如下异常情况：</p><p>(1) 删除异常：</p><p>当仓库被清空后，所有”存储物品ID”和”数量”信息被删除的同时，”仓库ID”和”管理员ID”信息也被删除了。</p><p>(2) 插入异常：</p><p>当仓库没有存储任何物品时，无法给仓库分配管理员。</p><p>(3) 更新异常：</p><p>如果仓库换了管理员，则表中所有行的管理员ID都要修改。</p><p>把仓库管理关系表分解为二个关系表：</p><p>仓库管理：StorehouseManage(仓库ID, 管理员ID)；</p><p>仓库：Storehouse(仓库ID, 存储物品ID, 数量)。</p><p>这样的数据库表是符合BCNF范式的，消除了删除异常、插入异常和更新异常。</p><p>一般，一个数据库设计符合3NF或BCNF就可以了。在BC范式以上还有第四范式、第五范式。</p><h3 id="第四范式：要求把同一表内的多对多关系删除"><a href="#第四范式：要求把同一表内的多对多关系删除" class="headerlink" title="第四范式：要求把同一表内的多对多关系删除"></a>第四范式：要求把同一表内的多对多关系删除</h3><h3 id="第五范式：从最终结构重新建立原始结构"><a href="#第五范式：从最终结构重新建立原始结构" class="headerlink" title="第五范式：从最终结构重新建立原始结构"></a>第五范式：从最终结构重新建立原始结构</h3><p>其实数据库设计范式这方面重点掌握的就是<code>1NF、2NF、3NF、BCNF</code></p><p>四种范式之间存在如下关系：</p><p><img src="9.png" alt="1561558192833"></p><p>这里主要区别<code>3NF</code>和<code>BCNF</code>，一句话就是<code>3NF</code>是要满足不存在非主属性对候选码的传递函数依赖，<code>BCNF</code>是要满足不存在任一属性（包含非主属性和主属性）对候选码的传递函数依赖。</p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;转载自：&lt;a href=&quot;https://blog.csdn.net/tkzc_csk/article/details/88684166&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[数据库] 理解数据库范式-通俗易懂&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;​        &lt;strong&gt;数据库范式&lt;/strong&gt;是数据库设计中必不可少的知识，没有对范式的理解，就无法设计出&lt;code&gt;高效率&lt;/code&gt;、&lt;code&gt;优雅&lt;/code&gt;的数据库。甚至设计出错误的数据库。而想要理解并掌握范式却并不是那么容易。教科书中一般以&lt;strong&gt;关系代数&lt;/strong&gt;的方法来解释数据库范式。这样做虽然能够&lt;strong&gt;十分准确&lt;/strong&gt;的表达数据库范式，但&lt;strong&gt;比较抽象&lt;/strong&gt;，&lt;strong&gt;不太直观，不便于理解，更难以记忆&lt;/strong&gt;。
　　本文用较为&lt;strong&gt;直白&lt;/strong&gt;的语言介绍范式，旨在&lt;strong&gt;便于理解和记忆&lt;/strong&gt;，这样做可能会出现一些&lt;strong&gt;不精确的表述&lt;/strong&gt;。但对于初学者应该是个不错的入门。我写下这些的目的主要是为了&lt;strong&gt;加强记忆&lt;/strong&gt;，其实我也比较菜，我希望当我对一些概念生疏的时候，回过头来看看自己写的笔记，可以快速地进入状态。如果你发现其中用错误，请指正。&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://changsk.top/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
  </entry>
  
  <entry>
    <title>mysql的优化问题</title>
    <link href="http://changsk.top/2019/06/26/mysql-optimize/"/>
    <id>http://changsk.top/2019/06/26/mysql-optimize/</id>
    <published>2019-06-26T13:13:38.000Z</published>
    <updated>2019-06-27T06:03:14.752Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MySQL表设计原则"><a href="#MySQL表设计原则" class="headerlink" title="MySQL表设计原则"></a>MySQL表设计原则</h1><h2 id="表结构设计满足三大范式"><a href="#表结构设计满足三大范式" class="headerlink" title="表结构设计满足三大范式"></a>表结构设计满足三大范式</h2><h3 id="三大范式"><a href="#三大范式" class="headerlink" title="三大范式"></a>三大范式</h3><p>◆ 第一范式（1NF）：强调的是<strong>列的原子性</strong>，即列不能够再分成其他几列。 </p><p>◆ 第二范式（2NF）：<strong>首先是 1NF，另外包含两部分内容，一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。</strong> </p><p>◆ 第三范式（3NF）：<strong>首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。</strong> </p><a id="more"></a><p>第二范式（2NF）和第三范式（3NF）的概念很容易混淆，区分它们的关键点在于</p><blockquote><p>2NF：非主键列是否完全依赖于主键，还是依赖于主键的一部分；</p><p>3NF：非主键列是直接依赖于主键，还是直接依赖于非主键列。</p></blockquote><h3 id="范式的优点"><a href="#范式的优点" class="headerlink" title="范式的优点"></a>范式的优点</h3><ol><li>范式化的数据库更新起来更加快；</li><li>范式化之后，只有很少的重复数据，只需要修改更少的数据；</li><li>范式化的表更小，可以在内存中执行；</li><li>很少的冗余数据，在查询的时候需要更少的distinct或者group by语句。</li></ol><h3 id="范式的缺点"><a href="#范式的缺点" class="headerlink" title="范式的缺点"></a>范式的缺点</h3><p>范式化的表，<strong>在查询的时候经常需要很多的关联，因为单独一个表内不存在冗余和重复数据</strong>。这导致，稍微复杂一些的查询语句在查询范式的schema上都可能需要较多次的关联。这会增加让查询的代价，也可能使一些索引策略无效。因为范式化将列存放在不同的表中，而这些列在一个表中本可以属于同一个索引。</p><h2 id="适度冗余，-让query尽量减少join"><a href="#适度冗余，-让query尽量减少join" class="headerlink" title="适度冗余， 让query尽量减少join"></a>适度冗余， 让query尽量减少join</h2><p>虽然<code>optimizer</code>会对<code>query</code>进行一定的优化，但有时候遇见复杂的join，优化效果并不令人满意，再加上本来join的性能开销，所以需要尽量的减少join，而<strong>需要通过冗余来实现</strong>。比如：有两个数据表分别为用户信息表和用户发帖表，在展示发帖列表时，如果没有冗余的话，两个表要join以取得想要的发帖信息和用户昵称，但如果考虑冗余，用户昵称占用空间不大，如果在发帖表里增加这么一个字段的话，在展示列表时就不用做join操作了，性能会得到很大的改善。</p><p>但冗余也会带来一些问题，比如在发帖表里增加了用户昵称字段，就得维护两份用户昵称数据，为了保证数据的一致性，在用户昵称发生改变时，就<strong>得向两个表做更新操作</strong>，程序中就得做更多的处理。但相比的话，<strong>更新频率显然不及查询频率</strong>，这样通过增加少量的更新操作会换来更大的性能提升，这也是在项目中经常采用的优化手段。</p><h2 id="大字段垂直分拆"><a href="#大字段垂直分拆" class="headerlink" title="大字段垂直分拆"></a>大字段垂直分拆</h2><p>所谓的大字段，没有一个很严格的标准，常用的是<strong>如果一个字段的大小占整条记录的50%以上，我们就视为其为大字段。</strong>大字段垂直分拆相比适度冗余是完全相反的操作，适度冗余是将别的表中的字段放进一个表中，而大字段分拆是将自身的大字段拆分出去放进另一个表中。</p><p>这两个优化策略貌似是矛盾的，但要<strong>根据具体的应用场景来分析</strong>，<code>适度冗余是因为在频率较高的查询中要使用该字段，为了减少join的性能开销。而大字段垂直分拆是将在查询中不使用的大字段拿出去，</code>虽然不使用该字段但mysql在查询时并不是只需要访问需要查询的那几个字段，而是读取所有的字段，所以即使不使用字段，mysql也会读取该字段，为了节省IO开销，所以将查询中不常使用的大字段分拆出去。比如：拿博客系统为例，常用的作法是将博客内容从博客列表里分拆出去建立一个博客内容表，因为访问博客列表时并不需要读取博客内容，分拆出去之后，访问博客列表的性能将会大大的提升。但同时访问博客内容时就得做一次join操作了，性能对比的话，join操作两个表是一对一的关系，性能开销会很低。</p><h2 id="大表水平分拆"><a href="#大表水平分拆" class="headerlink" title="大表水平分拆"></a>大表水平分拆</h2><p>举例说明：在一个论坛系统里，管理员经常会发一些帖子，这些帖子要求在每个分类列表里都要置顶。</p><p>设计方案一：在发帖表里增加一列用来标示是否是管理员发帖，这样在每个分类列表展示时就需要对发帖表查询两次，一次是置顶帖，一次是普通帖，然后将两次结果合并。如果发帖表内容较大时，查询置顶帖的性能开销会比较大。</p><p>设计方案二：将置顶帖存放在一个单独的置顶表里。因为置顶帖数量相比会很少，但访问频率很高，这样从发帖表里分拆开来，访问的性能开销会少很多。</p><h2 id="选择合适的数据类型"><a href="#选择合适的数据类型" class="headerlink" title="选择合适的数据类型"></a>选择合适的数据类型</h2><p>要选择合适的数据类型必须要先了解不同数据类型间的差异。</p><p>数字类型有整数类型和浮点数类型，还有一类是通过二进制格式以字符串来存放的数字类型，如DECIMAL(size,d)，其存放长度主要通过定义的size决定，size定义多大，则实际存放就有多长。默认的size为10，d为0。这种类型的存放长度较长而且完全可以用整形来代替实现，所以不推荐使用。</p><p>时间类型主要使用<code>DATE</code>，<code>DATETIME</code>和<code>TIMESTAMP</code>三种类型，<strong>TIMESTAMP占用存储空间最少，只要4个字节</strong>，其它两种类型都要占用8个字节。从存储内容来看，<strong>TIMESTAMP只能存储1970年之后的时间</strong>，另外两种都能存储从1001开始的时间。</p><p>特别要说明的是<code>varchar</code>类型，varchar(size)，在mysql5.0.3之前size表示的是字节数，mysql5.0.3之后size表示的是字符数。这里我们只关注mysql5.0.3之后的表示，size表示的字符数最大限制和字符集有关，如果是gbk编码，最大长度为(65535-1-2)/2=32766，减1的原因是实际行存储从第二个字节开始，减2的原因是varchar头部的2个字节表示长度，除2因为是gbk编码；如果是utf8编码，最大长度为(65535-1-2)/3=21844。 </p><p>如果数据量一样，但数据类型更小的话，数据存放同样的数据就会占用更少的空间，这样检索同样的数据所带来的IO消耗自然会降低，性能也就很自然的得到提升。此外，mysql对不同类型的数据，处理方式也不一样，比如在运算或者排序操作中，越简单的数据类型操作性能越高，所以对于要频繁进行运算或者排序的字段尽量选择简单的数据类型。</p><blockquote><p>参考：<br><a href="https://www.cnblogs.com/wzj4858/p/7910084.html" target="_blank" rel="noopener">mysql表设计原则</a> </p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;MySQL表设计原则&quot;&gt;&lt;a href=&quot;#MySQL表设计原则&quot; class=&quot;headerlink&quot; title=&quot;MySQL表设计原则&quot;&gt;&lt;/a&gt;MySQL表设计原则&lt;/h1&gt;&lt;h2 id=&quot;表结构设计满足三大范式&quot;&gt;&lt;a href=&quot;#表结构设计满足三大范式&quot; class=&quot;headerlink&quot; title=&quot;表结构设计满足三大范式&quot;&gt;&lt;/a&gt;表结构设计满足三大范式&lt;/h2&gt;&lt;h3 id=&quot;三大范式&quot;&gt;&lt;a href=&quot;#三大范式&quot; class=&quot;headerlink&quot; title=&quot;三大范式&quot;&gt;&lt;/a&gt;三大范式&lt;/h3&gt;&lt;p&gt;◆ 第一范式（1NF）：强调的是&lt;strong&gt;列的原子性&lt;/strong&gt;，即列不能够再分成其他几列。 &lt;/p&gt;
&lt;p&gt;◆ 第二范式（2NF）：&lt;strong&gt;首先是 1NF，另外包含两部分内容，一是表必须有一个主键；二是没有包含在主键中的列必须完全依赖于主键，而不能只依赖于主键的一部分。&lt;/strong&gt; &lt;/p&gt;
&lt;p&gt;◆ 第三范式（3NF）：&lt;strong&gt;首先是 2NF，另外非主键列必须直接依赖于主键，不能存在传递依赖。即不能存在：非主键列 A 依赖于非主键列 B，非主键列 B 依赖于主键的情况。&lt;/strong&gt; &lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://changsk.top/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="Mysql" scheme="http://changsk.top/tags/Mysql/"/>
    
  </entry>
  
  <entry>
    <title>Redis内部数据结构详解——skiplist</title>
    <link href="http://changsk.top/2019/06/26/redis-skiplist/"/>
    <id>http://changsk.top/2019/06/26/redis-skiplist/</id>
    <published>2019-06-26T12:50:52.000Z</published>
    <updated>2019-06-26T13:58:37.550Z</updated>
    
    <content type="html"><![CDATA[<p>本文是《<a href="http://zhangtielei.com/posts/blog-redis-dict.html" target="_blank" rel="noopener">Redis内部数据结构详解</a>》系列的第六篇。在本文中，我们围绕一个<code>Redis</code>的内部数据结构——<strong>skiplist</strong>展开讨论。</p><p>Redis里面使用skiplist是为了实现<code>sorted set</code>这种对外的数据结构。<code>sorted set</code>提供的操作非常丰富，可以满足非常多的应用场景。这也意味着，sorted set相对来说实现比较复杂。同时，<code>skiplist</code>这种数据结构对于很多人来说都比较陌生，因为大部分学校里的算法课都没有对这种数据结构进行过详细的介绍。因此，为了介绍得足够清楚，本文会比这个系列的其它几篇花费更多的篇幅。</p><a id="more"></a><p>我们将大体分成三个部分进行介绍：</p><ol><li>介绍经典的<code>skiplist</code>数据结构，并进行简单的算法分析。这一部分的介绍，与Redis没有直接关系。我会尝试尽量使用通俗易懂的语言进行描述。</li><li>讨论Redis里的<code>skiplist</code>的具体实现。为了支持sorted set本身的一些要求，在经典的<code>skiplist</code>基础上，Redis里的相应实现做了若干改动。</li><li>讨论sorted set是如何在<code>skiplist</code>, dict和ziplist基础上构建起来的。</li></ol><p>我们在讨论中还会涉及到两个Redis配置（在<code>redis.conf</code>中的<code>ADVANCED CONFIG</code>部分）：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zset-max-ziplist-entries <span class="number">128</span></span><br><span class="line">zset-max-ziplist-value <span class="number">64</span></span><br></pre></td></tr></table></figure><p>我们在讨论中会详细解释这两个配置的含义。</p><blockquote><p>注：本文讨论的代码实现基于Redis源码的3.2分支。</p></blockquote><h2 id="skiplist数据结构简介"><a href="#skiplist数据结构简介" class="headerlink" title="skiplist数据结构简介"></a>skiplist数据结构简介</h2><p><code>skiplist</code>本质上也是一种查找结构，用于解决算法中的查找问题（<strong>Searching</strong>），即根据给定的key，快速查到它所在的位置（或者对应的value）。</p><p>我们在《Redis内部数据结构详解》系列的<a href="http://zhangtielei.com/posts/blog-redis-dict.html" target="_blank" rel="noopener">第一篇</a>中介绍dict的时候，曾经讨论过：一般查找问题的解法分为两个大类：一个是基于各种<strong>平衡树</strong>，一个是基于<strong>哈希表</strong>。但<code>skiplist</code>却比较特殊，它没法归属到这两大类里面。</p><p>这种数据结构是由<a href="https://en.wikipedia.org/wiki/William_Pugh" target="_blank" rel="noopener">William Pugh</a>发明的，最早出现于他在1990年发表的论文《<a href="ftp://ftp.cs.umd.edu/pub/skipLists/skiplists.pdf" target="_blank" rel="noopener">Skip Lists: A Probabilistic Alternative to Balanced Trees</a>》。对细节感兴趣的同学可以下载论文原文来阅读。</p><p><code>skiplist</code>，顾名思义，首先它是一个list。实际上，它是在有序链表的基础上发展起来的。</p><p>我们先来看一个有序链表，如下图（最左侧的灰色节点表示一个空的头结点）：</p><p><img src="1.jpg" alt="有序链表结构图"></p><p>在这样一个链表中，如果我们要查找某个数据，那么需要从头开始逐个进行比较，直到找到包含数据的那个节点，或者找到第一个比给定数据大的节点为止（没找到）。也就是说，<strong>时间复杂度为O(n)</strong>。同样，当我们要插入新数据的时候，也要经历同样的查找过程，从而确定插入位置。</p><p>假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图：</p><p><img src="2.jpg" alt="每两个节点增加一个跳跃指针的有序链表"></p><p>这样所有新增加的指针连成了一个新的链表，但它包含的节点个数只有原来的一半（上图中是7, 19, 26）。现在当我们想查找数据的时候，可以先沿着这个新链表进行查找。当碰到比待查数据大的节点时，再回到原来的链表中进行查找。比如，我们想查找23，查找的路径是沿着下图中标红的指针所指向的方向进行的：</p><p><img src="3.jpg" alt="一个搜索路径的例子"></p><ul><li>23首先和7比较，再和19比较，比它们都大，继续向后比较。</li><li>但23和26比较的时候，比26要小，因此回到下面的链表（原链表），与22比较。</li><li>23比22要大，沿下面的指针继续向后和26比较。23比26小，说明待查数据23在原链表中不存在，而且它的插入位置应该在22和26之间。</li></ul><p>在这个查找过程中，由于新增加的指针，我们不再需要与链表中每个节点逐个进行比较了。需要比较的节点数大概只有原来的一半。</p><p>利用同样的方式，我们可以在上层新产生的链表上，继续为每相邻的两个节点增加一个指针，从而产生第三层链表。如下图：</p><p><img src="4.jpg" alt="两层跳跃指针"></p><p>在这个新的三层链表结构上，如果我们还是查找23，那么沿着最上层链表首先要比较的是19，发现23比19大，接下来我们就知道只需要到19的后面去继续查找，从而一下子跳过了19前面的所有节点。可以想象，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。</p><p><code>skiplist</code>正是受这种<strong>多层链表</strong>的想法的启发而设计出来的。实际上，按照上面生成链表的方式，<strong>上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个二分查找，使得查找的时间复杂度可以降低到O(log n)。</strong>但是，这种方法在插入数据的时候有很大的问题。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数<strong>严格的2:1的对应关系</strong>。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。</p><p><code>skiplist</code>为了避免这一问题，它<strong>不要求上下相邻两层链表之间的节点个数有严格的对应关系</strong>，而是<strong>为每个节点随机出一个层数(level)。</strong>比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个skiplist的过程：</p><p><img src="5.jpg" alt="skiplist插入形成过程"></p><p>从上面<code>skiplist</code>的创建和插入过程可以看出，<strong>每一个节点的层数（level）是随机出来的</strong>，<strong>而且新插入一个节点不会影响其它节点的层数</strong>。因此，插入操作只需要修改插入节点前后的指针，而不需要对很多节点都进行调整。这就降低了插入操作的复杂度。实际上，这是<code>skiplist</code>的一个很重要的特性，这让它在<strong>插入性能上明显优于平衡树的方案</strong>。这在后面我们还会提到。</p><p>根据上图中的<code>skiplist</code>结构，我们很容易理解这种数据结构的名字的由来。skiplist，翻译成中文，可以翻译成“<strong>跳表</strong>”或“<strong>跳跃表</strong>”，指的就是除了最下面第1层链表之外，它会产生<strong>若干层稀疏的链表</strong>，<strong>这些链表里面的指针故意跳过了一些节点（而且越高层的链表跳过的节点越多）。</strong>这就使得我们在查找数据的时候能够先在高层的链表中进行查找，然后逐层降低，<strong>最终降到第1层链表来精确地确定数据位置</strong>。在这个过程中，我们跳过了一些节点，从而也就加快了查找速度。</p><p>刚刚创建的这个<code>skiplist</code>总共包含4层链表，现在假设我们在它里面依然查找23，下图给出了查找路径：</p><p><img src="6.jpg" alt="skiplist上的查找路径展示"></p><p>需要注意的是，前面演示的各个节点的插入过程，实际上在插入之前也要先经历一个类似的查找过程，在确定插入位置后，再完成插入操作。</p><p>至此，<code>skiplist</code>的查找和插入操作，我们已经很清楚了。而删除操作与插入操作类似，我们也很容易想象出来。这些操作我们也应该能很容易地用代码实现出来。</p><p>当然，实际应用中的<code>skiplist</code>每个节点应该包含<strong>key</strong>和<strong>value</strong>两部分。前面的描述中我们没有具体区分key和value，但实际上<strong>列表中是按照key进行排序的</strong>，查找过程也是根据key在比较。</p><p>但是，如果你是第一次接触<code>skiplist</code>，那么一定会产生一个疑问：节点插入时随机出一个层数，仅仅依靠这样一个简单的随机数操作而构建出来的多层链表结构，能保证它有一个良好的查找性能吗？为了回答这个疑问，我们需要分析<code>skiplist</code>的统计性能。</p><p>在分析之前，我们还需要着重指出的是，执行插入操作时计算随机数的过程，是一个很关键的过程，它对<code>skiplist</code>的统计特性有着很重要的影响。<strong>这并不是一个普通的服从均匀分布的随机数</strong>，它的计算过程如下：</p><ul><li>首先，每个节点肯定都有第1层指针（每个节点都在第1层链表里）。</li><li>如果一个节点有第i层(i&gt;=1)指针（即节点已经在第1层到第i层链表中），那么它有第(i+1)层指针的概率为p。</li><li>节点最大的层数不允许超过一个最大值，记为<strong>MaxLevel</strong>。</li></ul><p>这个计算随机层数的伪码如下所示：</p><figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">randomLevel()</span><br><span class="line">    level := <span class="number">1</span></span><br><span class="line">    <span class="comment">// random()返回一个[0...1)的随机数</span></span><br><span class="line">    <span class="built_in">while</span> <span class="built_in">random</span>() &lt; p <span class="keyword">and</span> level &lt; MaxLevel <span class="built_in">do</span></span><br><span class="line">        level := level + <span class="number">1</span></span><br><span class="line">    <span class="built_in">return</span> level</span><br></pre></td></tr></table></figure><p><code>randomLevel()</code>的伪码中包含两个参数，一个是p，一个是MaxLevel。在Redis的skiplist实现中，这两个参数的取值为：</p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">p</span> = <span class="number">1</span>/<span class="number">4</span></span><br><span class="line"><span class="attr">MaxLevel</span> = <span class="number">32</span></span><br></pre></td></tr></table></figure><h3 id="skiplist的算法性能分析"><a href="#skiplist的算法性能分析" class="headerlink" title="skiplist的算法性能分析"></a>skiplist的算法性能分析</h3><p>在这一部分，我们来简单分析一下<code>skiplist</code>的时间复杂度和空间复杂度，以便对于<code>skiplist</code>的性能有一个直观的了解。如果你不是特别偏执于算法的性能分析，那么可以暂时跳过这一小节的内容。</p><p>我们先来计算一下每个节点所包含的平均指针数目（概率期望）。节点包含的指针数目，相当于这个算法在空间上的额外开销(overhead)，可以用来度量空间复杂度。</p><p>根据前面randomLevel()的伪码，我们很容易看出，产生越高的节点层数，概率越低。定量的分析如下：</p><ul><li>节点层数至少为1。而大于1的节点层数，满足一个概率分布。</li><li>节点层数恰好等于1的概率为1-p。</li><li>节点层数大于等于2的概率为p，而节点层数恰好等于2的概率为p(1-p)。</li><li>节点层数大于等于3的概率为p2，而节点层数恰好等于3的概率为p2(1-p)。</li><li>节点层数大于等于4的概率为p3，而节点层数恰好等于4的概率为p3(1-p)。</li><li>……</li></ul><p>因此，一个节点的平均层数（也即包含的平均指针数目），计算如下：</p><p><img src="7.jpg" alt="skiplist平均层数计算"></p><p>现在很容易计算出：</p><ul><li>当p=1/2时，每个节点所包含的平均指针数目为2；</li><li>当p=1/4时，每个节点所包含的平均指针数目为1.33。这也是Redis里的skiplist实现在空间上的开销。</li></ul><p>接下来，为了分析时间复杂度，我们计算一下skiplist的平均查找长度。查找长度指的是查找路径上跨越的跳数，而查找过程中的比较次数就等于查找长度加1。以前面图中标出的查找23的查找路径为例，从左上角的头结点开始，一直到结点22，查找长度为6。</p><p>为了计算查找长度，这里我们需要利用一点小技巧。我们注意到，每个节点插入的时候，它的层数是由随机函数randomLevel()计算出来的，而且随机的计算不依赖于其它节点，每次插入过程都是完全独立的。所以，从统计上来说，一个skiplist结构的形成与节点的插入顺序无关。</p><p>这样的话，为了计算查找长度，我们可以将查找过程倒过来看，从右下方第1层上最后到达的那个节点开始，沿着查找路径向左向上回溯，类似于爬楼梯的过程。我们假设当回溯到某个节点的时候，它才被插入，这虽然相当于改变了节点的插入顺序，但从统计上不影响整个skiplist的形成结构。</p><p>现在假设我们从一个层数为i的节点x出发，需要向左向上攀爬k层。这时我们有两种可能：</p><ul><li>如果节点x有第(i+1)层指针，那么我们需要向上走。这种情况概率为p。</li><li>如果节点x没有第(i+1)层指针，那么我们需要向左走。这种情况概率为(1-p)。</li></ul><p>这两种情形如下图所示：</p><p><img src="8.jpg" alt="skiplist沿查找路径回溯"></p><p>用C(k)表示向上攀爬k个层级所需要走过的平均查找路径长度（概率期望），那么：</p><figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="title">C</span><span class="params">(<span class="number">0</span>)</span></span>=<span class="number">0</span></span><br><span class="line"><span class="function"><span class="title">C</span><span class="params">(k)</span></span>=(<span class="number">1</span>-p)×(上图中情况b的查找长度) + p×(上图中情况c的查找长度)</span><br></pre></td></tr></table></figure><p>代入，得到一个差分方程并化简：</p><figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">C(<span class="name">k</span>)=(<span class="number">1</span>-p)(<span class="name">C</span>(<span class="name">k</span>)<span class="number">+1</span>) + p(<span class="name">C</span>(<span class="name">k-1</span>)<span class="number">+1</span>)</span><br><span class="line">C(<span class="name">k</span>)=1/p+C(<span class="name">k-1</span>)</span><br><span class="line">C(<span class="name">k</span>)=k/p</span><br></pre></td></tr></table></figure><p>这个结果的意思是，我们每爬升1个层级，需要在查找路径上走1/p步。而我们总共需要攀爬的层级数等于整个skiplist的总层数-1。</p><p>那么接下来我们需要分析一下当skiplist中有n个节点的时候，它的总层数的概率均值是多少。这个问题直观上比较好理解。根据节点的层数随机算法，容易得出：</p><ul><li>第1层链表固定有n个节点；</li><li>第2层链表平均有n*p个节点；</li><li>第3层链表平均有n*p2个节点；</li><li>…</li></ul><p>所以，从第1层到最高层，各层链表的平均节点数是一个指数递减的等比数列。容易推算出，总层数的均值为log1/pn，而最高层的平均节点数为1/p。</p><p>综上，粗略来计算的话，平均查找长度约等于：</p><ul><li>C(log1/pn-1)=(log1/pn-1)/p</li></ul><p>即，平均时间复杂度为O(log n)。</p><p>当然，这里的时间复杂度分析还是比较粗略的。比如，沿着查找路径向左向上回溯的时候，可能先到达左侧头结点，然后沿头结点一路向上；还可能先到达最高层的节点，然后沿着最高层链表一路向左。但这些细节不影响平均时间复杂度的最后结果。另外，这里给出的时间复杂度只是一个概率平均值，但实际上计算一个精细的概率分布也是有可能的。详情还请参见<a href="https://en.wikipedia.org/wiki/William_Pugh" target="_blank" rel="noopener">William Pugh</a>的论文《<a href="ftp://ftp.cs.umd.edu/pub/skipLists/skiplists.pdf" target="_blank" rel="noopener">Skip Lists: A Probabilistic Alternative to Balanced Trees</a>》。</p><h3 id="skiplist与平衡树、哈希表的比较"><a href="#skiplist与平衡树、哈希表的比较" class="headerlink" title="skiplist与平衡树、哈希表的比较"></a>skiplist与平衡树、哈希表的比较</h3><ul><li><code>skiplist</code>和各种平衡树（如<strong>AVL</strong>、<strong>红黑树</strong>等）的元素是有序排列的，而哈希表不是有序的。因此，<strong>在哈希表上只能做单个key的查找，不适宜做范围查找。</strong>所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。</li><li>在做范围查找的时候，<strong>平衡树比skiplist操作要复杂</strong>。在平衡树上，我们找到指定范围的小值之后，还需要以<strong>中序遍历</strong>的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在<code>skiplist</code>上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。</li><li>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而<code>skiplist</code>的插入和删除只需要修改相邻节点的指针，操作简单又快速。</li><li>从内存占用上来说，<code>skiplist</code>比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。</li><li>查找单个key，<strong>skiplist和平衡树的时间复杂度都为O(log n)</strong>，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。</li><li>从算法实现难度上来比较，skiplist比平衡树要简单得多。</li></ul><h2 id="Redis中的skiplist实现"><a href="#Redis中的skiplist实现" class="headerlink" title="Redis中的skiplist实现"></a>Redis中的skiplist实现</h2><p>在这一部分，我们讨论<code>Redis</code>中的<code>skiplist</code>实现。</p><p>在Redis中，skiplist被用于实现暴露给外部的一个数据结构：<strong>sorted set</strong>。准确地说，<strong>sorted set底层不仅仅使用了skiplist，还使用了ziplist和dict。</strong>这几个数据结构的关系，我们下一章再讨论。现在，我们先花点时间把sorted set的关键命令看一下。这些命令对于Redis里skiplist的实现，有重要的影响。</p><h3 id="sorted-set的命令举例"><a href="#sorted-set的命令举例" class="headerlink" title="sorted set的命令举例"></a>sorted set的命令举例</h3><p><strong>sorted set是一个有序的数据集合，对于像类似排行榜这样的应用场景特别适合。</strong></p><p>现在我们来看一个例子，用sorted set来存储代数课（algebra）的成绩表。原始数据如下：</p><ul><li>Alice 87.5</li><li>Bob 89.0</li><li>Charles 65.5</li><li>David 78.0</li><li>Emily 93.5</li><li>Fred 87.5</li></ul><p>这份数据给出了每位同学的名字和分数。下面我们将这份数据存储到sorted set里面去：</p><p>[<img src="8.jpg" alt="sorted set命令举例"></p><p>对于上面的这些命令，我们需要的注意的地方包括：</p><ul><li>前面的6个<code>zadd</code>命令，将6位同学的名字和分数(<code>score</code>)都输入到一个key值为algebra的sorted set里面了。注意Alice和Fred的分数相同，都是87.5分。</li><li><code>zrevrank</code>命令查询Alice的排名（命令中的rev表示<strong>按照倒序排列</strong>，也就是从大到小），返回3。排在Alice前面的分别是Emily、Bob、Fred，而排名(rank)从0开始计数，所以Alice的排名是3。注意，其实Alice和Fred的分数相同，这种情况下sorted set会把分数相同的元素，按照字典顺序来排列。按照倒序，Fred排在了Alice的前面。</li><li><code>zscore</code>命令查询了Charles对应的分数。</li><li><code>zrevrange</code>命令查询了从大到小排名为0~3的4位同学。</li><li><code>zrevrangebyscore</code>命令查询了分数在80.0和90.0之间的所有同学，并按分数从大到小排列。</li></ul><p>总结一下，<code>sorted set</code>中的每个元素主要表现出3个属性：</p><ul><li>数据本身（在前面的例子中我们把名字存成了数据）。</li><li>每个数据对应一个分数(score)。</li><li>根据分数大小和数据本身的字典排序，每个数据会产生一个排名(rank)。可以<strong>按正序或倒序。</strong></li></ul><h3 id="Redis中skiplist实现的特殊性"><a href="#Redis中skiplist实现的特殊性" class="headerlink" title="Redis中skiplist实现的特殊性"></a>Redis中skiplist实现的特殊性</h3><p>我们简单分析一下前面出现的几个查询命令：</p><ul><li>zrevrank由数据查询它对应的排名，这在前面介绍的skiplist中并不支持。</li><li>zscore由数据查询它对应的分数，这也不是skiplist所支持的。</li><li>zrevrange根据一个排名范围，查询排名在这个范围内的数据。这在前面介绍的skiplist中也不支持。</li><li>zrevrangebyscore根据分数区间查询数据集合，是一个skiplist所支持的典型的范围查找（score相当于key）。</li></ul><p>实际上，Redis中sorted set的实现是这样的：</p><ul><li>当数据较少时，sorted set是由一个<code>ziplist</code>来实现的。</li><li>当数据多的时候，sorted set是由<code>一个dict + 一个skiplist</code>来实现的。简单来讲，<strong>dict用来查询数据到分数的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。</strong></li></ul><p>这里sorted set的构成我们在下一章还会再详细地讨论。现在我们集中精力来看一下sorted set与skiplist的关系，：</p><ul><li>zscore的查询，不是由skiplist来提供的，而是由那个dict来提供的。</li><li>为了支持排名(rank)，Redis里对skiplist做了扩展，使得根据排名能够快速查到数据，或者根据分数查到数据之后，也同时很容易获得排名。而且，根据排名的查找，时间复杂度也为O(log n)。</li><li>zrevrange的查询，是根据排名查数据，由扩展后的skiplist来提供。</li><li>zrevrank是先在dict中由数据查到分数，再拿分数到skiplist中去查找，查到后也同时获得了排名。</li></ul><p>前述的查询过程，也暗示了各个操作的时间复杂度：</p><ul><li>zscore只用查询一个dict，所以时间复杂度为O(1)</li><li>zrevrank, zrevrange, zrevrangebyscore由于要查询skiplist，所以zrevrank的时间复杂度为O(log n)，而zrevrange, zrevrangebyscore的时间复杂度为O(log(n)+M)，其中M是当前查询返回的元素个数。</li></ul><p>总结起来，Redis中的skiplist跟前面介绍的经典的skiplist相比，有如下不同：</p><ul><li>分数(score)允许重复，<strong>即skiplist的key允许重复</strong>。这在最开始介绍的经典skiplist中是不允许的。</li><li>在比较时，不仅比较分数（相当于skiplist的key），还比较数据本身。在Redis的skiplist实现中，数据本身的内容唯一标识这份数据，而不是由key来唯一标识。另外，<strong>当多个元素分数相同的时候，还需要根据数据内容来进字典排序。</strong></li><li>第1层链表不是一个单向链表，而是一个<strong>双向链表</strong>。这是为了方便<strong>以倒序方式获取一个范围内的元素。</strong></li><li>在skiplist中可以很方便地计算出每个元素的排名(rank)。</li></ul><h4 id="skiplist的数据结构定义"><a href="#skiplist的数据结构定义" class="headerlink" title="skiplist的数据结构定义"></a>skiplist的数据结构定义</h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ZSKIPLIST_MAXLEVEL 32</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ZSKIPLIST_P 0.25</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> &#123;</span></span><br><span class="line">    robj *obj;</span><br><span class="line">    <span class="keyword">double</span> score;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">backward</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistLevel</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">forward</span>;</span></span><br><span class="line">        <span class="keyword">unsigned</span> <span class="keyword">int</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplist</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">header</span>, *<span class="title">tail</span>;</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> length;</span><br><span class="line">    <span class="keyword">int</span> level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure><p>这段代码出自server.h，我们来简要分析一下：</p><ul><li>开头定义了两个常量，ZSKIPLIST_MAXLEVEL和ZSKIPLIST_P，分别对应我们前面讲到的skiplist的两个参数：一个是MaxLevel，一个是p。</li><li>zskiplistNode定义了skiplist的节点结构。<ul><li>obj字段存放的是节点数据，它的类型是一个string robj。本来一个string robj可能存放的不是sds，而是long型，但zadd命令在将数据插入到skiplist里面之前先进行了解码，所以这里的obj字段里存储的一定是一个sds。有关robj的详情可以参见系列文章的第三篇：《<a href="http://zhangtielei.com/posts/blog-redis-robj.html" target="_blank" rel="noopener">Redis内部数据结构详解(3)——robj</a>》。这样做的目的应该是为了方便在查找的时候对数据进行字典序的比较，而且，skiplist里的数据部分是数字的可能性也比较小。</li><li>score字段是数据对应的分数。</li><li>backward字段是指向链表前一个节点的指针（前向指针）。节点只有1个前向指针，所以只有第1层链表是一个双向链表。</li><li>level[]存放指向各层链表后一个节点的指针（后向指针）。每层对应1个后向指针，用forward字段表示。另外，每个后向指针还对应了一个span值，它表示当前的指针跨越了多少个节点。span用于计算元素排名(rank)，这正是前面我们提到的Redis对于skiplist所做的一个扩展。需要注意的是，level[]是一个柔性数组（<a href="https://en.wikipedia.org/wiki/Flexible_array_member" target="_blank" rel="noopener">flexible array member</a>），因此它占用的内存不在zskiplistNode结构里面，而需要插入节点的时候单独为它分配。也正因为如此，skiplist的每个节点所包含的指针数目才是不固定的，我们前面分析过的结论——skiplist每个节点包含的指针数目平均为1/(1-p)——才能有意义。</li></ul></li><li>zskiplist定义了真正的skiplist结构，它包含：<ul><li>头指针header和尾指针tail。</li><li>链表长度length，即链表包含的节点总数。注意，新创建的skiplist包含一个空的头指针，这个头指针不包含在length计数中。</li><li>level表示skiplist的总层数，即所有节点层数的最大值。</li></ul></li></ul><p>下图以前面插入的代数课成绩表为例，展示了Redis中一个skiplist的可能结构：</p><p><img src="9.jpg" alt="Redis skiplist结构举例"></p><p>注意：图中前向指针上面括号中的数字，表示对应的span的值。即当前指针跨越了多少个节点，这个计数不包括指针的起点节点，但包括指针的终点节点。</p><p>假设我们在这个skiplist中查找score=89.0的元素（即Bob的成绩数据），在查找路径中，我们会跨域图中标红的指针，这些指针上面的span值累加起来，就得到了Bob的排名(2+2+1)-1=4（减1是因为rank值以0起始）。需要注意这里算的是从小到大的排名，而如果要算从大到小的排名，只需要用skiplist长度减去查找路径上的span累加值，即6-(2+2+1)=1。</p><p>可见，在查找skiplist的过程中，通过累加span值的方式，我们就能很容易算出排名。相反，如果指定排名来查找数据（类似zrange和zrevrange那样），也可以不断累加span并时刻保持累加值不超过指定的排名，通过这种方式就能得到一条O(log n)的查找路径。</p><h2 id="Redis中的sorted-set"><a href="#Redis中的sorted-set" class="headerlink" title="Redis中的sorted set"></a>Redis中的sorted set</h2><p>我们前面提到过，Redis中的sorted set，是在<strong>skiplist, dict和ziplist</strong>基础上构建起来的:</p><ul><li>当数据较少时，sorted set是由一个<code>ziplist</code>来实现的。</li><li>当数据多的时候，sorted set是由一个叫zset的数据结构来实现的，这个zset包含一个<code>dict + 一个skiplist</code>。<strong>dict用来查询数据到分数(score)的对应关系，而skiplist用来根据分数查询数据（可能是范围查找）。</strong></li></ul><p>在这里我们先来讨论一下前一种情况——基于ziplist实现的sorted set。在本系列前面<a href="http://zhangtielei.com/posts/blog-redis-ziplist.html" target="_blank" rel="noopener">关于ziplist的文章</a>里，我们介绍过，<strong>ziplist就是由很多数据项组成的一大块连续内存</strong>。由于sorted set的每一项元素都由数据和score组成，因此，<strong>当使用zadd命令插入一个(数据, score)对的时候，底层在相应的ziplist上就插入两个数据项：数据在前，score在后。</strong></p><p><strong>ziplist的主要优点是节省内存</strong>，但它上面的查找操作只能<strong>按顺序查找</strong>（可以正序也可以倒序）。因此，sorted set的各个查询操作，就是在ziplist上从前向后（或从后向前）一步步查找，每一步前进两个数据项，跨域一个(数据, score)对。</p><p>随着数据的插入，sorted set底层的这个ziplist就可能会转成zset的实现（转换过程详见t_zset.c的zsetConvert）。那么到底插入多少才会转呢？</p><p>还记得本文开头提到的两个Redis配置吗？</p><figure class="highlight excel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">zset-<span class="built_in">max</span>-ziplist-entries <span class="number">128</span></span><br><span class="line">zset-<span class="built_in">max</span>-ziplist-<span class="built_in">value</span> <span class="number">64</span></span><br></pre></td></tr></table></figure><p>这个配置的意思是说，在如下两个条件之一满足的时候，ziplist会转成zset（具体的触发条件参见t_zset.c中的zaddGenericCommand相关代码）：</p><ul><li>当sorted set中的元素个数，即(数据, score)对的数目超过128的时候，<strong>也就是ziplist数据项超过256的时候。</strong></li><li>当sorted set中插入的任意一个数据的长度超过了64的时候。</li></ul><p>最后，zset结构的代码定义如下：</p><figure class="highlight mipsasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">typedef struct zset &#123;</span><br><span class="line">    <span class="keyword">dict </span>*<span class="keyword">dict;</span></span><br><span class="line"><span class="keyword"> </span>   zskiplist *zsl<span class="comment">;</span></span><br><span class="line">&#125; zset<span class="comment">;</span></span><br></pre></td></tr></table></figure><h3 id="Redis为什么用skiplist而不用平衡树？"><a href="#Redis为什么用skiplist而不用平衡树？" class="headerlink" title="Redis为什么用skiplist而不用平衡树？"></a>Redis为什么用skiplist而不用平衡树？</h3><p>在前面我们对于skiplist和平衡树、哈希表的比较中，其实已经不难看出Redis里使用skiplist而不用平衡树的原因了。现在我们看看，对于这个问题，Redis的作者 @antirez 是怎么说的：</p><blockquote><p>There are a few reasons:</p><p>1) They are not very memory intensive. It’s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees.</p><p>2) A sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees.</p><p>3) They are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.</p></blockquote><p>这段话原文出处：</p><blockquote><p><a href="https://news.ycombinator.com/item?id=1171423" target="_blank" rel="noopener">https://news.ycombinator.com/item?id=1171423</a></p></blockquote><p>这里从内存占用、对范围查找的支持和实现难易程度这三方面总结的原因，我们在前面其实也都涉及到了。</p><hr><p>系列下一篇我们将介绍intset，以及它与Redis对外暴露的数据类型set的关系，敬请期待。</p><p><strong>其它精选文章</strong>：</p><ul><li><a href="http://zhangtielei.com/posts/blog-redis-quicklist.html" target="_blank" rel="noopener">Redis内部数据结构详解(5)——quicklist</a></li><li><a href="http://zhangtielei.com/posts/blog-redis-ziplist.html" target="_blank" rel="noopener">Redis内部数据结构详解(4)——ziplist</a></li><li><a href="http://zhangtielei.com/posts/blog-redis-robj.html" target="_blank" rel="noopener">Redis内部数据结构详解(3)——robj</a></li><li><a href="http://zhangtielei.com/posts/blog-redis-sds.html" target="_blank" rel="noopener">Redis内部数据结构详解(2)——sds</a></li><li><a href="http://zhangtielei.com/posts/blog-redis-dict.html" target="_blank" rel="noopener">Redis内部数据结构详解(1)——dict</a></li><li><a href="http://zhangtielei.com/posts/blog-neural-nets.html" target="_blank" rel="noopener">你需要了解深度学习和神经网络这项技术吗？</a></li><li><a href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261357&idx=1&sn=ebb11a1623e00ca8e6ad55c9ad6b2547#rd" target="_blank" rel="noopener">技术的正宗与野路子</a></li><li><a href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261385&idx=1&sn=56b335b4f33546c5baa41a1c7f1b6551#rd" target="_blank" rel="noopener">论人生之转折</a></li><li><a href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261372&idx=1&sn=89c5b0fa1e9e339ee220d0c30001d01a#rd" target="_blank" rel="noopener">编程世界的熵增原理</a></li><li><a href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261350&idx=1&sn=6cea730ef5a144ac243f07019fb43076#rd" target="_blank" rel="noopener">Android端外推送到底有多烦？</a></li><li><a href="http://zhangtielei.com/posts/blog-series-async-task-4.html" target="_blank" rel="noopener">Android和iOS开发中的异步处理（四）——异步任务和队列</a></li><li><a href="http://mp.weixin.qq.com/s?__biz=MzA4NTg1MjM0Mg==&mid=2657261255&idx=1&sn=01ab92edada77803fc4ab7a575453d97&scene=19#wechat_redirect" target="_blank" rel="noopener">用树型模型管理App数字和红点提示</a></li></ul><p><strong>原创文章，转载请注明出处，并包含下面的二维码！否则拒绝转载！</strong><br><a href="http://zhangtielei.com/posts/blog-redis-skiplist.html" target="_blank" rel="noopener">http://zhangtielei.com/posts/blog-redis-skiplist.html</a></p><p><img src="10.jpg" alt></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文是《&lt;a href=&quot;http://zhangtielei.com/posts/blog-redis-dict.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis内部数据结构详解&lt;/a&gt;》系列的第六篇。在本文中，我们围绕一个&lt;code&gt;Redis&lt;/code&gt;的内部数据结构——&lt;strong&gt;skiplist&lt;/strong&gt;展开讨论。&lt;/p&gt;
&lt;p&gt;Redis里面使用skiplist是为了实现&lt;code&gt;sorted set&lt;/code&gt;这种对外的数据结构。&lt;code&gt;sorted set&lt;/code&gt;提供的操作非常丰富，可以满足非常多的应用场景。这也意味着，sorted set相对来说实现比较复杂。同时，&lt;code&gt;skiplist&lt;/code&gt;这种数据结构对于很多人来说都比较陌生，因为大部分学校里的算法课都没有对这种数据结构进行过详细的介绍。因此，为了介绍得足够清楚，本文会比这个系列的其它几篇花费更多的篇幅。&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://changsk.top/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://changsk.top/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>BitMap对海量无重复的整数排序</title>
    <link href="http://changsk.top/2019/06/26/bitmap/"/>
    <id>http://changsk.top/2019/06/26/bitmap/</id>
    <published>2019-06-26T12:28:52.000Z</published>
    <updated>2019-06-26T12:40:53.973Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>转载自：<a href="https://blog.csdn.net/tkzc_csk/article/details/88661393" target="_blank" rel="noopener">bitmap对海量无重复的整数排序</a></p></blockquote><p>现在有n个<strong>无重复</strong>的正整数（n 小于10的7次方），如果内存限制在<code>1.5M</code>以内，要求对着n个数进行排序。【编程珠玑第一章题目】</p><blockquote><p>很显然，10的7次方个整数占用的空间为10 ^ 7 * 4字节，大约等于40M，而内存限制为1.5M，因此，无法将所有数字加载到内存，所以快速排序、堆排序等高效的排序算法就没法使用。这里可以使用bitmap方式，用1bit表示一个整数，那么，10^7个整数需要10^7位，也就是大约1.25M空间。</p></blockquote><p>如下是bitmap对无重复整数的排序过程。</p><a id="more"></a><h1 id="一次bitmap就可以将所有数据排完"><a href="#一次bitmap就可以将所有数据排完" class="headerlink" title="一次bitmap就可以将所有数据排完"></a>一次bitmap就可以将所有数据排完</h1><p>如果每个整数占一位，可以将所有的整数在内存中表示（如上述提到的那样），那么可以直接一次bitmap排序就完成了，<strong>时间复杂度为O(n)，空间复杂度为O(n位)</strong>。下面分别给出<code>C</code>和<code>C++</code>的bitset方式：</p><h2 id="C语言方式"><a href="#C语言方式" class="headerlink" title="C语言方式"></a>C语言方式</h2><blockquote><p>下面代码以n = 100为例子；n是海量时，只要每个整数1bit可以一次在内存中表示所有整数的情况下，方法一样，将宏定义N的值改为海量数据的上限（比如10^7）即可：</p></blockquote><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//位图排序</span></span><br><span class="line"><span class="meta">#include &lt;iostream&gt;</span></span><br><span class="line"><span class="meta">#include &lt;bitset&gt;</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> WIDTHWORD 32 //一个整数的宽度是32bit</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> SHIFT 5      </span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MASK 0x1F    //0x1f == 31</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 100        //对100个无重复的整数排序</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="title">std</span>;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//申请一个N位的bitmap</span></span><br><span class="line"><span class="keyword">int</span> bitmap[<span class="number">1</span> + N / WIDTHWORD];</span><br><span class="line"> </span><br><span class="line"><span class="comment">//将bitmap的第value设置为1</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">set</span>(<span class="params"><span class="keyword">int</span> <span class="keyword">value</span></span>)</span> &#123;</span><br><span class="line">bitmap[<span class="keyword">value</span> &gt;&gt; SHIFT] |= (<span class="number">1</span> &lt;&lt; (<span class="keyword">value</span> &amp; MASK));</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//清除bitmap第value位上的1:设置为0</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">clear</span>(<span class="params"><span class="keyword">int</span> <span class="keyword">value</span></span>)</span> &#123;</span><br><span class="line">bitmap[<span class="keyword">value</span> &gt;&gt; SHIFT] &amp;= ~(<span class="number">1</span> &lt;&lt; (<span class="keyword">value</span> &amp; MASK));</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//测试bitmap第value位是否为1</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">test</span>(<span class="params"><span class="keyword">int</span> <span class="keyword">value</span></span>)</span> &#123;</span><br><span class="line"><span class="keyword">return</span> bitmap[<span class="keyword">value</span> &gt;&gt; SHIFT] &amp; (<span class="number">1</span> &lt;&lt; (<span class="keyword">value</span> &amp; MASK));</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span>(<span class="params"></span>)</span> &#123;</span><br><span class="line"><span class="keyword">int</span> a[] = &#123;<span class="number">12</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">89</span>, <span class="number">64</span>, <span class="number">49</span>, <span class="number">77</span>, <span class="number">91</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">32</span>, <span class="number">50</span>, <span class="number">99</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> length = <span class="keyword">sizeof</span>(a) / <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">//将bitmap所有位设置为0</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">clear(i);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">//bitmap中将待排序数组中值所在的位设置为1</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length; i++)</span><br><span class="line"><span class="keyword">set</span>(a[i]);</span><br><span class="line"> </span><br><span class="line"><span class="comment">//输出排序后的结果</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line"><span class="keyword">if</span> (test(i))</span><br><span class="line">cout &lt;&lt; i &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如上代码中：<br>N表示待排序整数的上限，例如本题要求的10^7。那么申请一个N位大小的bitmap：</p><p><code>int bitmap[1 + N / WIDTHWORD];</code><br>设置、清除、测试函数的含义可以参考文章：<a href="http://blog.163.com/xb_stone_yinyang/blog/static/2118160372013625112558579/，" target="_blank" rel="noopener">http://blog.163.com/xb_stone_yinyang/blog/static/2118160372013625112558579/，</a><br>下面给出这几个函数的简要解释：</p><ul><li>对于一个整数value，要将其对应到bitmap中的第value位，如果设置第value位为1呢？</li></ul><p>看设置函数：<code>value &gt;&gt; SHIFT 是找到value在bitmap中对应的是第几个int型数的位置</code>，例如整数100，它对应的是int数组（也就是bitmap）的第 100 &gt;&gt; 5 == 100 / 32 == 3个int型的位置（从0开始计数，每个int型占据32位）；<code>然后再在int数组（也就是bitmap）的第3个位置中寻找需要将第几位设置为1</code>： 1 &lt;&lt; (value &amp; 0x1f) == 1 &lt;&lt; 100 &amp; 31 == 1 &lt;&lt; 4，即要将1左移四位就是要设置为1的那一位；bitmap[value &gt;&gt; SHIFT] |= (1 &lt;&lt; (value &amp; MASK)); 最终完成将bitmap的第100位设置为1。</p><ul><li>对于一个整数value，如何将其对应到bitmap中的那位的上的1清除掉呢？</li></ul><p>看清除函数，和设置函数一样，value &gt;&gt; SHIFT 是找到value在bitmap中对应的是第几个整型的位置；然后，1 &lt;&lt; (value &amp; 0x1f)在找到的那个整型的位置中判断要将该字节的哪一位设置为0；bitmap[value &gt;&gt; SHIFT] &amp;= ~(1 &lt;&lt; (value &amp; MASK));完成最终清除工作。</p><ul><li>对于一个整数value，如何测试在bitmap中是否包含该数，也就是bitmap中第value位上是否为1？</li></ul><p>也是先找到value对应bitmap中第几个整型位置，然后在该位置中找到对应的位，再看该位上是否为1，为1表示bitmap中包含value。</p><p>程序排序结果：<br><img src="1.jpg" alt="在这里插入图片描述"></p><h2 id="使用C-的bitset"><a href="#使用C-的bitset" class="headerlink" title="使用C++的bitset"></a>使用C++的bitset</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;bitset&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> N 100</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="keyword">int</span> a[] = &#123;<span class="number">12</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">89</span>, <span class="number">64</span>, <span class="number">49</span>, <span class="number">77</span>, <span class="number">91</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">32</span>, <span class="number">50</span>, <span class="number">99</span>&#125;;</span><br><span class="line">       <span class="keyword">int</span> length = <span class="keyword">sizeof</span>(a) / <span class="keyword">sizeof</span>(<span class="keyword">int</span>);</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">       <span class="comment">//直接使用C++bitset，申请Nbit的空间，每一位均设置为0</span></span><br><span class="line">       <span class="built_in">bitset</span>&lt;N&gt; bitmap; </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">       <span class="comment">//遍历待排序数组，将bitmap中对应位设置为1</span></span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length; i++)</span><br><span class="line">            bitmap.<span class="built_in">set</span>(a[i], <span class="number">1</span>);</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">       <span class="comment">//输入排序结果</span></span><br><span class="line">       <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">            <span class="keyword">if</span> (bitmap[i])</span><br><span class="line">               <span class="built_in">cout</span> &lt;&lt; i &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">       &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="需要多次bitmap排序"><a href="#需要多次bitmap排序" class="headerlink" title="需要多次bitmap排序"></a>需要多次bitmap排序</h1><blockquote><p>如果上限N更大或者进一步限制内存大小（例如，将内存限制在0.5M之内），那么一次bitmap就不能将所有数据排序。需要多次bitmap排序。</p><p>例如上面排序小于100的一些数，我们上面的一次bitmap，是申请100位的bitmap；但是，如果限制我们只能使用30位bitmap，那么就需要排序100 / 30 + 1次：第一次排序0 ~ 29之间的数，第二次排序30 ~ 59之间的数，第三次排序60 ~ 89之间的数，第四次排序90 ~ 100之间的数。如果是k次bitmap排序，那么时间复杂度为O(kn)，空间开销为O(n / k 位).</p></blockquote><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">下面只给出C++方式，C方式类似：</span><br><span class="line"></span><br><span class="line">```c</span><br><span class="line">int main() &#123;</span><br><span class="line">      int a[] = &#123;<span class="number">12</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">89</span>, <span class="number">64</span>, <span class="number">49</span>, <span class="number">77</span>, <span class="number">91</span>, <span class="number">3</span>, <span class="number">0</span>, <span class="number">32</span>, <span class="number">50</span>, <span class="number">99</span>&#125;;</span><br><span class="line">      int length = sizeof(a) / sizeof(int);</span><br><span class="line"> </span><br><span class="line">      <span class="comment">//假设还是有小于100的不重复整数需要排序，但是</span></span><br><span class="line">      <span class="comment">//不能申请100位空间，只能申请30位空间，那么，需要</span></span><br><span class="line">      <span class="comment">//排序的次数如下：</span></span><br><span class="line">      int sort_times = N / <span class="number">30</span> + <span class="number">1</span>;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">      <span class="comment">//那么，第一趟先排序0-29，第二趟排序30-59，</span></span><br><span class="line">      <span class="comment">//第三趟排序60-89，第四趟排序剩下的</span></span><br><span class="line">      bitset&lt;<span class="number">30</span>&gt; bitmap;             <span class="comment">//只能申请30位的bitmap</span></span><br><span class="line">      for (int times = <span class="number">0</span>; times &lt; sort_times; ++times) &#123;   <span class="comment">//一共进行四趟排序</span></span><br><span class="line">           bitmap.reset();                             <span class="comment">//记得每次排序前将bitmap清空为0</span></span><br><span class="line">           for (int i = <span class="number">0</span>; i &lt; length; i++) &#123;</span><br><span class="line">                  if (a[i] &gt;= <span class="number">30</span> * times &amp;&amp; a[i] &lt; <span class="number">30</span> * (times + <span class="number">1</span>))  </span><br><span class="line">                         bitmap.set(a[i] - <span class="number">30</span> * times);</span><br><span class="line">           &#125;</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line">           for (int i = <span class="number">0</span>; i &lt; <span class="number">30</span>; ++i) &#123;</span><br><span class="line">                if (bitmap[i])</span><br><span class="line">                      cout &lt;&lt; i + <span class="number">30</span> * times &lt;&lt; <span class="string">" "</span>;</span><br><span class="line">           &#125;</span><br><span class="line">      &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="如果每个整数最多出现m次，如何排序"><a href="#如果每个整数最多出现m次，如何排序" class="headerlink" title="如果每个整数最多出现m次，如何排序?"></a>如果每个整数最多出现m次，如何排序?</h1><p>上述两部分讨论的是如果整数是不重复时的排序，那么，如果海量整数，每个整数<strong>允许重复</strong>，但是重复次数不超过m（例如m == 10），如何排序？<br>方法：如果每个整数重复出现次数不超过10次，那么，可以用4位表示一个整数，<strong>用这四位统计该数出现次数</strong>，然后排序后输出该数时，输出m次即可。</p><h1 id="除了排序，bitmap的其他用途"><a href="#除了排序，bitmap的其他用途" class="headerlink" title="除了排序，bitmap的其他用途"></a>除了排序，bitmap的其他用途</h1><p>如上，bitmap可以用于不重复正整数排序，那么，bitmap其他用途：<br>1、找出不重复数：<br><a href="https://blog.csdn.net/v_july_v/article/details/7382693" target="_blank" rel="noopener">在2.5亿个整数中找出不重复的整数，内存不足以容纳这2.5亿个整数。</a><br>2、判断某数是否存在于海量整数中：<br><a href="https://blog.csdn.net/v_july_v/article/details/7382693" target="_blank" rel="noopener">给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中？</a></p>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;转载自：&lt;a href=&quot;https://blog.csdn.net/tkzc_csk/article/details/88661393&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;bitmap对海量无重复的整数排序&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;现在有n个&lt;strong&gt;无重复&lt;/strong&gt;的正整数（n 小于10的7次方），如果内存限制在&lt;code&gt;1.5M&lt;/code&gt;以内，要求对着n个数进行排序。【编程珠玑第一章题目】&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;很显然，10的7次方个整数占用的空间为10 ^ 7 * 4字节，大约等于40M，而内存限制为1.5M，因此，无法将所有数字加载到内存，所以快速排序、堆排序等高效的排序算法就没法使用。这里可以使用bitmap方式，用1bit表示一个整数，那么，10^7个整数需要10^7位，也就是大约1.25M空间。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如下是bitmap对无重复整数的排序过程。&lt;/p&gt;
    
    </summary>
    
      <category term="数据结构" scheme="http://changsk.top/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
    
      <category term="BitMap" scheme="http://changsk.top/tags/BitMap/"/>
    
  </entry>
  
  <entry>
    <title>java中创建实例对象的方式</title>
    <link href="http://changsk.top/2019/06/26/java-create-instance/"/>
    <id>http://changsk.top/2019/06/26/java-create-instance/</id>
    <published>2019-06-26T10:00:34.000Z</published>
    <updated>2019-06-26T10:08:53.262Z</updated>
    
    <content type="html"><![CDATA[<p>1、关键字 <strong>new</strong>。<strong>工厂模式</strong>是对这种方式的包装；</p><p>2、类实现克隆接口，克隆一个实例。<strong>原型模式</strong>是一个应用实例；</p><p>3、用该类的加载器，newInstance。<strong>java的反射</strong>，反射使用实例：Spring的依赖注入、切面编程中动态代理</p><p>4、sun.misc.Unsafe类，allocateInstance方法创建一个实例。（Java官方也不建议直接使用的Unsafe类，据说Oracle正在计划从Java 9中去掉Unsafe类）</p><p>5、实现序列化接口的类，通过IO流<strong>反序列化</strong>读取一个类，获得实例。</p><blockquote><p>参考：<br><a href="https://blog.csdn.net/lizhen54/article/details/74544801/" target="_blank" rel="noopener">Java创建类的实例的几种方法</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;1、关键字 &lt;strong&gt;new&lt;/strong&gt;。&lt;strong&gt;工厂模式&lt;/strong&gt;是对这种方式的包装；&lt;/p&gt;
&lt;p&gt;2、类实现克隆接口，克隆一个实例。&lt;strong&gt;原型模式&lt;/strong&gt;是一个应用实例；&lt;/p&gt;
&lt;p&gt;3、用该类的加载器，newInst
      
    
    </summary>
    
      <category term="Java" scheme="http://changsk.top/categories/Java/"/>
    
    
      <category term="java" scheme="http://changsk.top/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>Redis中基本数据类型与内部存储结构</title>
    <link href="http://changsk.top/2019/06/26/redis-storage-structure/"/>
    <id>http://changsk.top/2019/06/26/redis-storage-structure/</id>
    <published>2019-06-26T08:04:44.000Z</published>
    <updated>2019-06-26T09:09:31.855Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自：<a href="https://www.jianshu.com/p/f09480c05e42" target="_blank" rel="noopener">Redis-基本数据类型与内部存储结构</a></p><h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p><code>Redis</code>是典型的<code>Key-Value</code>类型数据库，<strong>Key为字符类型</strong>，<strong>Value的类型常用的为五种类型：String、Hash 、List 、 Set 、 Ordered Set</strong></p><a id="more"></a><h2 id="Redis内部内存管理"><a href="#Redis内部内存管理" class="headerlink" title="Redis内部内存管理"></a>Redis内部内存管理</h2><p><img src="1.jpg" alt="img"></p><h3 id="redisObject-核心对象"><a href="#redisObject-核心对象" class="headerlink" title="redisObject 核心对象"></a>redisObject 核心对象</h3><blockquote><p>Redis 内部使用一个 redisObject 对象来表示所有的 key 和 value。</p></blockquote><ol><li>type ：代表一个 value 对象具体是何种数据类型。</li><li>encoding ：是不同数据类型在 redis 内部的存储方式，比如：type=string 代表 value 存储的是一个普通字符串，那么对应的 encoding 可以是 raw 或者是 int，<strong>如果是 int 则代表实际 redis 内部是按数值型类存储和表示这个字符串的，当然前提是这个字符串本身可以用数值表示，比如：”123” “456”这样的字符串。</strong></li><li>vm 字段：只有打开了 Redis 的虚拟内存功能，此字段才会真正的分配内存，该功能默认是关闭状态的。 Redis 使用 redisObject 来表示所有的 key/value 数据是比较浪费内存的，当然这些内存管理成本的付出主要也是为了给 Redis 不同数据类型提供一个统一的管理接口，实际作者也提供了多种方法帮助我们尽量节省内存使用。</li></ol><h2 id="Key（键值）"><a href="#Key（键值）" class="headerlink" title="Key（键值）"></a>Key（键值）</h2><blockquote><p>官网Key链接：<a href="https://link.jianshu.com?t=https://redis.io/commands#generic" target="_blank" rel="noopener">https://redis.io/commands#generic</a></p></blockquote><h3 id="过期删除"><a href="#过期删除" class="headerlink" title="过期删除"></a>过期删除</h3><p>过期数据的清除从来不容易，为每一条key设置一个timer，到点立刻删除的消耗太大，每秒遍历所有数据消耗也大，<strong>Redis使用了一种相对务实的做法： 当client主动访问key会先对key进行超时判断，过时的key会立刻删除。 如果clien永远都不再get那条key呢？ 它会在Master的后台，每秒10次的执行如下操作： 随机选取100个key校验是否过期，如果有25个以上的key过期了，立刻额外随机选取下100个key(不计算在10次之内)。</strong>可见，如果过期的key不多，它最多每秒回收200条左右，如果有超过25%的key过期了，它就会做得更多，但只要key不被主动get，它占用的内存什么时候最终被清理掉只有天知道。</p><h3 id="常用操作"><a href="#常用操作" class="headerlink" title="常用操作"></a>常用操作</h3><ol><li>Key的长度限制：<strong>Key的最大长度不能超过1024字节</strong>，在实际开发时不要超过这个长度，但是Key的命名不能太短，要能唯一标识缓存的对，作者建议<strong>按照在关系型数据库中的库表唯一标识字段的方式来命令Key的值，用分号分割不同数据域，用点号作为单词连接。</strong></li><li>Key的查询：<strong>Keys</strong>，返回匹配的key，支持通配符如 “<code>keys a*</code>” 、 “<code>keys a?c</code>”，<strong>但不建议在生产环境大数据量下使用</strong>。</li><li>对Key对应的Value进行的排序：<strong>Sort命令对集合按数字或字母顺序排序后返回或另存为list</strong>，还可以关联到外部key等。因为<em>复杂度是最高的O(N+Mlog(M))*</em>(N是集合大小，M 为返回元素的数量)，有时会安排到slave上执行。官网链接<a href="https://link.jianshu.com?t=https://redis.io/commands/sort" target="_blank" rel="noopener">https://redis.io/commands/sort</a></li><li>Key的超时操作：Expire（指定失效的秒数）/ExpireAt（指定失效的时间戳）/Persist（持久化）/TTL（返回还可存活的秒数），关于Key超时的操作。默认以秒为单位，也有p字头的以毫秒为单位的版本</li></ol><h2 id="String（字符串类型的Value）"><a href="#String（字符串类型的Value）" class="headerlink" title="String（字符串类型的Value）"></a>String（字符串类型的Value）</h2><blockquote><p>可以是String，也可是是任意的byte[]类型的数组，如图片等。<strong>String 在 redis 内部存储默认就是一个字符串，被 redisObject 所引用，当遇到 incr,decr 等操作时会转成数值型进行计算，此时 redisObject 的 encoding 字段为int。</strong><br> <a href="https://link.jianshu.com?t=https://redis.io/commands#string" target="_blank" rel="noopener">https://redis.io/commands#string</a></p></blockquote><ol><li>大小限制：最大为<strong>512Mb</strong>，基本可以<strong>存储任意图片</strong>啦。</li><li>常用命令的<strong>时间复杂度为O(1)，读写一样的快。</strong></li><li><strong>对String代表的数字进行增减操作</strong>（没有指定的Key则设置为0值，然后在进行操作）：Incr/IncrBy/IncrByFloat/Decr/DecrBy（原子性），** 可以用来做计数器，做自增序列，也可以用于限流，令牌桶计数等**。key不存在时会创建并贴心的设原值为0。IncrByFloat专门针对float。。</li><li>设置Value的安全性：SetNx命令仅当key不存在时才Set（原子性操作）。<strong>可以用来选举Master或做分布式锁：所有Client不断尝试使用SetNx master myName抢注Master，成功的那位不断使用Expire刷新它的过期时间。如果Master倒掉了key就会失效，剩下的节点又会发生新一轮抢夺。</strong>SetEx， Set + Expire 的简便写法，p字头版本以毫秒为单位。</li><li>获取：GetSet（原子性）， 设置新值，返回旧值。比如一个按小时计算的计数器，可以用GetSet获取计数并重置为0。这种指令在服务端做起来是举手之劳，客户端便方便很多。MGet/MSet/MSetNx， 一次get/set多个key。</li><li>其他操作：Append/SetRange/GetRange/StrLen，对文本进行扩展、替换、截取和求长度，只对特定数据格式如字段定长的有用，json就没什么用。</li><li>BitMap的用法：GetBit/SetBit/BitOp,与或非/BitCount， <strong>BitMap的玩法，比如统计今天的独立访问用户数时，每个注册用户都有一个offset，他今天进来的话就把他那个位设为1，用BitCount就可以得出今天的总人数</strong>。</li></ol><h2 id="Hash（HashMap，哈希映射表）"><a href="#Hash（HashMap，哈希映射表）" class="headerlink" title="Hash（HashMap，哈希映射表）"></a>Hash（HashMap，哈希映射表）</h2><blockquote><p>Redis 的 Hash 实际是内部存储的 Value 为一个 HashMap，并提供了直接存取这个 Map 成员的接口。Hash将对象的各个属性存入Map里，可以只读取/更新对象的某些属性。另外不同的模块可以只更新自己关心的属性而不会互相并发覆盖冲突。</p></blockquote><blockquote><p><img src="2.jpg" alt="img"></p></blockquote><blockquote><p> 不同程序通过 key（用户 ID） + field（属性标签）就可以并发操作各自关心的属性数据</p><p><a href="https://redis.io/commands#hash" target="_blank" rel="noopener">https://redis.io/commands#hash</a></p></blockquote><h3 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h3><p>Redis Hash 对应 Value 内部实际就是一个 HashMap，实际这里会有2种不同实现，** 这个 Hash 的成员比较少时 Redis <strong>为了节省内存会采用类似一维数组的方式来紧凑存储</strong>，而不会采用真正的 HashMap 结构，对应的 value redisObject 的 encoding 为 <code>zipmap</code>，<strong>当成员数量增大时会自动转成真正的 HashMap</strong>，此时 encoding 为 ht**。一般操作复杂度是O(1)，要同时操作多个field时就是O(N)，N是field的数量。</p><h3 id="常用操作-1"><a href="#常用操作-1" class="headerlink" title="常用操作"></a>常用操作</h3><ol><li><p>O(1)操作：<strong>hget</strong>、<strong>hset</strong>等等</p></li><li><p>O(n)操作：<strong>hgetallRedis</strong> 可以直接取到全部的属性数据，但是如果内部 Map 的成员很多，那么涉及到遍历整个内部 Map 的操作，</p><p>由于 <strong>Redis 单线程模型</strong>的缘故，这个遍历操作可能会比较耗时，而另其它客户端的请求完全不响应，这点需要格外注意。</p></li></ol><p>   <img src="3.jpg" alt="img"></p><h2 id="List（双向链表）"><a href="#List（双向链表）" class="headerlink" title="List（双向链表）"></a>List（双向链表）</h2><blockquote><p>Redis list 的应用场景非常多，也是 Redis 最重要的数据结构之一，<strong>比如 twitter 的关注列表，粉丝列表等都可以用 Redis 的 list 结构来实现，还提供了生产者消费者阻塞模式（B开头的命令,block,表示阻塞），常用于任务队列，消息队列等</strong>。</p></blockquote><h3 id="实现方式"><a href="#实现方式" class="headerlink" title="实现方式"></a>实现方式</h3><p>Redis list 的实现为一个<strong>双向链表</strong>，即可以支持<strong>反向查找和遍历</strong>，更方便操作，不过带来了部分额外的内存开销，Redis 内部的很多实现，包括<strong>发送缓冲队列等</strong>也都是用的这个数据结构。</p><h3 id="用作消息队列中防止数据丢失的解决方法"><a href="#用作消息队列中防止数据丢失的解决方法" class="headerlink" title="用作消息队列中防止数据丢失的解决方法"></a>用作消息队列中防止数据丢失的解决方法</h3><blockquote><p>如果消费者把job给Pop走了又没处理完就死机了怎么办？</p></blockquote><ol><li>消息生产者保证不丢失</li></ol><blockquote><p>加多一个sorted set，分发的时候同时发到list与sorted set，以分发时间为score，用户把job做完了之后要用ZREM消掉sorted set里的job，并且定时从sorted set中取出超时没有完成的任务，重新放回list。 如果发生重复可以在sorted set中在查询确认一遍，或者将消息的消费接口设计成幂等性。</p></blockquote><ol start="2"><li>消息消费者保证不丢失</li></ol><blockquote><p>为每个worker多加一个的list，弹出任务时改用RPopLPush，将job同时放到worker自己的list中，完成时用LREM消掉。如果集群管理(如zookeeper)发现worker已经挂掉，就将worker的list内容重新放回主list</p></blockquote><h3 id="常用操作-2"><a href="#常用操作-2" class="headerlink" title="常用操作"></a>常用操作</h3><ol><li><p>复合操作：RPopLPush/ BRPopLPush，弹出来返回给client的同时，把自己又推入另一个list，是原子操作。</p><blockquote><p><strong>RPUSH key value [value …]</strong></p><p>将一个或多个值 <code>value</code> 插入到列表 <code>key</code> 的表尾(最右边)。</p></blockquote><blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash"> LRANGE KEY_NAME START END</span></span><br><span class="line"><span class="meta">&gt;</span><span class="bash"></span></span><br></pre></td></tr></table></figure></blockquote><blockquote><p>Redis Lrange 返回列表中指定区间内的元素，区间以偏移量 START 和 END(从0开始) 指定。 其中 0 表示列表的第一个元素， 1 表示列表的第二个元素，以此类推。 你也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。</p></blockquote></li></ol><p>   <img src="3.jpg" alt="img"></p><ol start="2"><li>按值进行的操作：<strong>LRem</strong>(按值删除元素)、<strong>LInsert</strong>(插在某个值的元素的前后)，<strong>复杂度是O(N)</strong>，N是List长度，因为List的值不唯一，所以要遍历全部元素，而Set只要O(log(N))。</li></ol><p>   <img src="4.jpg" alt="img"></p><ol start="3"><li>按下表进行操作（下标从0开始，队列从左到右算，下标为负数时则从右到左，-1为右端第一个元素）</li></ol><blockquote><p>时间复杂度为O(N)</p></blockquote><ul><li><p>LSet ：按下标设置元素值。（N为List的长度）</p></li><li><p>LIndex：按下标返回元素。（N为index的值）</p></li><li><p>LTrim：限制List的大小，保留指定范围的元素。（N是移除元素的个数）</p></li></ul><p>  <img src="5.jpg" alt="img"></p><ul><li>LRange：返回列表内指定范围下标的元素，常用于分页。（N = start+range）</li></ul><p>  <img src="6.jpg" alt="img"></p><h2 id="set（HashSet）"><a href="#set（HashSet）" class="headerlink" title="set（HashSet）"></a>set（HashSet）</h2><blockquote><p>Set就是HashSet，可以将重复的元素随便放入而Set会自动去重，底层实现也是HashMap，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。</p></blockquote><h3 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h3><p>set 的内部实现是一个 <strong>value 永远为 null 的 HashMap</strong>，实际就是通过计算 hash 的方式来快速排重的，这也是 set 能提供判断一个成员是否在集合内的原因。</p><h3 id="常用操作-3"><a href="#常用操作-3" class="headerlink" title="常用操作"></a>常用操作</h3><ol><li>增删改查：<code>SAdd/SRem/SIsMember/SCard/SMove/SMembers</code>等等。除了SMembers都是O(1)。</li><li>集合操作：<code>SInter/SInterStore/SUnion/SUnionStore/SDiff/SDiffStore</code>，各种集合操作。交集运算可以用来<strong>显示在线好友(在线用户 交集 好友列表)，共同关注(两个用户的关注列表的交集)</strong>。O(N)，并集和差集的N是集合大小之和，交集的N是小的那个集合的大小的2倍。</li></ol><h2 id="Sorted-Set（插入有序Set集合）"><a href="#Sorted-Set（插入有序Set集合）" class="headerlink" title="Sorted Set（插入有序Set集合）"></a>Sorted Set（插入有序Set集合）</h2><blockquote><p>set 不是自动有序的，而** sorted set 可以通过用户额外提供一个优先级（score）的参数来为成员排序<strong>，</strong>并且是插入有序的，即自动排序<strong>。当你需要一个有序的并且不重复的集合列表，那么可以选择 sorted set 数据结构，比如 twitter 的 public **timeline 可以以发表时间作为 score 来存储，这样获取时就是自动按时间排好序的</strong>。</p></blockquote><h3 id="实现方式-1"><a href="#实现方式-1" class="headerlink" title="实现方式"></a>实现方式</h3><blockquote><p><strong>内部使用 HashMap 和跳跃表（SkipList）来保证数据的存储和有序</strong></p></blockquote><p><code>Sorted Set</code>的实现是<strong>HashMap(element-&gt;score, 用于实现ZScore及判断element是否在集合内)，和SkipList(score-&gt;element,按score排序)的混合体</strong>。<code>SkipList有点像平衡二叉树那样，不同范围的score被分成一层一层，每层是一个按score排序的链表。</code></p><h3 id="常用操作-4"><a href="#常用操作-4" class="headerlink" title="常用操作"></a>常用操作</h3><blockquote><p>ZAdd/ZRem是O(log(N))；ZRangeByScore/ZRemRangeByScore是O(log(N)+M)，N是Set大小，M是结果/操作元素的个数。复杂度的log取对数很关键，可以使，1000万大小的Set，复杂度也只是几十不到。但是，如果一次命中很多元素M很大则复杂度很高。</p></blockquote><ol><li><code>ZRange/ZRevRange</code>，按排序结果的范围返回元素列表，可以为正数与倒数。</li><li><code>ZRangeByScore/ZRevRangeByScore</code>，按score的范围返回元素，可以为正数与倒数。</li><li><code>ZRemRangeByRank/ZRemRangeByScore</code>，按排序/按score的范围限删除元素。</li><li><code>ZCount</code>，统计按score的范围的元素个数。</li><li><code>ZRank/ZRevRank</code> ，显示某个元素的正/倒序的排名。</li><li><code>ZScore/ZIncrby</code>，显示元素的Score值/增加元素的Score。</li><li><code>ZAdd(Add)/ZRem(Remove)/ZCard(Count)</code>，ZInsertStore(交集)/ZUnionStore(并集)，与Set相比，少了IsMember和差集运算。</li></ol><h2 id="Redis使用与内存优化"><a href="#Redis使用与内存优化" class="headerlink" title="Redis使用与内存优化"></a>Redis使用与内存优化</h2><blockquote><p>上面的一些实现上的分析可以看出 redis 实际上的内存管理成本非常高，即占用了过多的内存，属于用<strong>空间换时间</strong>。作者对这点也非常清楚，所以提供了一系列的参数和手段来控制和节省内存</p></blockquote><h3 id="建议不要开启VM（虚拟内存）选项"><a href="#建议不要开启VM（虚拟内存）选项" class="headerlink" title="建议不要开启VM（虚拟内存）选项"></a>建议不要开启VM（虚拟内存）选项</h3><blockquote><p>VM 选项是作为 Redis 存储超出物理内存数据的一种数据在内存与磁盘换入换出的一个持久化策略，将严重地拖垮系统的运行速度，所以要关闭 VM 功能，请检查你的 redis.conf 文件中 vm-enabled 为 no。</p></blockquote><h3 id="设置最大内存选项"><a href="#设置最大内存选项" class="headerlink" title="设置最大内存选项"></a>设置最大内存选项</h3><p>最好设置下 redis.conf 中的 <code>maxmemory</code> 选项，该选项是告诉 Redis <strong>当使用了多少物理内存后就开始拒绝后续的写入请求</strong>，<strong>该参数能很好的保护好你的 Redis 不会因为使用了过多的物理内存而导致 swap，最终严重影响性能甚至崩溃。</strong></p><blockquote><p>一般还需要设置内存饱和回收策略</p></blockquote><ol><li>volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰</li><li>volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰</li><li>volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰</li><li>allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰</li><li>allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰</li><li>no-enviction（驱逐）：禁止驱逐数据</li></ol><h3 id="控制内存使用的参数"><a href="#控制内存使用的参数" class="headerlink" title="控制内存使用的参数"></a>控制内存使用的参数</h3><blockquote><p>Redis 为不同数据类型分别提供了一组参数来控制内存使用</p></blockquote><ol><li>Hash</li></ol><blockquote><p>redis.conf 配置文件中下面2项</p></blockquote><ul><li>*<em>hash-max-zipmap-entries 64 *</em></li></ul><blockquote><p>含义是当 value 这个 Map 内部不超过多少个成员时会采用<strong>线性紧凑格式</strong>存储，默认是64，即 <strong>value 内部有64个以下的成员就是使用线性紧凑存储zipmap，超过该值自动转成真正的 HashMap(ht)。</strong></p></blockquote><ul><li><strong>hash-max-zipmap-value 512</strong></li></ul><blockquote><p>hash-max-zipmap-value 含义是当 value 这个 Map 内部的每个成员值长度不超过<br> 多少字节就会采用线性紧凑存储zipmap来节省空间。</p></blockquote><p><strong>以上2个条件任意一个条件超过设置值都会转换成真正的 HashMap</strong>，也就不会再节省内存了，但是也不是越大越好（空间和查改效率需要根据实际情况来权衡）</p><ol start="2"><li>List</li></ol><blockquote></blockquote><ul><li><strong>list-max-ziplist-entries 512</strong><br>list 数据类型多少节点以下会采用去指针的紧凑存储格式ziplist</li><li><strong>list-max-ziplist-value 64</strong><br>list 数据类型节点值大小小于多少字节会采用紧凑存储格式ziplist。</li></ul><ol start="3"><li>Set</li></ol><blockquote></blockquote><ul><li><strong>set-max-intset-entries 512</strong><br>set 数据类型内部数据如果全部是数值型，且包含多少节点以下会采用紧凑格式存储</li></ul><h3 id="Redis内部的优化"><a href="#Redis内部的优化" class="headerlink" title="Redis内部的优化"></a>Redis内部的优化</h3><ol><li>Redis 内部实现没有对内存分配方面做过多的优化，在一定程度上会存在<strong>内存碎片</strong>，不过大多数情况下这个不会成为 Redis 的性能瓶颈。</li><li>Redis 缓存了<strong>一定范围的常量数字</strong>作为资源共享，在很多数据类型是数值型则能极大减少内存开销，默认为1-10000，可以重新编译配置修改源代码中的一行宏定义 <code>REDIS_SHARED_INTEGERS</code>。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>根据业务需要选择合适的数据类型，并为不同的应用场景<strong>设置相应的紧凑存储参数</strong>。</li><li><strong>当业务场景不需要数据持久化时，关闭所有的持久化方式可以获得最佳的性能以及最大的内存使用量。</strong></li><li>如果需要使用持久化，<strong>根据是否可以容忍重启丢失部分数据在快照方式与语句追加方式之间选择其一</strong>，不要使用虚拟内存以及 diskstore 方式。</li><li><strong>不要让你的 Redis 所在机器物理内存使用超过实际内存总量的3/5</strong>。</li></ol><blockquote><p>Redis 的持久化使用了 Buffer IO ，所谓 Buffer IO 是指 Redis 对持久化文件的写入和读取操作都会使用物理内存的 Page Cache，而当 Redis 的持久化文件过大操作系统会进行Swap，这时你的系统就会有内存还有余量但是系统不稳定或者崩溃的风险。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自：&lt;a href=&quot;https://www.jianshu.com/p/f09480c05e42&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Redis-基本数据类型与内部存储结构&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;概览&quot;&gt;&lt;a href=&quot;#概览&quot; class=&quot;headerlink&quot; title=&quot;概览&quot;&gt;&lt;/a&gt;概览&lt;/h2&gt;&lt;p&gt;&lt;code&gt;Redis&lt;/code&gt;是典型的&lt;code&gt;Key-Value&lt;/code&gt;类型数据库，&lt;strong&gt;Key为字符类型&lt;/strong&gt;，&lt;strong&gt;Value的类型常用的为五种类型：String、Hash 、List 、 Set 、 Ordered Set&lt;/strong&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://changsk.top/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://changsk.top/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Nagle算法</title>
    <link href="http://changsk.top/2019/06/26/nagle/"/>
    <id>http://changsk.top/2019/06/26/nagle/</id>
    <published>2019-06-26T03:27:37.000Z</published>
    <updated>2019-06-26T03:44:50.969Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Nagle算法</strong>用于<code>对缓冲区内的一定数量的消息进行自动连接</code>。该处理过程(称为Nagling)，通过<code>减少必须发送的封包的数量</code>，提高了网络应用程序系统的效率。</p><a id="more"></a><h2 id="Nagle算法的规则"><a href="#Nagle算法的规则" class="headerlink" title="Nagle算法的规则"></a>Nagle算法的规则</h2><p>  （可参考<code>tcp_output.c</code>文件里<code>tcp_nagle_check</code>函数注释）：</p><ol><li><p>如果包长度达到<strong>MSS</strong>，则允许发送；</p><blockquote><p>MSS是最大分段大小Maxitum Segment Size ，TCP双方建立连接的时候可以协商<br>MTU是最大传输单元Maxitum Transmission Unit</p></blockquote></li><li><p>如果该包含有FIN，则允许发送；</p></li><li><p>设置了TCP_NODELAY选项，则允许发送；</p></li><li><p>未设置TCP_CORK选项时，若所有发出去的包均被确认，或所有发出去的小数据包(包长度小于MSS)均被确认，则允许发送。</p><blockquote><p>对于规则4，就是说一个TCP连接上最多只能有一个未被确认的小数据包，在该分组的确认到达之前，不能发送其他的小数据包。如果某个小分组的确认被延迟了，那么后续小分组的发送就会相应的延迟。也就是说延迟确认影响的并不只是被延迟确认的那个数据包，而是后续所有的应答包。</p></blockquote></li></ol><h2 id="Nagle算法的门槛"><a href="#Nagle算法的门槛" class="headerlink" title="Nagle算法的门槛"></a>Nagle算法的门槛</h2><p>实际上<code>Nagle</code>算法并不是很复杂，他的主要职责是<code>数据的累积</code>，实际上有三个门槛：</p><ol><li>缓冲区中的字节数达到了一定量；</li><li>等待了一定的时间（一般的Nagle算法都是等待200ms）；</li><li>紧急数据发送。</li></ol><p>这三个门槛的任何一个达到都必须发送数据了。一般情况下，如果数据流量很大，第二个条件是永远不会起作用的，但当发送小的数据包时，第二个门槛就发挥作用了，防止数据被无限的缓存在缓冲区不是好事情哦。 </p><h2 id="Nagle算法的选项配置"><a href="#Nagle算法的选项配置" class="headerlink" title="Nagle算法的选项配置"></a>Nagle算法的选项配置</h2><p><code>TCP_NODELAY</code>和<code>TCP_CORK</code>都是<strong>禁用Nagle算法</strong>，只不过<code>NODELAY</code>完全关闭而<code>TCP_CORK</code>完全由自己决定发送时机。<strong>Linux文档上说两者不要同时设置。</strong></p><h3 id="TCP-NODELAY-选项"><a href="#TCP-NODELAY-选项" class="headerlink" title="TCP_NODELAY 选项"></a>TCP_NODELAY 选项</h3><p>设置该选项: <code>setsockopt(s,IPPRO_TCP,TCP_NODELAY,(const char*)&amp;on,sizeof(int));</code><br>读取该选项: <code>getsockopt(s,IPPRO_TCP,TCP_NODELAY,(char*)&amp;on,&amp;optlen);</code></p><p>   默认情况下, 发送数据采用<code>Nagle 算法</code>。<strong>Nagle 算法是指发送方发送的数据不会立即发出,而是先放在缓冲区, 等缓存区满了再发出. 发送完一批数据后, 会等待接收方对这批数据的回应,然后再发送下一批数据。</strong> </p><blockquote><p>Nagle 算法适用于发送方需要发送大批量数据, 并且接收方会及时作出回应的场合, 这种算法通过减少传输数据的次数来提高通信效率。如果发送方持续地发送小批量的数据, 并且接收方不一定会立即发送响应数据, 那么Nagle算法会使发送方运行很慢。</p></blockquote><h3 id="TCP-CORK选项"><a href="#TCP-CORK选项" class="headerlink" title="TCP_CORK选项"></a>TCP_CORK选项</h3><p>   <code>TCP链接的过程中，默认开启Nagle算法</code>，进行<strong>小包发送的优化</strong>。优化网络传输，兼顾网络延时和网络拥塞。这个时候可以置位<code>TCP_NODELAY关闭Nagle算法</code>，<strong>有数据包的话直接发送保证网络时效性</strong>。</p><p> 在进行大量数据发送的时候可以<code>置位TCP_CORK关闭Nagle算法保证网络利用性</code>。尽可能的进行数据的组包，以最大mtu传输，如果发送的数据包大小过小则如果在0.6 到 0.8S范围内都没能组装成一个MTU时，直接发送。如果发送的数据包大小足够间隔在0.45内时，每次组装一个MTU进行发送。如果间隔大于0.4 到 0.8S则，每过来一个数据包就直接发送。</p><p>Nagle组织包的长度是由系统决定的，有时候我们知道我们会每个1分钟产生1字节，共1000字节。如果完全由Nagle算法来发送的话，可能还是会1字节1字节发送[这是一种极端情况，假设返回ACK时间不是很长]。这个时候首先设置TCP_CORK能够阻塞住TCP[尽量阻塞住]，等我们write完1000字节之后，取消TCP_CORK，这个时候就能够将1000字节一次发出。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>   <code>TCP_CORK</code>选项与<code>TCP_NODELAY</code>一样，是控制Nagle化的。      </p><ol><li>打开TCP_NODELAY选项，则意味着无论数据包是多么的小，都立即发送（不考虑拥塞窗口）。</li><li>如果将TCP连接比喻为一个管道，那TCP_CORK选项的作用就像一个塞子。            </li></ol><blockquote><p>设置TCP_CORK选项，就是用塞子塞住管道，而取消TCP_CORK选项，就是将塞子拔掉。<br>当TCP_CORK选项被设置时，TCP链接不会发送任何的小包，即只有当数据量达到MSS时，才会被发送。<br>一般当数据传输完成时，通常需要取消该选项，以防被塞住，这样才可以让不够MSS大小的包能及时发出去。</p></blockquote><blockquote><p>参考：<br><a href="https://blog.csdn.net/libinjlu/article/details/42366757" target="_blank" rel="noopener">Nagle算法–TCP缓冲区管理算法</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Nagle算法&lt;/strong&gt;用于&lt;code&gt;对缓冲区内的一定数量的消息进行自动连接&lt;/code&gt;。该处理过程(称为Nagling)，通过&lt;code&gt;减少必须发送的封包的数量&lt;/code&gt;，提高了网络应用程序系统的效率。&lt;/p&gt;
    
    </summary>
    
      <category term="计算机网络" scheme="http://changsk.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="Nagle" scheme="http://changsk.top/tags/Nagle/"/>
    
  </entry>
  
  <entry>
    <title>为什么单线程的redis这么快</title>
    <link href="http://changsk.top/2019/06/25/why-redis-quick/"/>
    <id>http://changsk.top/2019/06/25/why-redis-quick/</id>
    <published>2019-06-25T12:31:34.000Z</published>
    <updated>2019-06-25T12:34:41.501Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>纯内存访问，redis将所有数据都放在内存中，内存响应时间大约为100纳秒，这是redis达到每秒万级级别访问的重要基础。完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；</p><a id="more"></a></li><li><p>数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；</p></li><li><p>非阻塞IO，redis使用epoll作为IO多路复用技术的实现，再加上redis自身事件处理模型将epoll中的链接、读写、关闭都转换为事件，不在网络IO上浪费过多的事件。</p><p><img src="1.jpg" alt="img"></p></li></ol><figure class="highlight mathematica"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">多路<span class="keyword">I</span>/<span class="keyword">O</span>复用模型是利用 select、poll、epoll 可以同时监察多个流的 <span class="keyword">I</span>/<span class="keyword">O</span> 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有 <span class="keyword">I</span>/<span class="keyword">O</span> 事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll 是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。</span><br><span class="line"></span><br><span class="line">这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 <span class="keyword">I</span>/<span class="keyword">O</span> 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络 IO 的时间消耗），且 Redis 在内存中操作数据的速度非常快。</span><br></pre></td></tr></table></figure><ol start="4"><li>单线程避免了线程切换和竟态产生的消耗。避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；<br>1.单线程简化数据结构和算法的实现。<br>2.单线程避免线程切换和竟态产生的消耗。<br>缺点：如果命令执行时间过程，会导致其它命令阻塞。</li></ol><blockquote><p>参考：</p><p><a href="https://www.cnblogs.com/oskyhg/p/7856043.html" target="_blank" rel="noopener">单线程的redis为什么达到每秒万级的处理速度？</a><br><a href="https://blog.csdn.net/chenyao1994/article/details/79491337" target="_blank" rel="noopener">为什么说Redis是单线程的以及Redis为什么这么快！</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;&lt;p&gt;纯内存访问，redis将所有数据都放在内存中，内存响应时间大约为100纳秒，这是redis达到每秒万级级别访问的重要基础。完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；&lt;/p&gt;
    
    </summary>
    
      <category term="Redis" scheme="http://changsk.top/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://changsk.top/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>MSS和MTU的关系</title>
    <link href="http://changsk.top/2019/06/24/mss-mtu/"/>
    <id>http://changsk.top/2019/06/24/mss-mtu/</id>
    <published>2019-06-24T14:17:47.000Z</published>
    <updated>2019-06-24T14:29:01.279Z</updated>
    
    <content type="html"><![CDATA[<p><code>MSS</code>，Maxitum Segment Size 最大分段大小，是TCP协议定义的一个选项。MSS选项用于在TCP连接建立时，收发双方协商通信时每一个报文段所能承载的最大数据长度。建立tcp连接的两端在三次握手时会协商<code>tcp mss</code>大小。</p><p><code>MTU</code>，Maxitum Transmission Unit ，最大传输单元，是指ip层数据包的最大字节数，因为ip数据报要在数据链路层传输，所以也是数据链路层所能传输的的最大字节数，不同链路层的MTU可能不同。</p><blockquote><p>举个例子：如果你要搬家，需要把东西打包，用车运走。这样的情况下，车的大小受路的宽度限制；箱子的大小受车限制；能够搬运的东西的大小受箱子的限制。这时可以将路的宽度理解成第二层的MTU，车的大小理解成第三层的MTU，箱子的大小理解成第四层的MTU，搬运的东西理解成MSS。</p></blockquote><p><strong>MTU= MSS+TCP层头部长度+IP层头部长度</strong></p><blockquote><p>参考: <a href="https://blog.csdn.net/aiaiai010101/article/details/82984940" target="_blank" rel="noopener">MSS和MTU的关系</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;code&gt;MSS&lt;/code&gt;，Maxitum Segment Size 最大分段大小，是TCP协议定义的一个选项。MSS选项用于在TCP连接建立时，收发双方协商通信时每一个报文段所能承载的最大数据长度。建立tcp连接的两端在三次握手时会协商&lt;code&gt;tcp mss&lt;/
      
    
    </summary>
    
      <category term="计算机网络" scheme="http://changsk.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="MSS" scheme="http://changsk.top/tags/MSS/"/>
    
      <category term="MTU" scheme="http://changsk.top/tags/MTU/"/>
    
  </entry>
  
  <entry>
    <title>HTTP方法GET和POST的区别</title>
    <link href="http://changsk.top/2019/06/24/get-post/"/>
    <id>http://changsk.top/2019/06/24/get-post/</id>
    <published>2019-06-24T09:27:28.000Z</published>
    <updated>2019-06-24T09:38:58.568Z</updated>
    
    <content type="html"><![CDATA[<p>当第一次面试的时候被问到说一说<code>get和post有什么区别</code>。当时就说了一大堆很普遍很基础的答案，什么post比get安全，get比post传的少什么的。然而，面试官问，还有呢？</p><a id="more"></a><p>好家伙，面试完回去百度，整理了网上一堆的get和post的区别。整理如下：</p><ol><li>从http标准来看，<code>get比post安全</code>，这里的安全是针对服务器而言的，<code>get用于获取数据，不会引起数据的变化，并且是安全和幂等(多次请求，效果一致)的。而post是有可能引起数据的变化。</code></li><li>从应用角度来看，get参数是放在URL后面(通过URL传递)，参数直接暴露在URL上，所以不能用来传递敏感信息，而post提交的数据会放置在Request body中</li><li>get请求会被浏览器主动缓存post不会，除非手动设置。从这里看，post安全性比get高。</li><li>GET请求只能进行url编码，而POST支持多种编码方式。 </li><li>GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。</li><li>GET在浏览器回退时是无害的，而POST会再次提交请求。 </li><li>GET产生的URL地址可以被Bookmark，而POST不可以。</li><li>对参数的数据类型，GET只接受ASCII字符，而POST没有限制。</li><li>Get方式的提交顶多是1024字节，理论上post没有限制，可以传较大量的数据。</li><li>Get一般是获取数据，post是向服务器提交修改的数据。</li></ol><p>再然后呢，去面试的时候自然自信满满。结果，还有没有点别的，感觉有种答非所问的赶脚。<br>好吧，回去继续百度深造。结果是这样的：</p><blockquote><p>GET和POST是什么?HTTP协议中的两种发送请求的方法。<br>HTTP是什么?HTTP是基于TCP/IP的关于数据如何在万维网中如何通信的协议。<br>HTTP的底层是TCP/IP。所以GET和POST的底层也是TCP/IP，也就是说，GET/POST都是TCP链接 。GET和POST能做的事情是一样一样的。你要给GET加上request body，给POST带上url参数，技术上是完全行的通的。</p></blockquote><p>那所谓的区别呢？</p><blockquote><p>运输快递需要车辆，而TCP就像车辆，但如果车辆全部按自己的想法走，交通就会瘫痪，所以交通规则HTTP诞生了。HTTP规定了运输方式：get、post、head、options、put、delete等。当执行get请求时，车上贴get标签，货物放在上层运输。如果是post请求，车上贴post标签，货物放在下层运输。当然，get方式也可以把货物放在下层，但是这样是算get还是post呢？所以，HTTP只是个行为准则，而TCP才是GET和POST怎么实现的基本。</p></blockquote><p>而关于传递的参数大小问题，是这样的。</p><blockquote><p>过大的数据量会增加运输成本，超出的部分，概不处理，那还不如乖按照规定走。所以，浏览器通常都会限制url长度在2K个字节，而(大多数)服务器最多处理64K大小的url。如果你用GET服务，在request body偷偷藏了数据，不同服务器的处理方式也是不同的，有些服务器会帮你卸货，读出数据，有些服务器直接忽略，所以，虽然GET可以带request body，也不能保证一定能被接收到哦。</p></blockquote><p>GET和POST还有一个重大区别，简单的说：</p><blockquote><p>GET产生一个TCP数据包;POST产生两个TCP数据包。<br>对于GET方式的请求，浏览器会把http header和data一并发送出去，服务器响应200(返回数据);<br>而对于POST，浏览器先发送header，服务器响应100 continue，浏览器再发送data，服务器响应200 ok(返回数据)</p></blockquote><p>总结：</p><ul><li>语义不同：get获取数据；post提交数据</li></ul><blockquote><p>GET是用来向获取服务器信息的，请求报文传输的信息只是用于描述所需资源的参数，返回的信息才是数据本身；POST是用来向服务器传递数据的，其请求报文传递的信息就是数据本身，返回的报文只是操作的结果。这是GET和POST最重要的区别，没有之一。</p></blockquote><ul><li>get在浏览器回退时是无害的，而post会再次请求</li><li>get产生的url地址可以被收藏，而post不会</li><li>get请求会被浏览器主动缓存，而post不会，除非手动设置</li></ul><blockquote><p>使用GET，你可能会有意无意就享受到从浏览器到代理到网络服务商再到服务器各个网络组件一层一层的透明缓存；而POST默认是不可缓存的,需要你显式使用缓存相关Header。</p></blockquote><ul><li>get请求只能进行url编码，而post支持多种编码方式</li><li>get请求参数会被完整保留在浏览历史记录里，而post中的参数不会被保留</li><li>get 请求在url中传送的参数有长度限制，而post没有</li></ul><blockquote><p>使用载荷的POST比使用URI的GET可以传递更多数据。<br>HTTP协议本身没有限制传递信息的最大值，但具体的限制受各个网络组件的实现影响，一般而言，GET的长度限制更短。当然用来获取数据的GET方式，绝大多数情况也用不着传递那么多的数据。</p></blockquote><ul><li>对参数的数据类型，get只接受ascll字符，而post没有限制</li><li>get比post更安全，因为参数直接暴露在url上，所以不能用来传递敏感信息</li></ul><blockquote><p>简单来说HTTP的安全(Safe)指的是是否改变服务器资源的状态，即是我们平常说的有无副作用。因为提交数据的目的往往是为了改变服务器状态，所以POST不是安全的(Safe)；而GET是为了获取数据，所以它不应该改变服务器的状态，是安全的(Safe)。HTTP中的安全Safe(副作用)和大多数人平时想的安全Security(例如数据安全)，仅仅是共用一个中文词汇，实质上就是雷峰和雷峰塔的关系，从这个角度上来说GET反而比POST安全多了。为此我建议大家把安全留给更加常用的Security,中文使用一个更加少歧义的说法来描述GET和POST的第二个区别:<br>POST是一个可能有副作用的方法，但GET应是没有副作用的的。<br>如果要保证传输的安全，请使用HTTPS。</p></blockquote><ul><li>get参数通过url传递，poet放在request body中</li><li>GET产生一个TCP数据包;POST产生两个TCP数据包。</li></ul><blockquote><p>有些浏览器在发送POST的Ajax请求时会在发送POST请求前先发送一个HEAD，而GET请求则是直接发送。</p></blockquote><ul><li>get是幂等的，post是非幂等的</li></ul><blockquote><p>‘POST是非幂等的‘就是你提交完表单后，按F5后浏览器会弹框要求你重复确认是否刷新的原因。</p></blockquote><blockquote><p>参考：<br><a href="https://www.jianshu.com/p/fcdc0f86633a" target="_blank" rel="noopener">关于面试被问到post和get的区别？？？</a><br><a href="https://www.jianshu.com/p/22aad0481886" target="_blank" rel="noopener">[原][经典面试题]带你深入理解HTTP中GET和POST的区别</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;当第一次面试的时候被问到说一说&lt;code&gt;get和post有什么区别&lt;/code&gt;。当时就说了一大堆很普遍很基础的答案，什么post比get安全，get比post传的少什么的。然而，面试官问，还有呢？&lt;/p&gt;
    
    </summary>
    
      <category term="计算机网络" scheme="http://changsk.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="get" scheme="http://changsk.top/tags/get/"/>
    
      <category term="post" scheme="http://changsk.top/tags/post/"/>
    
  </entry>
  
  <entry>
    <title>java中的CopyOnWriteArraylist</title>
    <link href="http://changsk.top/2019/06/24/java-CopyOnWriteArraylist/"/>
    <id>http://changsk.top/2019/06/24/java-CopyOnWriteArraylist/</id>
    <published>2019-06-24T09:21:21.000Z</published>
    <updated>2019-06-24T09:26:19.397Z</updated>
    
    <content type="html"><![CDATA[<p>转载自：<a href="https://www.xttblog.com/?p=4006" target="_blank" rel="noopener">https://www.xttblog.com/?p=4006</a></p><h2 id="CopyOnWriteArrayList简介"><a href="#CopyOnWriteArrayList简介" class="headerlink" title="CopyOnWriteArrayList简介"></a>CopyOnWriteArrayList简介</h2><p><code>CopyOnWriteArrayList</code>是一个并发容器。有很多人称它是线程安全的，我认为这句话不严谨，缺少一个前提条件，那就是非复合场景下操作它是线程安全的。</p><p><code>Copy-On-Write 简称 COW</code>，是一种用于程序设计中的优化策略。其基本思路是，<code>从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容 Copy 出去形成一个新的内容然后再改，这是一种延时懒惰策略。</code></p><a id="more"></a><p>Java 并发包提供了很多线程安全的集合，有了他们的存在，使得我们在多线程开发下，大大简化了多线程开发的难度，但是如果不知道其中的原理，可能会引发意想不到的问题，所以知道其中的原理还是很有必要的。</p><h2 id="CopyOnWriteArrayList原理"><a href="#CopyOnWriteArrayList原理" class="headerlink" title="CopyOnWriteArrayList原理"></a>CopyOnWriteArrayList原理</h2><p><code>CopyOnWrite</code> 容器即<code>写时复制</code>的容器。通俗的理解是<code>当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行 Copy，复制出一个新的容器，然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器</code>。这样做的好处是我们可以<strong>对 CopyOnWrite 容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素</strong>。所以 CopyOnWrite 容器也是一种<strong>读写分离</strong>的思想，<strong>读和写不同的容器</strong>。</p><h3 id="add-方法"><a href="#add-方法" class="headerlink" title="add 方法"></a>add 方法</h3><p>下面我们看看它的 add 方法的源码：</p><figure class="highlight d"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">`public`</span> <span class="string">`boolean`</span> <span class="string">`add(E e) &#123;`</span><span class="string">`    `</span><span class="string">`//1.获得独占锁`</span><span class="string">`    `</span><span class="string">`final`</span> <span class="string">`ReentrantLock lock = `</span><span class="string">`this`</span><span class="string">`.lock;`</span><span class="string">`    `</span><span class="string">`lock.lock();`</span><span class="string">`    `</span><span class="string">`try`</span> <span class="string">`&#123;`</span><span class="string">`        `</span><span class="string">`Object[] elements = getArray();`</span><span class="string">`//2.获得Object[]`</span><span class="string">`        `</span><span class="string">`int`</span> <span class="string">`len = elements.length;`</span><span class="string">`//3.获得elements的长度`</span><span class="string">`        `</span><span class="string">`Object[] newElements = Arrays.copyOf(elements, len + `</span><span class="string">`1`</span><span class="string">`);`</span><span class="string">`//4.复制到新的数组`</span><span class="string">`        `</span><span class="string">`newElements[len] = e;`</span><span class="string">`//5.将add的元素添加到新元素`</span><span class="string">`        `</span><span class="string">`setArray(newElements);`</span><span class="string">`//6.替换之前的数据`</span><span class="string">`        `</span><span class="string">`return`</span> <span class="string">`true`</span><span class="string">`;`</span><span class="string">`    `</span><span class="string">`&#125; `</span><span class="string">`finally`</span> <span class="string">`&#123;`</span><span class="string">`        `</span><span class="string">`lock.unlock();`</span><span class="string">`//7.释放独占锁`</span><span class="string">`    `</span><span class="string">`&#125;`</span><span class="string">`&#125;`</span><span class="string">`final`</span> <span class="string">`Object[] getArray() &#123;`</span><span class="string">`    `</span><span class="string">`return`</span> <span class="string">`array;`</span><span class="string">`&#125;`</span></span><br></pre></td></tr></table></figure><p><code>CopyOnWrite</code>的名字就是这样来的。在写的时候，先 copy 一个，操作新的对象。然后在覆盖旧的对象，保证 <code>volatile</code>语义。</p><p>看完这个源码后，我们来看几个常见的面试题。</p><p><strong>CopyOnWriteArrayList 有什么优点？</strong></p><p>读写分离，适合写少读多的场景。使用了独占锁，支持多线程下的并发写。</p><p>** CopyOnWriteArrayList 是如何保证写时线程安全的？**</p><p>因为用了<code>ReentrantLock</code>独占锁，保证同时只有一个线程对集合进行修改操作。</p><p><strong>CopyOnWrite 怎么理解？</strong></p><p><code>写时复制</code>。就是在写的时候，先 copy 一个，操作新的对象。然后在覆盖旧的对象，保证 volatile 语义。新数组的长度等于旧数组的长度 + 1。</p><p><strong>从 add 方法的源码中你可以看出  CopyOnWriteArrayList 的缺点是什么？</strong></p><p>占用内存，写时 copy 效率低。因为 CopyOnWrite 的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比如说 200M 左右，那么再写入 100M 数据进去，内存就会占用 300M，那么这个时候很有可能造成频繁的 Yong GC 和 Full GC。</p><h3 id="get-方法"><a href="#get-方法" class="headerlink" title="get 方法"></a>get 方法</h3><p>get 的源码分析。</p><figure class="highlight kotlin"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> E <span class="keyword">get</span>(int index) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">get</span>(getArray(), index);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">final</span> Object[] getArray() &#123;</span><br><span class="line">    <span class="keyword">return</span> array;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>get 方法很简单。但是会出现一个很致命的问题，那就是<strong>一致性问题</strong>。</p><p>当我们获得了 array 后，由于整个 get 方法没有独占锁，所以另外一个线程还可以继续执行修改的操作，比如执行了 remove 的操作，remove 和 add 一样，也会申请独占锁，并且复制出新的数组，删除元素后，替换掉旧的数组。而这一切 get 方法是不知道的，它不知道 array 数组已经发生了天翻地覆的变化。就像微信一样，虽然对方已经把你给删了，但是你不知道。这就是一个一致性问题。</p><p>CopyOnWrite 容器<strong>只能保证数据的最终一致性，不能保证数据的实时一致性</strong>。<strong>所以如果你希望写入的的数据，马上能读到，请不要使用 CopyOnWrite 容器。</strong></p><h3 id="set方法"><a href="#set方法" class="headerlink" title="set方法"></a>set方法</h3><p>set 方法解读。</p><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> E <span class="title">set</span>(<span class="params"><span class="keyword">int</span> index, E element</span>)</span> &#123;</span><br><span class="line">    <span class="comment">//(1)获得独占锁</span></span><br><span class="line">    final ReentrantLock <span class="keyword">lock</span> = <span class="keyword">this</span>.<span class="keyword">lock</span>;</span><br><span class="line">    <span class="keyword">lock</span>.<span class="keyword">lock</span>();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Object[] elements = getArray();<span class="comment">//(2)获得array</span></span><br><span class="line">        E oldValue = <span class="keyword">get</span>(elements, index);<span class="comment">//(3)根据下标,获得旧的元素</span></span><br><span class="line"> </span><br><span class="line">        <span class="keyword">if</span> (oldValue != element) &#123;<span class="comment">//(4)如果旧的元素不等于新的元素</span></span><br><span class="line">            <span class="keyword">int</span> len = elements.length;<span class="comment">//(5)获得旧数组的长度</span></span><br><span class="line">            Object[] newElements = Arrays.copyOf(elements, len);<span class="comment">//(6)复制出新的数组</span></span><br><span class="line">            newElements[index] = element;<span class="comment">//(7)修改</span></span><br><span class="line">            setArray(newElements);<span class="comment">//(8)替换</span></span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//(9)为了保证volatile 语义，即使没有修改，也要替换成新的数组</span></span><br><span class="line">            <span class="comment">// Not quite a no-op; ensures volatile write semantics</span></span><br><span class="line">            setArray(elements);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> oldValue;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        <span class="keyword">lock</span>.unlock();<span class="comment">//(10)释放独占锁</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上面的代码，我写的都有注释，相信大家都能看明白。</p><p>set 的时候，同样的会获得一个独占锁，来保证写的线程安全。修改操作，实际上操作的是 array 的一个副本，最后才把 array 给替换掉。所以，修改和 add 很相似。set、add、remove 是互斥的。</p><h3 id="remove"><a href="#remove" class="headerlink" title="remove"></a>remove</h3><p>remove 方法解读。</p><figure class="highlight haxe"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">    final ReentrantLock lock = <span class="built_in">this</span>.lock;<span class="comment">//获得独占锁</span></span><br><span class="line">    lock.lock();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        Object[] elements = getArray();</span><br><span class="line">        int len = elements.length;<span class="comment">// 旧数组的长度</span></span><br><span class="line">        E oldValue = <span class="keyword">get</span>(elements, index);</span><br><span class="line">        int numMoved = len - index - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (numMoved == <span class="number">0</span>)<span class="comment">//判断是否是删除数组尾部的最后一个元素</span></span><br><span class="line">            <span class="comment">//则复制出一个长度为【旧数组的长度-1】的新数组</span></span><br><span class="line">            setArray(Arrays.copyOf(elements, len - <span class="number">1</span>));</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//如果要删除的元素不是最后一个，则分两次复制，随之替换。</span></span><br><span class="line">            Object[] <span class="keyword">new</span><span class="type">Elements</span> = <span class="keyword">new</span> <span class="type">Object</span>[len - <span class="number">1</span>];</span><br><span class="line">            System.arraycopy(elements, <span class="number">0</span>, <span class="keyword">new</span><span class="type">Elements</span>, <span class="number">0</span>, index);</span><br><span class="line">            System.arraycopy(elements, index + <span class="number">1</span>, <span class="keyword">new</span><span class="type">Elements</span>, index,</span><br><span class="line">                             numMoved);</span><br><span class="line">            setArray(<span class="keyword">new</span><span class="type">Elements</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> oldValue;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>研究 java 自带的一些数据结构，你会发现设计的都很巧妙。大师就是大师啊。</p><h3 id="迭代器"><a href="#迭代器" class="headerlink" title="迭代器"></a>迭代器</h3><p>迭代器的主要源码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Iterator&lt;E&gt; <span class="title">iterator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> COWIterator&lt;E&gt;(getArray(), <span class="number">0</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">COWIterator</span>&lt;<span class="title">E</span>&gt; <span class="keyword">implements</span> <span class="title">ListIterator</span>&lt;<span class="title">E</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Object[] snapshot;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> cursor;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">COWIterator</span><span class="params">(Object[] elements, <span class="keyword">int</span> initialCursor)</span> </span>&#123;</span><br><span class="line">        cursor = initialCursor;</span><br><span class="line">        snapshot = elements;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 判断是否还有下一个元素</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> cursor &lt; snapshot.length;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//获取下个元素</span></span><br><span class="line">    <span class="meta">@SuppressWarnings</span>(<span class="string">"unchecked"</span>)</span><br><span class="line">    <span class="function"><span class="keyword">public</span> E <span class="title">next</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (! hasNext())</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> NoSuchElementException();</span><br><span class="line">        <span class="keyword">return</span> (E) snapshot[cursor++];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用<code>iterator</code> 方法获取迭代器，内部会调用 <code>COWIterator</code> 的构造方法，此构造方法有两个参数，第一个参数就是 array 数组，第二个参数是下标，就是 0。随后构造方法中会把 array 数组赋值给snapshot变量。snapshot 是“快照”的意思，如果 Java 基础尚可的话，应该知道<code>数组是引用类型</code>，传递的是指针，如果有其他地方修改了数组，这里应该马上就可以反应出来，那为什么又会是 snapshot这样的命名呢？没错，如果其他线程没有对 <code>CopyOnWriteArrayList</code> 进行增删改的操作，那么 snapshot 就是本身的 array，但是如果其他线程对 CopyOnWriteArrayList 进行了增删改的操作，旧的数组会被新的数组给替换掉，但是 snapshot 还是原来旧的数组的引用。<code>也就是说 当我们使用迭代器便利 CopyOnWriteArrayList 的时候，不能保证拿到的数据是最新的，这也是一致性问题。</code></p><h2 id="CopyOnWriteArrayList-的使用场景"><a href="#CopyOnWriteArrayList-的使用场景" class="headerlink" title="CopyOnWriteArrayList 的使用场景"></a>CopyOnWriteArrayList 的使用场景</h2><p>通过源码分析，我们看出它的优缺点比较明显，所以使用场景也就比较明显。就是合适读多写少的场景。</p><h2 id="CopyOnWriteArrayList-的缺点"><a href="#CopyOnWriteArrayList-的缺点" class="headerlink" title="CopyOnWriteArrayList 的缺点"></a>CopyOnWriteArrayList 的缺点</h2><ol><li>由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致<code>young gc</code>或者 <code>full gc</code>。</li><li><code>不能用于实时读的场景</code>，像拷贝数组、新增元素都需要时间，所以调用一个 set 操作后，读取到数据可能还是旧的，虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求。</li><li>由于实际使用中可能没法保证 CopyOnWriteArrayList 到底要放置多少数据，万一数据稍微有点多，每次 add/set 都要重新复制数组，这个代价实在太高昂了。在高性能的互联网应用中，这种操作分分钟引起故障。</li></ol><h2 id="CopyOnWriteArrayList-的设计思想"><a href="#CopyOnWriteArrayList-的设计思想" class="headerlink" title="CopyOnWriteArrayList 的设计思想"></a>CopyOnWriteArrayList 的设计思想</h2><ol><li>读写分离，读和写分开</li><li>最终一致性</li><li>使用另外开辟空间的思路，来解决并发冲突</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;转载自：&lt;a href=&quot;https://www.xttblog.com/?p=4006&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.xttblog.com/?p=4006&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;CopyOnWriteArrayList简介&quot;&gt;&lt;a href=&quot;#CopyOnWriteArrayList简介&quot; class=&quot;headerlink&quot; title=&quot;CopyOnWriteArrayList简介&quot;&gt;&lt;/a&gt;CopyOnWriteArrayList简介&lt;/h2&gt;&lt;p&gt;&lt;code&gt;CopyOnWriteArrayList&lt;/code&gt;是一个并发容器。有很多人称它是线程安全的，我认为这句话不严谨，缺少一个前提条件，那就是非复合场景下操作它是线程安全的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Copy-On-Write 简称 COW&lt;/code&gt;，是一种用于程序设计中的优化策略。其基本思路是，&lt;code&gt;从一开始大家都在共享同一个内容，当某个人想要修改这个内容的时候，才会真正把内容 Copy 出去形成一个新的内容然后再改，这是一种延时懒惰策略。&lt;/code&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://changsk.top/categories/Java/"/>
    
    
      <category term="java" scheme="http://changsk.top/tags/java/"/>
    
      <category term="CopyOnWriteArrayList" scheme="http://changsk.top/tags/CopyOnWriteArrayList/"/>
    
  </entry>
  
  <entry>
    <title>java中常用的线程安全的类</title>
    <link href="http://changsk.top/2019/06/24/java-Thread-safe-classes/"/>
    <id>http://changsk.top/2019/06/24/java-Thread-safe-classes/</id>
    <published>2019-06-24T09:15:46.000Z</published>
    <updated>2019-06-24T09:20:25.507Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h2><h3 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h3><p>就是当多线程访问时，采用了<strong>加锁</strong>的机制；即当一个线程访问该类的某个数据时，会对这个数据进行保护，其他线程不能对其访问，直到该线程读取完之后，其他线程才可以使用。防止出现数据不一致或者数据被污染的情况。<br>线程不安全：就是不提供数据访问时的数据保护，多个线程能够同时操作某个数据，从而出现数据不一致或者数据污染的情况。</p><a id="more"></a><p>对于线程不安全的问题，一般会使用<strong>synchronized</strong>关键字加锁同步控制。</p><blockquote><p>工作原理：jvm中有一个main memory(主内存)对象，每一个线程也有自己的working memory(工作内存)，一个线程对于一个变量variable进行操作的时候， 都需要在自己的working memory里创建一个copy,操作完之后再写入main memory。 当多个线程操作同一个变量variable，就可能出现不可预知的结果。 </p><p>而用synchronized的关键是建立一个监控monitor，这个monitor可以是要修改的变量，也可以是其他自己认为合适的对象(方法)，然后通过给这个monitor加锁来实现线程安全，每个线程在获得这个锁之后，要执行完加载load到working memory 到 use &amp;&amp; 指派assign 到 存储store 再到 main memory的过程。才会释放它得到的锁。这样就实现了所谓的线程安全。</p></blockquote><h2 id="线程安全-Thread-safe-的集合对象："><a href="#线程安全-Thread-safe-的集合对象：" class="headerlink" title="线程安全(Thread-safe)的集合对象："></a>线程安全(Thread-safe)的集合对象：</h2><ul><li>Vector </li><li>HashTable</li><li>StringBuffer</li></ul><h2 id="非线程安全的集合对象："><a href="#非线程安全的集合对象：" class="headerlink" title="非线程安全的集合对象："></a>非线程安全的集合对象：</h2><ul><li>ArrayList </li><li>LinkedList</li><li>HashMap</li><li>HashSet</li><li>TreeMap</li><li>TreeSet</li><li>StringBulider</li></ul><h2 id="相关集合对象比较"><a href="#相关集合对象比较" class="headerlink" title="相关集合对象比较"></a>相关集合对象比较</h2><h3 id="Vector、ArrayList、LinkedList"><a href="#Vector、ArrayList、LinkedList" class="headerlink" title="Vector、ArrayList、LinkedList"></a>Vector、ArrayList、LinkedList</h3><ol><li>Vector：<br>Vector与ArrayList一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问ArrayList慢。 </li><li>ArrayList：<br>a. 当操作是在一列数据的后面添加数据而不是在前面或者中间，并需要随机地访问其中的元素时，使用ArrayList性能比较好。<br>b. ArrayList是最常用的List实现类，内部是通过数组实现的，它允许对元素进行快速<strong>随机访问</strong>。数组的缺点是每个元素之间不能有间隔，当数组大小不满足时需要增加存储能力，就要讲已经有数组的数据复制到新的存储空间中。当从ArrayList的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。 </li><li>LinkedList：<br>a. 当对一列数据的前面或者中间执行添加或者删除操作时，并且按照顺序访问其中的元素时，要使用LinkedList。<br>b. LinkedList是用链表结构存储数据的，很适合数据的<strong>动态插入和删除</strong>，随机访问和遍历速度比较慢。另外，他还提供了List接口中没有定义的方法，专门用于<strong>操作表头和表尾元素</strong>，可以当作<strong>堆栈</strong>、<strong>队列</strong>和<strong>双向队列</strong>使用。<br>　　  Vector和ArrayList在使用上非常相似，都可以用来表示一组数量可变的对象应用的集合，并且可以随机的访问其中的元素。</li></ol><h3 id="HashTable、HashMap、HashSet"><a href="#HashTable、HashMap、HashSet" class="headerlink" title="HashTable、HashMap、HashSet"></a>HashTable、HashMap、HashSet</h3><p>HashTable和HashMap采用的存储机制是一样的，不同的是： </p><ol><li><p>HashMap：<br>a. 采用数组方式存储key-value构成的Entry对象，无容量限制；<br>b. 基于key hash查找Entry对象存放到数组的位置，对于hash冲突采用链表的方式去解决；<br>c. 在插入元素时，可能会扩大数组的容量，在扩大容量时须要重新计算hash，并复制对象到新的数组中；<br>d. 是非线程安全的；<br>e. 遍历使用的是Iterator迭代器；</p><p>f. 键和值都允许为null，最多有一个键为null的元素</p></li><li><p>HashTable：<br>a. 是线程安全的；<br>b. 无论是key还是value<strong>都不允许有null值的存在</strong>；在HashTable中调用Put方法时，如果key为null，直接抛出NullPointerException异常；<br>c. 遍历使用的是Enumeration列举；</p></li><li><p>HashSet：<br>a. 基于HashMap实现，无容量限制；<br>b. 是非线程安全的；<br>c. 不保证数据的有序；</p></li></ol><h3 id="TreeSet、TreeMap"><a href="#TreeSet、TreeMap" class="headerlink" title="TreeSet、TreeMap"></a>TreeSet、TreeMap</h3><p>TreeSet和TreeMap都是完全基于Map来实现的。 </p><ol><li>TreeSet：<br>a. 基于TreeMap实现的，支持排序；<br>b. 是非线程安全的；</li><li>TreeMap：<br>a. 典型的基于红黑树的Map实现，因此它要求一定要有key比较的方法，要么传入Comparator比较器实现，要么key对象实现Comparator接口；<br>b. 是非线程安全的；</li></ol><h3 id="StringBuffer和StringBulider"><a href="#StringBuffer和StringBulider" class="headerlink" title="StringBuffer和StringBulider"></a>StringBuffer和StringBulider</h3><p>StringBuilder与StringBuffer都继承自<code>AbstractStringBuilder</code>类，在AbstractStringBuilder中也是使用<strong>字符数组</strong>保存字符串。</p><ol><li>在执行速度方面的比较：StringBuilder &gt; StringBuffer ；</li><li>他们都是字符串变量，是可改变的对象，每当我们用它们对字符串做操作时，实际上是在一个对象上操作的，不像String一样创建一些对象进行操作，所以速度快； </li><li>StringBuilder：线程非安全的； StringBuffer：线程安全的； </li></ol><blockquote><p>对于String、StringBuffer和StringBulider三者使用的总结：<br>1.如果要操作少量的数据用 = String<br>2.单线程操作字符串缓冲区 下操作大量数据 = StringBuilder<br>3.多线程操作字符串缓冲区 下操作大量数据 = StringBuffer</p></blockquote><h2 id="Java中常见的线程安全的类"><a href="#Java中常见的线程安全的类" class="headerlink" title="Java中常见的线程安全的类"></a>Java中常见的线程安全的类</h2><ol><li>通过<code>synchronized</code> 关键字给方法加上内置锁来实现线程安全 </li></ol><blockquote><p>Timer，TimerTask，Vector，Stack，HashTable，StringBuffer</p></blockquote><ol start="2"><li>原子类Atomicxxx—包装类的线程安全类<br>如<code>AtomicLong</code>，<code>AtomicInteger</code>等等 </li></ol><blockquote><p>Atomicxxx 是通过Unsafe 类的native(CAS)方法实现线程安全的</p></blockquote><ol start="3"><li>BlockingQueue 和BlockingDeque<br>BlockingDeque接口继承了BlockingQueue接口，<br>BlockingQueue 接口的实现类有<code>ArrayBlockingQueue</code> ，<code>LinkedBlockingQueue</code> ，<code>PriorityBlockingQueue</code>, 而BlockingDeque接口的实现类有<code>LinkedBlockingDeque</code>, </li></ol><blockquote><p>BlockingQueue和BlockingDeque 都是通过使用定义为<strong>final的ReentrantLock</strong>作为类属性显式加锁实现同步的</p></blockquote><ol start="4"><li>CopyOnWriteArrayList和 CopyOnWriteArraySet </li></ol><blockquote><p>CopyOnWriteArraySet的内部实现是在其类内部声明一个final的CopyOnWriteArrayList属性，并在调用其构造函数时实例化该CopyOnWriteArrayList，CopyOnWriteArrayList采用的是显式地加上ReentrantLock实现同步，而CopyOnWriteArrayList(读写分离)容器的线程安全性在于在每次修改时都会创建并重新发布一个新的容器副本，从而实现可变性。</p></blockquote><ol start="5"><li>Concurrentxxx<br>最常用的就是<code>ConcurrentHashMap</code>，当然还有<code>ConcurrentSkipListSet</code>和<code>ConcurrentSkipListMap</code>等等。 </li></ol><blockquote><p>ConcurrentHashMap使用了一种完全不同的加锁策略来提供更高的并发性和伸缩性。ConcurrentHashMap并不是将每个方法都在同一个锁上同步并使得每次只能有一个线程访问容器，而是使用一种粒度更细的加锁机制——分段锁来实现更大程度的共享。在这种机制中，任意数量的读取线程可以并发访问Map，执行读取操作的线程和执行写入操作的线程可以并发地访问Map，并且一定数量的写入线程可以并发地修改Map，这使得在并发环境下吞吐量更高，而在单线程环境中只损失非常小的性能。</p></blockquote><ol start="6"><li>ThreadPoolExecutor </li></ol><blockquote><p>ThreadPoolExecutor也是使用了ReentrantLock显式加锁同步。</p></blockquote><ol start="7"><li><code>Collections</code>中的<code>synchronizedCollection(Collection c)</code>方法可将一个集合变为线程安全，其内部通过<code>synchronized</code>关键字加锁同步。</li></ol><blockquote><p>参考<br><a href="https://blog.csdn.net/tiandao321/article/details/81300489" target="_blank" rel="noopener">Java常见的线程安全的类</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;概念&quot;&gt;&lt;/a&gt;概念&lt;/h2&gt;&lt;h3 id=&quot;线程安全&quot;&gt;&lt;a href=&quot;#线程安全&quot; class=&quot;headerlink&quot; title=&quot;线程安全&quot;&gt;&lt;/a&gt;线程安全&lt;/h3&gt;&lt;p&gt;就是当多线程访问时，采用了&lt;strong&gt;加锁&lt;/strong&gt;的机制；即当一个线程访问该类的某个数据时，会对这个数据进行保护，其他线程不能对其访问，直到该线程读取完之后，其他线程才可以使用。防止出现数据不一致或者数据被污染的情况。&lt;br&gt;线程不安全：就是不提供数据访问时的数据保护，多个线程能够同时操作某个数据，从而出现数据不一致或者数据污染的情况。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://changsk.top/categories/Java/"/>
    
    
      <category term="java" scheme="http://changsk.top/tags/java/"/>
    
  </entry>
  
  <entry>
    <title>TCP协议详解</title>
    <link href="http://changsk.top/2019/06/23/TCP/"/>
    <id>http://changsk.top/2019/06/23/TCP/</id>
    <published>2019-06-23T03:38:00.000Z</published>
    <updated>2019-06-24T09:30:23.668Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>小到基于应用层做网络开发，大到生活中无处不在的网络。我们在享受这个便利的时候，没有人会关心它如此牢固的底层基石是如何搭建的。而这些基石中很重要的一环就是<code>tcp</code>协议。翻看一下“三次握手”和“四次挥手”，本以为这就是<code>tcp</code>了，其实不然。它仅仅解决了<code>连接和关闭</code>的问题，传输的问题才是<code>tcp</code>协议更重要，更难，更复杂的问题。回头看<code>tcp</code>协议的原理，会发现它为了承诺上层数据传输的“可靠”，不知要应对多少网络中复杂多变的情况。简单直白列举一下：</p><a id="more"></a><ul><li>怎么保证数据都是可靠呢？—<code>连接确认！关闭确认！收到数据确认！各种确认</code>！！</li><li>因为网络或其他原因，对方收不到数据怎么办？–<code>超时重试</code></li><li>网络情况千变万化，超时时间怎么确定？–根据<code>RTT</code>动态计算</li><li>反反复复，不厌其烦的重试，导致网络拥塞怎么办？—<code>慢启动，拥塞避免，快速重传，快速恢复</code></li><li>发送速度和接收速度不匹配怎么办？–<code>滑动窗口</code></li><li>滑动窗口滑的过程中，他一直告诉我处理不过来了，不让传数据了怎么办？–<code>ZWP</code></li><li>滑动窗口滑的过程中，他处理得慢，就理所当然的每次让我发很少的数据，导致网络利用率很低怎么办？—<code>Nagle</code></li></ul><p>其中任何一个小环节，都凝聚了无数的算法，我们没有能力理解各个算法的实现，但是需要了解下tcp实现者的思路历程。</p><p>梳理完所有内容，大概可以知道：</p><ul><li>tcp提供哪些机制保证了数据传输的可靠性？</li><li>tcp连接的“三次握手”和关闭的“四次挥手”流程是怎么样的？</li><li>tcp连接和关闭过程中，状态是如何变化的？</li><li>tcp头部有哪些字段，分别用来做什么的？</li><li>tcp的滑动窗口协议是什么？</li><li>超时重传的机制是什么？</li><li>如何避免传输拥塞？</li></ul><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="tcp连接的特点"><a href="#tcp连接的特点" class="headerlink" title="tcp连接的特点"></a>tcp连接的特点</h2><ul><li>提供面向<code>连接</code>的，1可靠1的1字节流1服务</li><li>为上层应用层提供服务，不关心具体传输的内容是什么，也不知道是二进制流，还是ascii字符。</li></ul><h2 id="tcp的可靠性如何保证"><a href="#tcp的可靠性如何保证" class="headerlink" title="tcp的可靠性如何保证"></a>tcp的可靠性如何保证</h2><ul><li>分块传送：数据被分割成<strong>最合适的</strong>数据块（UDP的数据报长度不变）</li><li>等待确认：通过定时器等待接收端发送确认请求，收不到确认则重发</li><li>确认回复：收到确认后发送确认回复(不是立即发送，通常推迟几分之一秒)</li><li>数据校验：保持首部和数据的校验和，检测数据传输过程有无变化</li><li>乱序排序：接收端能重排序数据，以正确的顺序交给应用端</li><li>重复丢弃：接收端能丢弃重复的数据包</li><li>流量缓冲：两端有固定大小的缓冲区（滑动窗口），防止速度不匹配丢数据</li></ul><h2 id="tcp的首部格式"><a href="#tcp的首部格式" class="headerlink" title="tcp的首部格式"></a>tcp的首部格式</h2><h3 id="宏观位置"><a href="#宏观位置" class="headerlink" title="宏观位置"></a>宏观位置</h3><p><img src="1.jpg" alt="img"></p><ul><li>从应用层-&gt;传输层-&gt;网络层-&gt;链路层，每经过一次都会在报文中增加相应的首部。</li><li>TCP数据被封装在IP数据报中</li></ul><h3 id="首部格式"><a href="#首部格式" class="headerlink" title="首部格式"></a>首部格式</h3><p><img src="2.jpg" alt="img"></p><ul><li><p>tcp首部数据通常包含20个字节（不包括任选字段）</p></li><li><p>第1-2两个字节：源端口号</p></li><li><p>第3-4两个字节：目的端口号</p><blockquote><p>源端口号+ip首部中的源ip地址+目的端口号+ip首部中的目的ip地址，唯一的确定了一个tcp连接。对应编码级别的socket。</p></blockquote></li><li><p>第5-8四个字节：32位序号。tcp提供<strong>全双工</strong>服务，两端都有各自的序号。</p><p>编号：解决网络包<strong>乱序</strong>的问题</p><blockquote><p>序号如何生成：不能是固定写死的，否则断网重连时序号重复使用会乱套。tcp基于时钟生成一个序号，每4微秒加一，到2^32-1时又从0开始</p></blockquote></li><li><p>第9-12四个字节：32位确认序列号。上次成功收到数据字节序号加1，ack为1才有效。<strong>确认号：解决丢包的问题</strong></p></li><li><p>第13位字节：首部长度。因为任选字段长度可变</p></li><li><p>后面6bite：保留</p></li><li><p>随后6bite：标识位。<strong>控制各种状态</strong></p></li><li><p>第15-16两个字节：窗口大小。接收端期望接收的字节数。<strong>解决流量控制的问题</strong></p></li><li><p>第17-18两个字节：校验和。由发送端计算和存储，由接收端校验。<strong>解决数据正确性问题</strong></p></li><li><p>第19-20两个字节：紧急指针</p></li></ul><h3 id="标识位说明"><a href="#标识位说明" class="headerlink" title="标识位说明"></a>标识位说明</h3><ul><li>URG：为1时，表示紧急指针有效</li><li>ACK：确认标识，连接建立成功后，总为1。为1时确认号有效</li><li>PSH：接收方应尽快把这个报文交给应用层</li><li>RST：复位标识，重建连接</li><li>SYN：建立新连接时，该位为0</li><li>FIN：关闭连接标识</li></ul><h3 id="tcp选项格式"><a href="#tcp选项格式" class="headerlink" title="tcp选项格式"></a>tcp选项格式</h3><p><img src="3.jpg" alt="img"></p><ul><li>每个选项开始是1字节kind字段，说明选项的类型</li><li>kind为0和1的选项，只占一个字节</li><li>其他kind后有一字节len，表示该选项总长度（包括kind和len）</li><li>kind为11，12，13表示tcp事务</li></ul><h3 id="MSS-最长报文大小"><a href="#MSS-最长报文大小" class="headerlink" title="MSS 最长报文大小"></a>MSS 最长报文大小</h3><ul><li>最常见的可选字段</li><li>MSS只能出现在SYN时传过来（第一次握手和第二次握手时）</li><li>指明本端能接收的最大长度的报文段</li><li>建立连接时，双方都要发送MSS</li><li>如果不发送，默认为536字节</li></ul><h1 id="连接的建立与释放"><a href="#连接的建立与释放" class="headerlink" title="连接的建立与释放"></a>连接的建立与释放</h1><h2 id="连接建立的“三次握手”"><a href="#连接建立的“三次握手”" class="headerlink" title="连接建立的“三次握手”"></a>连接建立的“三次握手”</h2><h3 id="三次握手流程"><a href="#三次握手流程" class="headerlink" title="三次握手流程"></a>三次握手流程</h3><p><img src="4.jpg" alt="img"><br>TCP协议中，主动发起请求的一端称为『<strong>客户端</strong>』，被动连接的一端称为『<strong>服务端</strong>』。不管是客户端还是服务端，TCP连接建立完后都能发送和接收数据。<br>起初，服务器和客户端都为<code>CLOSED</code>状态。在通信开始前，<code>双方都得创建各自的传输控制块（TCB）</code>。服务器创建完TCB后遍进入<code>LISTEN</code>状态，此时准备接收客户端发来的连接请求。</p><h4 id="第一次握手"><a href="#第一次握手" class="headerlink" title="第一次握手"></a>第一次握手</h4><p>客户端向服务端发送连接请求报文段。该报文段的头部中SYN=1，ACK=0，seq=x。请求发送后，客户端便进入<code>SYN-SENT</code>状态。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PS1：<span class="attribute">SYN</span>=1，ACK=0表示该报文段为连接请求报文。</span><br><span class="line">PS2：x为本次TCP通信的字节流的初始序号。</span><br><span class="line">TCP规定：<span class="attribute">SYN</span>=1的报文段不能有数据部分，但要消耗掉一个序号。</span><br></pre></td></tr></table></figure><h4 id="第二次握手"><a href="#第二次握手" class="headerlink" title="第二次握手"></a>第二次握手</h4><p>服务端收到连接请求报文段后，如果同意连接，则会发送一个应答：SYN=1，ACK=1，seq=y，ack=x+1。<br>该应答发送完成后便进入<code>SYN-RCVD</code>状态。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PS1：<span class="attribute">SYN</span>=1，ACK=1表示该报文段为连接同意的应答报文，ACK为1表示ack字段有效。</span><br><span class="line">PS2：<span class="attribute">seq</span>=y表示服务端作为发送者时，发送字节流的初始序号。</span><br><span class="line">PS3：<span class="attribute">ack</span>=x+1表示服务端希望下一个数据报发送序号从x+1开始的字节。</span><br></pre></td></tr></table></figure><h4 id="第三次握手"><a href="#第三次握手" class="headerlink" title="第三次握手"></a>第三次握手</h4><p>当客户端收到连接同意的应答后，还要向服务端发送一个确认报文段，表示：服务端发来的连接同意应答已经成功收到。<br>该报文段的头部为：ACK=1，seq=x+1，ack=y+1。<br>客户端发完这个报文段后便进入<code>ESTABLISHED</code>状态，服务端收到这个应答后也进入<code>ESTABLISHED</code>状态，此时连接的建立完成！</p><h3 id="为什么连接建立需要三次握手，而不是两次握手？"><a href="#为什么连接建立需要三次握手，而不是两次握手？" class="headerlink" title="为什么连接建立需要三次握手，而不是两次握手？"></a>为什么连接建立需要三次握手，而不是两次握手？</h3><p>防止失效的连接请求报文段被服务端接收，从而产生错误。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">PS：失效的连接请求：若客户端向服务端发送的连接请求丢失，客户端等待应答超时后就会再次发送连接请求，此时，上一个连接请求就是『失效的』。</span><br></pre></td></tr></table></figure><p>若建立连接只需两次握手，客户端并没有太大的变化，仍然需要获得服务端的应答后才进入ESTABLISHED状态，而服务端在收到连接请求后就进入ESTABLISHED状态。此时如果网络拥塞，客户端发送的连接请求迟迟到不了服务端，客户端便<code>超时重发请求</code>，如果服务端正确接收并确认应答，双方便开始通信，通信结束后释放连接。此时，如果那个失效的连接请求抵达了服务端，由于只有两次握手，服务端收到请求就会进入ESTABLISHED状态，等待发送数据或主动发送数据。但此时的客户端早已进入CLOSED状态，服务端将会一直等待下去，这样浪费服务端连接资源。</p><p>之所以存在 <code>3-way hanshake</code> 的说法，是因为 TCP 是双向通讯协议，作为响应一方(Responder) 要想初始化发送通道，必须也进行一轮 SYN + ACK。由于 SYN ACK 在 TCP 分组头部是两个标识位，因此处于优化目的被合并了。所以达到双方都能进行收发的状态只需要 3 个分组。</p><p>在谢希仁著《计算机网络》第四版中讲“<strong>三次握手</strong>”的目的是“<code>为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误</code>”。在另一部经典的《计算机网络》一书中讲“三次握手”的目的是为了解决<strong>“网络中存在延迟的重复分组</strong>”的问题。这两种不用的表述其实阐明的是同一个问题。<br>谢希仁版《计算机网络》中的例子是这样的，“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。</p><h2 id="连接关闭的“四次挥手”"><a href="#连接关闭的“四次挥手”" class="headerlink" title="连接关闭的“四次挥手”"></a>连接关闭的“四次挥手”</h2><h3 id="四次挥手流程"><a href="#四次挥手流程" class="headerlink" title="四次挥手流程"></a>四次挥手流程</h3><p><img src="5.jpg" alt></p><p>TCP连接的释放一共需要四步，因此称为『四次挥手』。<br>我们知道，TCP连接是<code>双向</code>的，因此在四次挥手中，前两次挥手用于断开一个方向的连接，后两次挥手用于断开另一方向的连接。</p><h4 id="第一次挥手"><a href="#第一次挥手" class="headerlink" title="第一次挥手"></a>第一次挥手</h4><p>若A认为数据发送完成，则它需要向B发送连接释放请求。该请求只有报文头，头中携带的主要参数为：<br>FIN=1，seq=u。此时，A将进入<code>FIN-WAIT-1</code>状态。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PS1：<span class="attribute">FIN</span>=1表示该报文段是一个连接释放请求。</span><br><span class="line">PS2：<span class="attribute">seq</span>=u，u-1是A向B发送的最后一个字节的序号。</span><br></pre></td></tr></table></figure><h4 id="第二次挥手"><a href="#第二次挥手" class="headerlink" title="第二次挥手"></a>第二次挥手</h4><p>B收到连接释放请求后，会通知相应的应用程序，告诉它A向B这个方向的连接已经释放。此时B进入<code>CLOSE-WAIT</code>状态，并向A发送连接释放的应答，其报文头包含：<br>ACK=1，seq=v，ack=u+1。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PS1：<span class="attribute">ACK</span>=1：除TCP连接请求报文段以外，TCP通信过程中所有数据报的ACK都为1，表示应答。</span><br><span class="line">PS2：<span class="attribute">seq</span>=v，v-1是B向A发送的最后一个字节的序号。</span><br><span class="line">PS3：<span class="attribute">ack</span>=u+1表示希望收到从第u+1个字节开始的报文段，并且已经成功接收了前u个字节。</span><br></pre></td></tr></table></figure><p>A收到该应答，进入<code>FIN-WAIT-2</code>状态，等待B发送连接释放请求。</p><p>第二次挥手完成后，A到B方向的连接已经释放，B不会再接收数据，A也不会再发送数据。但B到A方向的连接仍然存在，B可以继续向A发送数据。</p><h4 id="第三次挥手"><a href="#第三次挥手" class="headerlink" title="第三次挥手"></a>第三次挥手</h4><p>当B向A发完所有数据后，向A发送连接释放请求，请求头：FIN=1，ACK=1，seq=w，ack=u+1。B便进入<code>LAST-ACK</code>状态。</p><h4 id="第四次挥手"><a href="#第四次挥手" class="headerlink" title="第四次挥手"></a>第四次挥手</h4><p>A收到释放请求后，向B发送确认应答，此时A进入<code>TIME-WAIT</code>状态。该状态会持续<code>2MSL</code>时间，若该时间段内没有B的重发请求的话，就进入<code>CLOSED</code>状态，<strong>撤销TCB</strong>。当B收到确认应答后，也便进入CLOSED状态，撤销TCB。</p><h3 id="为什么A要先进入TIME-WAIT状态，等待2MSL时间后才进入CLOSED状态？"><a href="#为什么A要先进入TIME-WAIT状态，等待2MSL时间后才进入CLOSED状态？" class="headerlink" title="为什么A要先进入TIME-WAIT状态，等待2MSL时间后才进入CLOSED状态？"></a>为什么A要先进入TIME-WAIT状态，等待2MSL时间后才进入CLOSED状态？</h3><p>为了保证B能收到A的确认应答。<br>若A发完确认应答后直接进入CLOSED状态，那么如果该应答丢失，B等待超时后就会重新发送连接释放请求，但此时A已经关闭了，不会作出任何响应，因此B永远无法正常关闭。</p><h3 id="time-wait状态"><a href="#time-wait状态" class="headerlink" title="time_wait状态"></a>time_wait状态</h3><ul><li>也称为<code>2MSL</code>等待状态，<code>MSL=Maximum Segment LifetIme</code>，报文段最大生存时间，根据不同的tcp实现自行设定。常用值为30s，1min，2min。linux一般为30s。</li></ul><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">MSL是Maximum Segment Lifetime英文的缩写，中文可以译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为tcp报文（segment）是ip数据报（datagram）的数据部分，具体称谓请参见《数据在网络各层中的称呼》一文，而ip头中有一个TTL域，TTL是time to live的缩写，中文可以译为“生存时间”，这个生存时间是由源主机设置初始值但不是存的具体时间，而是存储了一个ip数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减<span class="number">1</span>，当此值为<span class="number">0</span>则数据报将被丢弃，同时发送ICMP报文通知源主机。RFC <span class="number">793</span>中规定MSL为<span class="number">2</span>分钟，实际应用中常用的是<span class="number">30</span>秒，<span class="number">1</span>分钟和<span class="number">2</span>分钟等。</span><br><span class="line"></span><br><span class="line">    <span class="number">2</span>MSL即两倍的MSL，TCP的TIME_WAIT状态也称为<span class="number">2</span>MSL等待状态，当TCP的一端发起主动关闭，在发出最后一个ACK包后，即第<span class="number">3</span>次握手完成后发送了第四次握手的ACK包后就进入了TIME_WAIT状态，必须在此状态上停留两倍的MSL时间，等待<span class="number">2</span>MSL时间主要目的是怕最后一个ACK包对方没收到，那么对方在超时后将重发第三次握手的FIN包，主动关闭端接到重发的FIN包后可以再发一个ACK应答包。在TIME_WAIT状态时两端的端口不能使用，要等到<span class="number">2</span>MSL时间结束才可继续使用。当连接处于<span class="number">2</span>MSL等待阶段时任何迟到的报文段都将被丢弃。不过在实际应用中可以通过设置SO_REUSEADDR选项达到不必等待<span class="number">2</span>MSL时间结束再使用此端口。</span><br><span class="line"></span><br><span class="line">TTL与MSL是有关系的但不是简单的相等的关系，MSL要大于等于TTL。</span><br></pre></td></tr></table></figure><ul><li>主动关闭的一方发送最后一个ack所处的状态</li><li>这个状态必须维持2MSL等待时间</li></ul><h2 id="复位报文段"><a href="#复位报文段" class="headerlink" title="复位报文段"></a>复位报文段</h2><p>一个报文段从源地址发往目的地址，只要出现错误，都会发出复位的报文段，首部字段的RST是用于“复位”的。这些错误包括以下情况</p><ul><li>端口没有在监听</li><li>异常中止：通过发送RST而不是fin来中止连接</li></ul><h2 id="同时打开"><a href="#同时打开" class="headerlink" title="同时打开"></a>同时打开</h2><p><img src="11.png" alt="img"></p><ul><li>两个应用程序同时执行主动打开，称为“同时打开“</li><li>这种情况极少发生</li><li>两端同时发送SYN，同时进入SYN_SENT状态</li><li>打开一条连接而不是两条</li><li>要进行四次报文交换过程，“四次握手”</li></ul><h2 id="同时关闭"><a href="#同时关闭" class="headerlink" title="同时关闭"></a>同时关闭</h2><p><img src="22.png" alt="img"></p><ul><li>双方同时执行主动关闭</li><li>进行四次报文交换</li><li>状态和正常关闭不一样</li></ul><h2 id="服务器对于并发请求的处理"><a href="#服务器对于并发请求的处理" class="headerlink" title="服务器对于并发请求的处理"></a>服务器对于并发请求的处理</h2><ul><li>正等待连接的一端有一个固定长度的队列（长度叫做“积压值”，大多数情况长度为5）</li><li>该队列中的连接为：已经完成了三次握手，但还没有被应用层接收（应用层需要等待最后一个ack收到后才知道这个连接）</li><li>应用层接收请求的连接，将从该队列中移除</li><li>当新的请求到来时，先判断队列情况来决定是否接收这个连接</li><li>积压值的含义：tcp监听的端点已经被tcp接收，但是等待应用层接收的最大值。与系统允许的最大连接数，服务器接收的最大并发数无关</li></ul><h1 id="数据的传输"><a href="#数据的传输" class="headerlink" title="数据的传输"></a>数据的传输</h1><h2 id="tcp传输的数据分类"><a href="#tcp传输的数据分类" class="headerlink" title="tcp传输的数据分类"></a>tcp传输的数据分类</h2><ul><li>成块数据传输：量大，报文段常常满</li><li>交互数据传输：量小，报文段为微小分组，大量微小分组，在广域网传输会增加拥堵的出现</li><li>tcp处理的数据包括两类，有不同的特点，需要不同的传输技术</li></ul><h2 id="交互数据的传输技术"><a href="#交互数据的传输技术" class="headerlink" title="交互数据的传输技术"></a>交互数据的传输技术</h2><h3 id="经受时延的确认"><a href="#经受时延的确认" class="headerlink" title="经受时延的确认"></a>经受时延的确认</h3><ul><li>概念：tcp收到数据时，并不立马发送ack确认，而是稍后发送</li><li>目的：将ack与需要沿该方向发送的数据一起发送，以减少开销</li><li>特点：接收方不必确认每一个收到的分组，ACK是累计的，它表示接收方已经正确收到了一直到确认序号-1的所有字节</li><li>延时时间：绝大多数为200ms。不能超过500ms</li></ul><h3 id="Nagle算法"><a href="#Nagle算法" class="headerlink" title="Nagle算法"></a>Nagle算法</h3><ul><li>解决什么问题：微小分组导致在广域网出现的拥堵问题</li><li>核心：减少了通过广域网传输的小分组数目</li><li>原理：<code>要求一个tcp连接上最多只能有一个未被确认的未完成的分组</code>，该分组的确认到达之前，不能发送其他分组。tcp收集这些分组，确认到来之前以一个分组的形式发出去</li><li>优点：自适应。确认到达的快，数据发送越快。确认慢，发送更少的组。</li><li>使用注意：局域网很少使用该算法。且有些特殊场景需要禁用该算法</li></ul><h2 id="成块数据的传输"><a href="#成块数据的传输" class="headerlink" title="成块数据的传输"></a>成块数据的传输</h2><ul><li>主要使用滑动窗口协议</li></ul><h1 id="滑动窗口协议"><a href="#滑动窗口协议" class="headerlink" title="滑动窗口协议"></a>滑动窗口协议</h1><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><ul><li>解决了什么问题：<code>发送方和接收方速率不匹配</code>时，保证可靠传输和包乱序的问题</li><li>机制：接收方根据目前缓冲区大小，通知发送方目前能接收的最大值。发送方根据接收方的处理能力来发送数据。通过这种协调机制，防止接收端处理不过来。</li><li>窗口大小：接收方发给发送端的这个值称为窗口大小</li></ul><h2 id="tcp缓冲区的数据结构"><a href="#tcp缓冲区的数据结构" class="headerlink" title="tcp缓冲区的数据结构"></a>tcp缓冲区的数据结构</h2><p><img src="6.jpg" alt="img"></p><ul><li>接收端：<ul><li>LastByteRead: 缓冲区读取到的位置</li><li>NextByteExpected：收到的连续包的最后一个位置</li><li>LastByteRcvd：收到的包的最后一个位置</li><li>中间空白区：数据没有到达</li></ul></li><li>发送端：<ul><li>LastByteAcked: 被接收端ack的位置，表示成功发送确认</li><li>LastByteSent：发出去了，还没有收到成功确认的Ack</li><li>LastByteWritten：上层应用正在写的地方</li></ul></li></ul><h2 id="滑动窗口示意图"><a href="#滑动窗口示意图" class="headerlink" title="滑动窗口示意图"></a>滑动窗口示意图</h2><h3 id="初始时示意图"><a href="#初始时示意图" class="headerlink" title="初始时示意图"></a>初始时示意图</h3><p><img src="7.jpg" alt="img"></p><ul><li>黑框表示滑动窗口</li><li>#1表示收到ack确认的数据</li><li>#2表示还没收到ack的数据</li><li>#3表示在窗口中还没有发出的（接收方还有空间）</li><li>#4窗口以外的数据（接收方没空间）</li></ul><h3 id="滑动过程示意图"><a href="#滑动过程示意图" class="headerlink" title="滑动过程示意图"></a>滑动过程示意图</h3><p><img src="8.jpg" alt="img"></p><ul><li>收到36的ack，并发出46-51的字节</li></ul><h2 id="拥塞窗口"><a href="#拥塞窗口" class="headerlink" title="拥塞窗口"></a>拥塞窗口</h2><ul><li>解决什么问题：发送方发送速度过快，导致中转路由器拥堵的问题</li><li>机制：发送方增加一个拥塞窗口（cwnd），每次收到ack，窗口值加1。发送时，<code>取拥塞窗口和接收方发来的窗口大小取最小值发送</code></li><li>起到发送方流量控制的作用</li></ul><h2 id="滑动窗口会引发的问题"><a href="#滑动窗口会引发的问题" class="headerlink" title="滑动窗口会引发的问题"></a>滑动窗口会引发的问题</h2><h3 id="零窗口"><a href="#零窗口" class="headerlink" title="零窗口"></a>零窗口</h3><ul><li>如何发生： 接收端处理速度慢，发送端发送速度快。窗口大小慢慢被调为0</li><li>如何解决：ZWP技术。发送zwp包给接收方，让接收方ack他的窗口大小。</li></ul><h3 id="糊涂窗口综合征"><a href="#糊涂窗口综合征" class="headerlink" title="糊涂窗口综合征"></a>糊涂窗口综合征</h3><ul><li>如何发生：接收方太忙，取不完数据，导致发送方越来越小。最后只让发送方传几字节的数据。</li><li>缺点：数据比tcp和ip头小太多，网络利用率太低。</li><li>如何解决：避免对小的窗口大小做响应。</li><li>发送端：前面说到的Nagle算法。</li><li>接收端：窗口大小小于某个值，直接ack（0），阻止发送数据。窗口变大后再发。</li></ul><h1 id="超时与重传"><a href="#超时与重传" class="headerlink" title="超时与重传"></a>超时与重传</h1><h2 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h2><ul><li>tcp提供可靠的运输层，使用的方法是<code>确认机制</code>。</li><li>但是数据和确认都有可能丢失</li><li>tcp通过在发送时<code>设置定时器</code>解决这种问题</li><li>定时器时间到了还没收到确认，就重传该数据</li></ul><h2 id="tcp管理的定时器类型"><a href="#tcp管理的定时器类型" class="headerlink" title="tcp管理的定时器类型"></a>tcp管理的定时器类型</h2><ul><li>重传定时器：等待收到确认</li><li>坚持定时器：使窗口大小信息保持不断流动</li><li>保活定时器：检测空闲连接崩溃或重启</li><li>2MSL定时器：检测time_wait状态</li></ul><h2 id="超时重传机制"><a href="#超时重传机制" class="headerlink" title="超时重传机制"></a>超时重传机制</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><ul><li>接收端给发送端的Ack确认只会确认最后一个连续的包</li><li>比如发送1,2,3,4,5共五份数据，接收端收到1,2，于是回ack3，然后收到4（还没收到3），此时tcp不会跳过3直接确认4，否则发送端以为3也收到了。这时你能想到的方法是什么呢？tcp又是怎么处理的呢？</li></ul><h3 id="被动等待的超时重传策略"><a href="#被动等待的超时重传策略" class="headerlink" title="被动等待的超时重传策略"></a>被动等待的超时重传策略</h3><ul><li>直观的方法是：接收方不做任何处理，等待发送方超时，然后重传。<ul><li>缺点：发送端不知道该重发3，还是重发3,4,5</li></ul></li><li>如果发送方如果只发送3：节省宽度，但是慢</li><li>如果发送方如果发送3,4,5：快，但是浪费宽带</li><li>总之，都在被动等待超时，超时可能很长。所以tcp不采用此方法</li></ul><h3 id="主动的快速重传机制"><a href="#主动的快速重传机制" class="headerlink" title="主动的快速重传机制"></a>主动的快速重传机制</h3><h4 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h4><ul><li>名称为：Fast Retransmit</li><li>不以实际驱动，而以数据驱动重传</li></ul><h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><ul><li><p>如果包没有送达，就一直ack最后那个可能被丢的包</p></li><li><p>发送方连续收到3相同的ack，就重传。不用等待超时</p><p><img src="9.jpg" alt="img"></p></li><li><p>图中发生1,2,3,4,5数据</p></li><li><p>数据1到达，发生ack2</p></li><li><p>数据2因为某些原因没有送到</p></li><li><p>后续收到3的时候，接收端并不是ack4，也不是等待。而是主动ack2</p></li><li><p>收到4,5同理，一直主动ack2</p></li><li><p>客户端收到三次ack2，就重传2</p></li><li><p>2收到后，结合之前收到的3,4,5，直接ack6</p></li></ul><h4 id="快速重传的利弊"><a href="#快速重传的利弊" class="headerlink" title="快速重传的利弊"></a>快速重传的利弊</h4><ul><li>解决了被动等待timeout的问题</li><li>无法解决重传之前的一个，还是所有的问题。</li><li>上面的例子中是重传2，还是重传2,3,4,5。因为并不清楚ack2是谁传回来的</li></ul><h3 id="SACK方法"><a href="#SACK方法" class="headerlink" title="SACK方法"></a>SACK方法</h3><h4 id="概述-4"><a href="#概述-4" class="headerlink" title="概述"></a>概述</h4><ul><li>为了解决快速重传的缺点，一种更好的SACK重传策略被提出</li><li>基于快速重传，同时在<code>tcp头里加了一个SACK的东西</code></li><li>解决了什么问题：客户端应该发送哪些超时包的问题</li></ul><h4 id="实现原理-1"><a href="#实现原理-1" class="headerlink" title="实现原理"></a>实现原理</h4><ul><li>SACK记录一个数值范围，表示哪些数据收到了</li><li>linux2.4后默认打开该功能，之前版本需要配置tcp-sack参数</li><li>SACK只是一种辅助的方式，发送方不能完全依赖SACK。主要还是依赖ACK和timout</li></ul><h4 id="Duplicate-SACK-D-SACK"><a href="#Duplicate-SACK-D-SACK" class="headerlink" title="Duplicate SACK(D-SACK)"></a>Duplicate SACK(D-SACK)</h4><ul><li>使用SACK标识的范围，还可以知道告知发送方，有哪些数据被重复接收了</li><li>可以让发送方知道：是发出去的包丢了，还是回来的ack包丢了</li></ul><h2 id="超时时间的确定"><a href="#超时时间的确定" class="headerlink" title="超时时间的确定"></a>超时时间的确定</h2><h3 id="背景-1"><a href="#背景-1" class="headerlink" title="背景"></a>背景</h3><ul><li>路由器和网络流量均会变化</li><li>所以超时时间肯定不能设置为一个固定值</li><li>超时长：重发慢，效率低，性能差</li><li>超时短：并没有丢就重发，导致网络拥塞，导致更多超时和更多重发</li><li>tcp会追踪这些变化，并相应的动态改变超时时间（RTO）</li></ul><h3 id="如何动态改变"><a href="#如何动态改变" class="headerlink" title="如何动态改变"></a>如何动态改变</h3><ul><li>每次重传的时间间隔为上次的一倍，直到最大间隔为64s，称为“指数退避”</li><li>首次重传到最后放弃重传的时间间隔一般为9min</li><li>依赖以往的往返时间计算（RTT）动态的计算</li></ul><h3 id="往返时间（RTT）的计算方法"><a href="#往返时间（RTT）的计算方法" class="headerlink" title="往返时间（RTT）的计算方法"></a>往返时间（RTT）的计算方法</h3><ul><li>并不是简单的ack时间和发送时间的差值。因为有重传，网络阻塞等各种变化的因素。</li><li>而是通过采样多次数值，然后做估算</li><li>tcp使用的方法有：<ul><li>被平滑的RTT估计器</li><li>被平滑的均值偏差估计器</li></ul></li></ul><h3 id="重传时间的具体计算"><a href="#重传时间的具体计算" class="headerlink" title="重传时间的具体计算"></a>重传时间的具体计算</h3><ul><li>计算往返时间（RTT），保存测量结果</li><li>通过测量结果维护一个被平滑的RTT估计器和被平滑的均值偏差估计器</li><li>根据这两个估计器计算下一次重传时间</li></ul><h2 id="超时重传引发的问题-拥塞"><a href="#超时重传引发的问题-拥塞" class="headerlink" title="超时重传引发的问题-拥塞"></a>超时重传引发的问题-拥塞</h2><h3 id="为什么重传会引发拥塞"><a href="#为什么重传会引发拥塞" class="headerlink" title="为什么重传会引发拥塞"></a>为什么重传会引发拥塞</h3><ul><li>当网络延迟突然增加时，tcp会重传数据</li><li>但是过多的重传会导致网络负担加重，从而导致更大的延时和丢包，进入恶性循环</li><li>也就是tcp的拥塞问题</li></ul><h3 id="解决拥塞-拥塞控制的算法"><a href="#解决拥塞-拥塞控制的算法" class="headerlink" title="解决拥塞-拥塞控制的算法"></a>解决拥塞-拥塞控制的算法</h3><ul><li>慢启动：降低分组进入网络的传输速率</li><li>拥塞避免：处理丢失分组的算法</li><li>快速重传</li><li>快速恢复</li></ul><h1 id="其他定时器"><a href="#其他定时器" class="headerlink" title="其他定时器"></a>其他定时器</h1><h2 id="坚持定时器"><a href="#坚持定时器" class="headerlink" title="坚持定时器"></a>坚持定时器</h2><h3 id="坚持定时器存在的意义"><a href="#坚持定时器存在的意义" class="headerlink" title="坚持定时器存在的意义"></a>坚持定时器存在的意义</h3><ul><li>当窗口大小为0时，接收方会发送一个没有数据，只有窗口大小的ack</li><li>但是，如果这个ack丢失了会出现什么问题？双方可能因为等待而中止连接</li><li><code>坚持定时器周期性的向接收方查询窗口是否被增大。这些发出的报文段称为窗口探查</code></li></ul><h3 id="坚持定时器启动时机"><a href="#坚持定时器启动时机" class="headerlink" title="坚持定时器启动时机"></a>坚持定时器启动时机</h3><ul><li>发送方被通告接收方窗口大小为0时</li></ul><h3 id="与超时重传的相同和不同"><a href="#与超时重传的相同和不同" class="headerlink" title="与超时重传的相同和不同"></a>与超时重传的相同和不同</h3><ul><li>相同：同样的重传时间间隔</li><li>不同：窗口探查从不放弃发送，直到窗口被打开或者进程被关闭。而超时重传到一定时间就放弃发送</li></ul><h2 id="保活定时器"><a href="#保活定时器" class="headerlink" title="保活定时器"></a>保活定时器</h2><h3 id="保活定时器存在的意义"><a href="#保活定时器存在的意义" class="headerlink" title="保活定时器存在的意义"></a>保活定时器存在的意义</h3><ul><li>当tcp上没有数据传输时，服务器如何检测到客户端是否还存活</li></ul><blockquote><p>参考：<br><a href="https://juejin.im/post/5ba895a06fb9a05ce95c5dac" target="_blank" rel="noopener">TCP协议详解</a><br><a href="https://www.cnblogs.com/lshs/p/6038458.html" target="_blank" rel="noopener">TCP系列01—概述及协议头格式</a><br><a href="https://blog.csdn.net/tkzc_csk/article/details/88672079" target="_blank" rel="noopener">TCP三次握手 四次挥手</a><br><a href="https://blog.csdn.net/xiaofei0859/article/details/6044694" target="_blank" rel="noopener">什么是2MSL</a></p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;小到基于应用层做网络开发，大到生活中无处不在的网络。我们在享受这个便利的时候，没有人会关心它如此牢固的底层基石是如何搭建的。而这些基石中很重要的一环就是&lt;code&gt;tcp&lt;/code&gt;协议。翻看一下“三次握手”和“四次挥手”，本以为这就是&lt;code&gt;tcp&lt;/code&gt;了，其实不然。它仅仅解决了&lt;code&gt;连接和关闭&lt;/code&gt;的问题，传输的问题才是&lt;code&gt;tcp&lt;/code&gt;协议更重要，更难，更复杂的问题。回头看&lt;code&gt;tcp&lt;/code&gt;协议的原理，会发现它为了承诺上层数据传输的“可靠”，不知要应对多少网络中复杂多变的情况。简单直白列举一下：&lt;/p&gt;
    
    </summary>
    
      <category term="计算机网络" scheme="http://changsk.top/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"/>
    
    
      <category term="TCP" scheme="http://changsk.top/tags/TCP/"/>
    
  </entry>
  
  <entry>
    <title>java8中的HashMap</title>
    <link href="http://changsk.top/2019/06/21/java8-HashMap/"/>
    <id>http://changsk.top/2019/06/21/java8-HashMap/</id>
    <published>2019-06-21T15:29:32.000Z</published>
    <updated>2019-06-23T03:34:38.381Z</updated>
    
    <content type="html"><![CDATA[<p>本文转载自：<a href="https://zhuanlan.zhihu.com/p/21673805" target="_blank" rel="noopener">Java 8系列之重新认识HashMap</a></p><h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a><strong>摘要</strong></h1><p>HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK（Java Developmet Kit）版本的更新，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别，深入探讨HashMap的结构实现和功能原理。</p><a id="more"></a><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a><strong>简介</strong></h1><p>Java为数据结构中的映射定义了一个接口<code>java.util.Map</code>，此接口主要有四个常用的实现类，分别是<code>HashMap</code>、<code>Hashtable</code>、<code>LinkedHashMap</code>和<code>TreeMap</code>，类继承关系如下图所示：</p><p><img src="1.jpg" alt="img"></p><p>下面针对各个实现类的特点做一些说明：</p><ul><li><p>HashMap：它根据键的<code>hashCode</code>值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但<code>遍历顺序却是不确定的</code>。 <code>HashMap最多只允许一条记录的键为null</code>，<code>允许多条记录的值为null</code>。HashMap<code>非线程安全</code>，即任一时刻可以有多个线程同时写<code>HashMap</code>，可能会导致数据的不一致。如果需要满足线程安全，可以用 <code>Collections的synchronizedMap</code>方法使<code>HashMap</code>具有线程安全的能力，或者使用<code>ConcurrentHashMap</code>，还可以使用<code>HashTable</code>。</p></li><li><p>Hashtable：<code>Hashtable</code>是遗留类，很多映射的常用功能与<code>HashMap</code>类似，不同的是它承自<code>Dictionary</code>类，并且是<code>线程安全</code>的，<code>任一时间只有一个线程能写Hashtable</code>，<code>并发性不如ConcurrentHashMap</code>，因为<code>ConcurrentHashMap引入了分段锁</code>。<code>Hashtable</code>不建议在新代码中使用，不需要线程安全的场合可以用<code>HashMap</code>替换，需要线程安全的场合可以用<code>ConcurrentHashMap</code>替换。</p><figure class="highlight x86asm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">简单来说，Hashtable通过给方法加synchronized实现线程安全。而ConcurrentHashMap是由<span class="meta">Segment</span>数组结构和HashEntry数组结构组成。<span class="meta">Segment</span>是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个<span class="meta">Segment</span>数组，<span class="meta">Segment</span>的结构和HashMap类似，是一种数组和链表结构， 一个<span class="meta">Segment</span>里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个<span class="meta">Segment</span>守护一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得它对应的<span class="meta">Segment</span>锁。 </span><br><span class="line">分段锁可理解为，把整个Map分成了N个<span class="meta">Segment</span>，put和get的时候，根据key.hashCode()找到该使用哪个<span class="meta">Segment</span>，这个<span class="meta">Segment</span>做到了类似于Hashtable的线程安全，分段锁就是说用到哪部分就锁哪部分。ConcurrentHashMap键值不能为null。</span><br></pre></td></tr></table></figure></li><li><p>LinkedHashMap：<code>LinkedHashMap</code>是<code>HashMap</code>的一个子类，<code>保存了记录的插入顺序</code>，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照<code>访问次序排序</code>。</p></li><li><p>TreeMap：<code>TreeMap</code>实现<code>SortedMap</code>接口，能够把它保存的记录<code>根据键排序</code>，默认是按键值的升序排序，也可以指定排序的比较器，当用<code>Iterator</code>遍历<code>TreeMap</code>时，得到的记录是排过序的。如果使用排序的映射，建议使用<code>TreeMap</code>。在使用<code>TreeMap</code>时，key必须实现<code>Comparable</code>接口或者在构造TreeMap传入自定义的<code>Comparator</code>，否则会在运行时抛出<code>java.lang.ClassCastException</code>类型的异常。</p></li></ul><p>对于上述四种Map类型的类，要求映射中的<code>key是不可变对象</code>。<code>不可变对象是该对象在创建后它的哈希值不会被改变</code>。如果对象的哈希值发生变化，Map对象很可能就定位不到映射的位置了。</p><p>通过上面的比较，我们知道了HashMap是Java的Map家族中一个普通成员，鉴于它可以满足大多数场景的使用条件，所以是使用频度最高的一个。下文我们主要结合源码，从存储结构、常用方法分析、扩容以及安全性等方面深入讲解HashMap的工作原理。</p><h1 id="内部实现"><a href="#内部实现" class="headerlink" title="内部实现"></a><strong>内部实现</strong></h1><p>搞清楚HashMap，首先需要知道HashMap是什么，即它的存储结构-字段；其次弄明白它能干什么，即它的功能实现-方法。下面我们针对这两个方面详细展开讲解。</p><h2 id="存储结构-字段"><a href="#存储结构-字段" class="headerlink" title="存储结构-字段"></a>存储结构-字段</h2><p>从结构实现来讲，HashMap是<code>数组+链表+红黑树</code>（JDK1.8增加了红黑树部分）实现的，如下如所示。</p><p><img src="2.jpg" alt="img"></p><p>这里需要讲明白两个问题：数据底层具体存储的是什么？这样的存储方式有什么优点呢？</p><ol><li>从源码可知，<code>HashMap</code>类中有一个非常重要的字段，就是 <code>Node[] table</code>，即哈希桶数组，明显它是一个Node的数组。我们来看Node[JDK1.8]是何物。</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123;</span><br><span class="line">        final int hash;    //用来定位数组索引位置</span><br><span class="line">        final K key;</span><br><span class="line">        V value;</span><br><span class="line">        Node&lt;K,V&gt; next;   //链表的下一个node</span><br><span class="line"></span><br><span class="line">        Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125;</span><br><span class="line">        public final K getKey()&#123; ... &#125;</span><br><span class="line">        public final V getValue() &#123; ... &#125;</span><br><span class="line">        public final String toString() &#123; ... &#125;</span><br><span class="line">        public final int hashCode() &#123; ... &#125;</span><br><span class="line">        public final V setValue(V newValue) &#123; ... &#125;</span><br><span class="line">        public final boolean equals(Object o) &#123; ... &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>Node</code>是<code>HashMap</code>的一个内部类，实现了<code>Map.Entry</code>接口，本质是就是一个映射(键值对)。上图中的每个黑色圆点就是一个Node对象。</p><ol start="2"><li><code>HashMap</code>就是使用哈希表来存储的。哈希表为解决冲突，可以采用<code>开放地址法</code>和<code>链地址法</code>等来解决问题，Java中HashMap采用了<code>链地址法</code>。链地址法，简单来说，就是<code>数组加链表的结合</code>。在每个数组元素上都一个链表结构，当数据被<code>Hash</code>后，得到数组下标，把数据放在对应下标元素的链表上。例如程序执行下面代码：</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">map.put(&quot;美团&quot;,&quot;小美&quot;);</span><br></pre></td></tr></table></figure><p>系统将调用”美团”这个<code>key</code>的<code>hashCode()</code>方法得到其<code>hashCode</code> 值（该方法适用于每个Java对象），然后再通过Hash算法的后两步运算（<code>高位运算和取模运算</code>，下文有介绍）来定位该键值对的存储位置，有时两个key会定位到相同的位置，表示发生了Hash碰撞。当然Hash算法计算结果越分散均匀，Hash碰撞的概率就越小，map的存取效率就会越高。</p><p>如果哈希桶数组很大，即使较差的Hash算法也会比较分散，如果哈希桶数组数组很小，即使好的Hash算法也会出现较多碰撞，所以就需要在<code>空间成本和时间成本之间权衡</code>，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的hash算法减少Hash碰撞。那么通过什么方式来控制map使得Hash碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？答案就是<code>好的Hash算法和扩容机制</code>。</p><p>在理解Hash和扩容流程之前，我们得先了解下HashMap的几个字段。从HashMap的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">int threshold;             // 所能容纳的key-value对极限 </span><br><span class="line">final float loadFactor;    // 负载因子</span><br><span class="line">int modCount;  </span><br><span class="line">int size;</span><br></pre></td></tr></table></figure><p>首先，<code>Node[] table</code>的初始化长度<code>length</code>(默认值是16)，<code>Load factor</code>为负载因子(默认值是0.75)，<code>threshold</code>是<code>HashMap</code>所能容纳的最大数据量的Node(键值对)个数。<code>threshold = length * Load factor</code>。也就是说，在数组定义好长度之后，<code>负载因子越大，所能容纳的键值对个数越多</code>。</p><p>结合负载因子的定义公式可知，<code>threshold</code>就是在此<code>Load factor</code>和<code>length</code>(数组长度)对应下允许的最大元素数目，超过这个数目就重新resize(扩容)，扩容后的HashMap容量是之前容量的两倍。默认的负载因子0.75是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子Load factor的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子loadFactor的值，这个值<code>可以大于1</code>。</p><p>size这个字段其实很好理解，就是HashMap中实际存在的键值对数量。注意和table的长度length、容纳最大键值对数量threshold的区别。而<code>modCount字段主要用来记录HashMap内部结构发生变化的次数</code>，<code>主要用于迭代的快速失败</code>。强调一点，内部结构发生变化指的是<code>结构发生变化</code>，例如<code>put新键值对</code>，但是某个key对应的value值被覆盖不属于结构变化。</p><p>在<code>HashMap</code>中，哈希桶数组table的长度length大小必须为<strong>2的n次方</strong>(一定是合数)，这是一种非常规的设计，常规的设计是<code>把桶的大小设计为素数</code>。相对来说素数导致冲突的概率要小于合数，具体证明可以参考<a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/liuqiyao_01/article/details/14475159" target="_blank" rel="noopener">http://blog.csdn.net/liuqiyao_01/article/details/14475159</a>，<strong>Hashtable初始化桶大小为11</strong>，就是桶大小设计为素数的应用（Hashtable扩容后不能保证还是素数）。HashMap采用这种非常规设计，主要是为了在<code>取模和扩容时做优化</code>，<code>同时为了减少冲突</code>，HashMap定位哈希桶索引位置时，也加入了高位参与运算的过程。</p><p>这里存在一个问题，即使负载因子和Hash算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响HashMap的性能。于是，在JDK1.8版本中，对数据结构做了进一步的优化，引入了<code>红黑树</code>。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高HashMap的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考<a href="https://link.zhihu.com/?target=http%3A//blog.csdn.net/v_july_v/article/details/6105630" target="_blank" rel="noopener">http://blog.csdn.net/v_july_v/article/details/6105630</a>。</p><h2 id="功能实现-方法"><a href="#功能实现-方法" class="headerlink" title="功能实现-方法"></a>功能实现-方法</h2><p>HashMap的内部功能实现很多，本文主要从根据<code>key</code>获取哈希桶数组索引位置、<code>put</code>方法的详细执行、<code>扩容</code>过程三个具有代表性的点深入展开讲解。</p><h3 id="1-确定哈希桶数组索引位置"><a href="#1-确定哈希桶数组索引位置" class="headerlink" title="1. 确定哈希桶数组索引位置"></a>1. 确定哈希桶数组索引位置</h3><p>不管增加、删除、查找键值对，定位到哈希桶数组的位置都是很关键的第一步。前面说过HashMap的数据结构是数组和链表的结合，所以我们当然希望这个HashMap里面的元素位置尽量分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用hash算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，不用遍历链表，大大优化了查询的效率。HashMap定位数组索引位置，直接决定了hash方法的离散性能。先看看源码的实现(方法一+方法二):</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">//方法一：</span><br><span class="line">static final int hash(Object key) &#123;   //jdk1.8 &amp; jdk1.7</span><br><span class="line">     int h;</span><br><span class="line">     // h = key.hashCode() 为第一步 取hashCode值</span><br><span class="line">     // h ^ (h &gt;&gt;&gt; 16)  为第二步 高位参与运算</span><br><span class="line">     return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);</span><br><span class="line">&#125;</span><br><span class="line">//方法二：</span><br><span class="line">static int indexFor(int h, int length) &#123;  //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的</span><br><span class="line">     return h &amp; (length-1);  //第三步 取模运算</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的Hash算法本质上就是三步：<strong>取key的hashCode值、高位运算、取模运算</strong>。</p><p>对于任意给定的对象，只要它的hashCode()返回值相同，那么程序调用方法一所计算得到的Hash码值总是相同的。我们首先想到的就是把hash值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，<code>模运算的消耗还是比较大的</code>，在HashMap中是这样做的：调用方法二来计算该对象应该保存在table数组的哪个索引处。</p><p>这个方法非常巧妙，它通过<code>h &amp; (table.length -1)</code>来得到该对象的保存位，而HashMap底层数组的长度总是2的n次方，这是HashMap在速度上的优化。<code>当length总是2的n次方时，h&amp; (length-1)运算等价于对length取模</code>，也就是h%length，但是<code>&amp;比%具有更高的效率</code>。</p><p>在JDK1.8的实现中，优化了高位运算的算法，通过hashCode()的<code>高16位异或低16位</code>实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在数组table的length比较小的时候，也能保证考虑到<code>高低Bit都参与到Hash的计算</code>中，同时<code>不会有太大的开销</code>。</p><p>下面举例说明下，n为table的长度。</p><p><img src="3.jpg" alt="img"></p><h3 id="2-分析HashMap的put方法"><a href="#2-分析HashMap的put方法" class="headerlink" title="2. 分析HashMap的put方法"></a>2. 分析HashMap的put方法</h3><p>HashMap的put方法执行过程可以通过下图来理解，自己有兴趣可以去对比源码更清楚地研究学习。</p><p><img src="4.jpg" alt="img"></p><p>①.判断键值对数组table[i]是否为空或为null，否则执行resize()进行扩容；</p><p>②.根据键值key计算hash值得到插入的数组索引i，如果table[i]==null，直接新建节点添加，转向⑥，如果table[i]不为空，转向③；</p><p>③.判断table[i]的首个元素是否和key一样，如果相同直接覆盖value，否则转向④，这里的相同指的是hashCode以及equals；</p><p>④.判断table[i] 是否为treeNode，即table[i] 是否是红黑树，如果是红黑树，则直接在树中插入键值对，否则转向⑤；</p><p>⑤.遍历table[i]，判断链表长度是否大于8，大于8的话把链表转换为红黑树，在红黑树中执行插入操作，否则进行链表的插入操作；遍历过程中若发现key已经存在直接覆盖value即可；</p><p>⑥.插入成功后，判断实际存在的键值对数量size是否超多了最大容量threshold，如果超过，进行扩容。</p><p>JDK1.8HashMap的put方法源码如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"> public V put(K key, V value) &#123;</span><br><span class="line">     // 对key的hashCode()做hash</span><br><span class="line">     return putVal(hash(key), key, value, false, true);</span><br><span class="line"> &#125;</span><br><span class="line"> </span><br><span class="line"> final V putVal(int hash, K key, V value, boolean onlyIfAbsent,</span><br><span class="line">                boolean evict) &#123;</span><br><span class="line">     Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i;</span><br><span class="line">     // 步骤①：tab为空则创建</span><br><span class="line">    if ((tab = table) == null || (n = tab.length) == 0)</span><br><span class="line">        n = (tab = resize()).length;</span><br><span class="line">    // 步骤②：计算index，并对null做处理 </span><br><span class="line">    if ((p = tab[i = (n - 1) &amp; hash]) == null) </span><br><span class="line">        tab[i] = newNode(hash, key, value, null);</span><br><span class="line">    else &#123;</span><br><span class="line">        Node&lt;K,V&gt; e; K k;</span><br><span class="line">        // 步骤③：节点key存在，直接覆盖value</span><br><span class="line">        if (p.hash == hash &amp;&amp;</span><br><span class="line">            ((k = p.key) == key || (key != null &amp;&amp; key.equals(k))))</span><br><span class="line">            e = p;</span><br><span class="line">        // 步骤④：判断该链为红黑树</span><br><span class="line">        else if (p instanceof TreeNode)</span><br><span class="line">            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);</span><br><span class="line">        // 步骤⑤：该链为链表</span><br><span class="line">        else &#123;</span><br><span class="line">            for (int binCount = 0; ; ++binCount) &#123;</span><br><span class="line">                if ((e = p.next) == null) &#123;</span><br><span class="line">                    p.next = newNode(hash, key,value,null);</span><br><span class="line">                       //链表长度大于8转换为红黑树进行处理</span><br><span class="line">                    if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st  </span><br><span class="line">                        treeifyBin(tab, hash);</span><br><span class="line">                    break;</span><br><span class="line">                &#125;</span><br><span class="line">                   // key已经存在直接覆盖value</span><br><span class="line">                if (e.hash == hash &amp;&amp;</span><br><span class="line">                    ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))                                          break;</span><br><span class="line">                p = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        if (e != null) &#123; // existing mapping for key</span><br><span class="line">            V oldValue = e.value;</span><br><span class="line">            if (!onlyIfAbsent || oldValue == null)</span><br><span class="line">                e.value = value;</span><br><span class="line">            afterNodeAccess(e);</span><br><span class="line">            return oldValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    ++modCount;</span><br><span class="line">    // 步骤⑥：超过最大容量 就扩容</span><br><span class="line">    if (++size &gt; threshold)</span><br><span class="line">        resize();</span><br><span class="line">    afterNodeInsertion(evict);</span><br><span class="line">    return null;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-扩容机制"><a href="#3-扩容机制" class="headerlink" title="3. 扩容机制"></a>3. 扩容机制</h3><p>扩容(resize)就是重新计算容量，向HashMap对象里不停的添加元素，而HashMap对象内部的数组无法装载更多的元素时，对象就需要扩大数组的长度，以便能装入更多的元素。当然Java里的数组是无法自动扩容的，方法是使用一个<code>新的数组代替已有的容量小的数组</code>，就像我们用一个小桶装水，如果想装更多的水，就得换大水桶。</p><p>我们分析下resize的源码，鉴于JDK1.8融入了红黑树，较复杂，为了便于理解我们仍然使用JDK1.7的代码，好理解一些，本质上区别不大，具体区别后文再说。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"> void resize(int newCapacity) &#123;   //传入新的容量</span><br><span class="line">    Entry[] oldTable = table;    //引用扩容前的Entry数组</span><br><span class="line">    int oldCapacity = oldTable.length;         </span><br><span class="line">    if (oldCapacity == MAXIMUM_CAPACITY) &#123;  //扩容前的数组大小如果已经达到最大(2^30)了</span><br><span class="line">        threshold = Integer.MAX_VALUE; //修改阈值为int的最大值(2^31-1)，这样以后就不会扩容了</span><br><span class="line">        return;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    Entry[] newTable = new Entry[newCapacity];  //初始化一个新的Entry数组</span><br><span class="line">    transfer(newTable);                         //！！将数据转移到新的Entry数组里</span><br><span class="line">    table = newTable;                           //HashMap的table属性引用新的Entry数组</span><br><span class="line">    threshold = (int)(newCapacity * loadFactor);//修改阈值</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里就是使用一个容量更大的数组来代替已有的容量小的数组，transfer()方法将原有Entry数组的元素拷贝到新的Entry数组里。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">void transfer(Entry[] newTable) &#123;</span><br><span class="line">    Entry[] src = table;                   //src引用了旧的Entry数组</span><br><span class="line">    int newCapacity = newTable.length;</span><br><span class="line">    for (int j = 0; j &lt; src.length; j++) &#123; //遍历旧的Entry数组</span><br><span class="line">        Entry&lt;K,V&gt; e = src[j];             //取得旧Entry数组的每个元素</span><br><span class="line">        if (e != null) &#123;</span><br><span class="line">            src[j] = null;//释放旧Entry数组的对象引用（for循环后，旧的Entry数组不再引用任何对象）</span><br><span class="line">            do &#123;</span><br><span class="line">                Entry&lt;K,V&gt; next = e.next;</span><br><span class="line">                int i = indexFor(e.hash, newCapacity); //！！重新计算每个元素在数组中的位置</span><br><span class="line">                e.next = newTable[i]; //标记[1]</span><br><span class="line">                newTable[i] = e;      //将元素放在数组上</span><br><span class="line">                e = next;             //访问下一个Entry链上的元素</span><br><span class="line">            &#125; while (e != null);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>newTable[i]的引用赋给了e.next，也就是使用了单链表的<code>头插入方式</code>，同一位置上新元素总会被放在链表的头部位置；<code>这样先放在一个索引上的元素终会被放到Entry链的尾部</code>(如果发生了hash冲突的话），这一点和Jdk1.8有区别，下文详解。在旧数组中同一条Entry链上的元素，通过重新计算索引位置后，有可能被放到了新数组的不同位置上。</p><p>下面举个例子说明下扩容过程。假设了我们的hash算法就是简单的用key mod 一下表的大小（也就是数组的长度）。其中的哈希桶数组table的size=2， 所以key = 3、7、5，put顺序依次为 5、7、3。在mod 2以后都冲突在table[1]这里了。这里假设负载因子 loadFactor=1，即当键值对的实际大小size 大于 table的实际大小时进行扩容。接下来的三个步骤是哈希桶数组 resize成4，然后所有的Node重新rehash的过程。</p><p><img src="5.jpg" alt="img"></p><p>下面我们讲解下JDK1.8做了哪些优化。经过观测可以发现，我们使用的是2次幂的扩展(指长度扩为原来2倍)，所以，<code>元素的位置要么是在原位置，要么是在原位置再移动2次幂的位置</code>。看下图可以明白这句话的意思，n为table的长度，图（a）表示扩容前的key1和key2两种key确定索引位置的示例，图（b）表示扩容后key1和key2两种key确定索引位置的示例，其中hash1是key1对应的哈希与高位运算结果。</p><p><img src="6.jpg" alt="img"></p><p>元素在重新计算hash之后，因为n变为2倍，那么n-1的mask范围在高位多1bit(红色)，因此新的index就会发生这样的变化：</p><p><img src="7.jpg" alt="img"></p><p>因此，我们在扩充HashMap的时候，不需要像JDK1.7的实现那样重新计算hash，<code>只需要看看原来的hash值新增的那个bit是1还是0就好了，是0的话索引没变，是1的话索引变成“原索引+oldCap”</code>，可以看看下图为16扩充为32的resize示意图：</p><p><img src="8.jpg" alt="img"></p><p>这个设计确实非常的巧妙，既<code>省去了重新计算hash值的时间</code>，而且同时，由于<code>新增的1bit是0还是1可以认为是随机的，因此resize的过程，均匀的把之前的冲突的节点分散到新的bucket了</code>。这一块就是JDK1.8新增的优化点。有一点注意区别，<strong>JDK1.7中rehash的时候，旧链表迁移新链表的时候，如果在新表的数组索引位置相同，则链表元素会倒置，但是从上图可以看出，JDK1.8不会倒置</strong>。有兴趣的同学可以研究下JDK1.8的resize源码，写的很赞，如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line">final Node&lt;K,V&gt;[] resize() &#123;</span><br><span class="line">    Node&lt;K,V&gt;[] oldTab = table;</span><br><span class="line">    int oldCap = (oldTab == null) ? 0 : oldTab.length;</span><br><span class="line">    int oldThr = threshold;</span><br><span class="line">    int newCap, newThr = 0;</span><br><span class="line">    if (oldCap &gt; 0) &#123;</span><br><span class="line">        // 超过最大值就不再扩充了，就只好随你碰撞去吧</span><br><span class="line">        if (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">            threshold = Integer.MAX_VALUE;</span><br><span class="line">            return oldTab;</span><br><span class="line">        &#125;</span><br><span class="line">        // 没超过最大值，就扩充为原来的2倍</span><br><span class="line">        else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp;</span><br><span class="line">                 oldCap &gt;= DEFAULT_INITIAL_CAPACITY)</span><br><span class="line">            newThr = oldThr &lt;&lt; 1; // double threshold</span><br><span class="line">    &#125;</span><br><span class="line">    else if (oldThr &gt; 0) // initial capacity was placed in threshold</span><br><span class="line">        newCap = oldThr;</span><br><span class="line">    else &#123;               // zero initial threshold signifies using defaults</span><br><span class="line">        newCap = DEFAULT_INITIAL_CAPACITY;</span><br><span class="line">        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);</span><br><span class="line">    &#125;</span><br><span class="line">    // 计算新的resize上限</span><br><span class="line">    if (newThr == 0) &#123;</span><br><span class="line"></span><br><span class="line">        float ft = (float)newCap * loadFactor;</span><br><span class="line">        newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ?</span><br><span class="line">                  (int)ft : Integer.MAX_VALUE);</span><br><span class="line">    &#125;</span><br><span class="line">    threshold = newThr;</span><br><span class="line">    @SuppressWarnings(&#123;&quot;rawtypes&quot;，&quot;unchecked&quot;&#125;)</span><br><span class="line">        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap];</span><br><span class="line">    table = newTab;</span><br><span class="line">    if (oldTab != null) &#123;</span><br><span class="line">        // 把每个bucket都移动到新的buckets中</span><br><span class="line">        for (int j = 0; j &lt; oldCap; ++j) &#123;</span><br><span class="line">            Node&lt;K,V&gt; e;</span><br><span class="line">            if ((e = oldTab[j]) != null) &#123;</span><br><span class="line">                oldTab[j] = null;</span><br><span class="line">                if (e.next == null)</span><br><span class="line">                    newTab[e.hash &amp; (newCap - 1)] = e;</span><br><span class="line">                else if (e instanceof TreeNode)</span><br><span class="line">                    ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap);</span><br><span class="line">                else &#123; // 链表优化重hash的代码块</span><br><span class="line">                    Node&lt;K,V&gt; loHead = null, loTail = null;</span><br><span class="line">                    Node&lt;K,V&gt; hiHead = null, hiTail = null;</span><br><span class="line">                    Node&lt;K,V&gt; next;</span><br><span class="line">                    do &#123;</span><br><span class="line">                        next = e.next;</span><br><span class="line">                        // 原索引</span><br><span class="line">                        if ((e.hash &amp; oldCap) == 0) &#123;</span><br><span class="line">                            if (loTail == null)</span><br><span class="line">                                loHead = e;</span><br><span class="line">                            else</span><br><span class="line">                                loTail.next = e;</span><br><span class="line">                            loTail = e;</span><br><span class="line">                        &#125;</span><br><span class="line">                        // 原索引+oldCap</span><br><span class="line">                        else &#123;</span><br><span class="line">                            if (hiTail == null)</span><br><span class="line">                                hiHead = e;</span><br><span class="line">                            else</span><br><span class="line">                                hiTail.next = e;</span><br><span class="line">                            hiTail = e;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125; while ((e = next) != null);</span><br><span class="line">                    // 原索引放到bucket里</span><br><span class="line">                    if (loTail != null) &#123;</span><br><span class="line">                        loTail.next = null;</span><br><span class="line">                        newTab[j] = loHead;</span><br><span class="line">                    &#125;</span><br><span class="line">                    // 原索引+oldCap放到bucket里</span><br><span class="line">                    if (hiTail != null) &#123;</span><br><span class="line">                        hiTail.next = null;</span><br><span class="line">                        newTab[j + oldCap] = hiHead;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">             &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    return newTab;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="线程安全性"><a href="#线程安全性" class="headerlink" title="线程安全性"></a><strong>线程安全性</strong></h1><p>在多线程使用场景中，应该尽量避免使用线程不安全的<code>HashMap</code>，而使用线程安全的<code>ConcurrentHashMap</code>。那么为什么说<code>HashMap</code>是线程不安全的，下面举例子说明在并发的多线程使用场景中使用<code>HashMap</code>可能造成死循环。代码例子如下(便于理解，仍然使用JDK1.7的环境)：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">public class HashMapInfiniteLoop &#123;  </span><br><span class="line"></span><br><span class="line">    private static HashMap&lt;Integer,String&gt; map = new HashMap&lt;Integer,String&gt;(2，0.75f);  </span><br><span class="line">    public static void main(String[] args) &#123;  </span><br><span class="line">        map.put(5， &quot;C&quot;);  </span><br><span class="line"></span><br><span class="line">        new Thread(&quot;Thread1&quot;) &#123;  </span><br><span class="line">            public void run() &#123;  </span><br><span class="line">                map.put(7, &quot;B&quot;);  </span><br><span class="line">                System.out.println(map);  </span><br><span class="line">            &#125;;  </span><br><span class="line">        &#125;.start();  </span><br><span class="line">        new Thread(&quot;Thread2&quot;) &#123;  </span><br><span class="line">            public void run() &#123;  </span><br><span class="line">                map.put(3, &quot;A);  </span><br><span class="line">                System.out.println(map);  </span><br><span class="line">            &#125;;  </span><br><span class="line">        &#125;.start();        </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中，map初始化为一个长度为2的数组，loadFactor=0.75，threshold=2*0.75=1，也就是说当put第二个key的时候，map就需要进行resize。</p><p>通过设置断点让线程1和线程2同时debug到transfer方法(3.3小节代码块)的首行。注意此时两个线程已经成功添加数据。放开thread1的断点至transfer方法的“Entry next = e.next;” 这一行；然后放开线程2的的断点，让线程2进行resize。结果如下图。</p><p><img src="9.jpg" alt="img"></p><p>注意，Thread1的 e 指向了key(3)，而next指向了key(7)，其在线程二rehash后，指向了线程二重组后的链表。</p><p>线程一被调度回来执行，先是执行 newTalbe[i] = e， 然后是e = next，导致了e指向了key(7)，而下一次循环的next = e.next导致了next指向了key(3)。</p><p><img src="10.jpg" alt="img"></p><p>e.next = newTable[i] 导致 key(3).next 指向了 key(7)。注意：此时的key(7).next 已经指向了key(3)， 环形链表就这样出现了。</p><p><img src="11.jpg" alt="img"></p><p>于是，当我们用线程一调用map.get(11)时，悲剧就出现了——Infinite Loop。</p><h1 id="JDK1-8与JDK1-7的性能对比"><a href="#JDK1-8与JDK1-7的性能对比" class="headerlink" title="JDK1.8与JDK1.7的性能对比"></a><strong>JDK1.8与JDK1.7的性能对比</strong></h1><p>HashMap中，如果key经过hash算法得出的数组索引位置全部不相同，即Hash算法非常好，那样的话，getKey方法的时间复杂度就是O(1)，如果Hash算法技术的结果碰撞非常多，假如Hash算极其差，所有的Hash算法结果得出的索引位置一样，那样所有的键值对都集中到一个桶中，或者在一个链表中，或者在一个红黑树中，时间复杂度分别为O(n)和O(lgn)。 鉴于JDK1.8做了多方面的优化，总体性能优于JDK1.7，下面我们从两个方面用例子证明这一点。</p><h2 id="Hash较均匀的情况"><a href="#Hash较均匀的情况" class="headerlink" title="Hash较均匀的情况"></a>Hash较均匀的情况</h2><p>为了便于测试，我们先写一个类Key，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">class Key implements Comparable&lt;Key&gt; &#123;</span><br><span class="line"></span><br><span class="line">    private final int value;</span><br><span class="line"></span><br><span class="line">    Key(int value) &#123;</span><br><span class="line">        this.value = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int compareTo(Key o) &#123;</span><br><span class="line">        return Integer.compare(this.value, o.value);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public boolean equals(Object o) &#123;</span><br><span class="line">        if (this == o) return true;</span><br><span class="line">        if (o == null || getClass() != o.getClass())</span><br><span class="line">            return false;</span><br><span class="line">        Key key = (Key) o;</span><br><span class="line">        return value == key.value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int hashCode() &#123;</span><br><span class="line">        return value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个类复写了equals方法，并且提供了相当好的hashCode函数，任何一个值的hashCode都不会相同，因为直接使用value当做hashcode。为了避免频繁的GC，我将不变的Key实例缓存了起来，而不是一遍一遍的创建它们。代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public class Keys &#123;</span><br><span class="line"></span><br><span class="line">    public static final int MAX_KEY = 10_000_000;</span><br><span class="line">    private static final Key[] KEYS_CACHE = new Key[MAX_KEY];</span><br><span class="line"></span><br><span class="line">    static &#123;</span><br><span class="line">        for (int i = 0; i &lt; MAX_KEY; ++i) &#123;</span><br><span class="line">            KEYS_CACHE[i] = new Key(i);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public static Key of(int value) &#123;</span><br><span class="line">        return KEYS_CACHE[value];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>现在开始我们的试验，测试需要做的仅仅是，创建不同size的HashMap（1、10、100、……10000000），屏蔽了扩容的情况，代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">static void test(int mapSize) &#123;</span><br><span class="line"></span><br><span class="line">     HashMap&lt;Key, Integer&gt; map = new HashMap&lt;Key,Integer&gt;(mapSize);</span><br><span class="line">     for (int i = 0; i &lt; mapSize; ++i) &#123;</span><br><span class="line">         map.put(Keys.of(i), i);</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line">     long beginTime = System.nanoTime(); //获取纳秒</span><br><span class="line">     for (int i = 0; i &lt; mapSize; i++) &#123;</span><br><span class="line">         map.get(Keys.of(i));</span><br><span class="line">     &#125;</span><br><span class="line">     long endTime = System.nanoTime();</span><br><span class="line">     System.out.println(endTime - beginTime);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"> public static void main(String[] args) &#123;</span><br><span class="line">     for(int i=10;i&lt;= 1000 0000;i*= 10)&#123;</span><br><span class="line">         test(i);</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure><p>在测试中会查找不同的值，然后度量花费的时间，为了计算getKey的平均时间，我们遍历所有的get方法，计算总的时间，除以key的数量，计算一个平均值，主要用来比较，绝对值可能会受很多环境因素的影响。结果如下：</p><p><img src="12.jpg" alt="img"></p><p>通过观测测试结果可知，JDK1.8的性能要高于JDK1.7 15%以上，在某些size的区域上，甚至高于100%。由于Hash算法较均匀，JDK1.8引入的红黑树效果不明显，下面我们看看Hash不均匀的的情况。</p><h2 id="Hash极不均匀的情况"><a href="#Hash极不均匀的情况" class="headerlink" title="Hash极不均匀的情况"></a>Hash极不均匀的情况</h2><p>假设我们有一个非常差的Key，它们所有的实例都返回相同的hashCode值。这是使用HashMap最坏的情况。代码修改如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">class Key implements Comparable&lt;Key&gt; &#123;</span><br><span class="line"></span><br><span class="line">    //...</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int hashCode() &#123;</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>仍然执行main方法，得出的结果如下表所示：</p><p><img src="13.jpg" alt="img"></p><p>从表中结果中可知，随着size的变大，JDK1.7的花费时间是增长的趋势，而JDK1.8是明显的降低趋势，并且呈现对数增长稳定。当一个链表太长的时候，HashMap会动态的将它替换成一个红黑树，这话的话会将时间复杂度从<code>O(n)降为O(logn)</code>。hash算法均匀和不均匀所花费的时间明显也不相同，这两种情况的相对比较，可以说明一个好的hash算法的重要性。</p><p>测试环境：处理器为2.2 GHz Intel Core i7，内存为16 GB 1600 MHz DDR3，SSD硬盘，使用默认的JVM参数，运行在64位的OS X 10.10.1上。</p><h1 id="遍历Map对象"><a href="#遍历Map对象" class="headerlink" title="遍历Map对象"></a>遍历Map对象</h1><p>既然java中的所有map都实现了Map接口，以下方法适用于任何map实现（HashMap, TreeMap, LinkedHashMap, Hashtable, 等等）：</p><h2 id="方法一：-在for-each循环中使用entries来遍历"><a href="#方法一：-在for-each循环中使用entries来遍历" class="headerlink" title="方法一： 在for-each循环中使用entries来遍历"></a>方法一： 在for-each循环中使用entries来遍历</h2><p>这是最常见的并且在大多数情况下也是最可取的遍历方式。在键值都需要时使用。但是如果你遍历的是一个空的map对象，for-each循环将抛出NullPointerException，因此<strong>在遍历前你总是应该检查空引用</strong>。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line"><span class="keyword">for</span> (Map.Entry&lt;Integer, Integer&gt; entry : map.entrySet()) &#123;</span><br><span class="line">    System.out.println(<span class="string">"Key = "</span> + entry.getKey() + <span class="string">", Value = "</span> + entry.getValue());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="方法二：在for-each循环中遍历keys或values"><a href="#方法二：在for-each循环中遍历keys或values" class="headerlink" title="方法二：在for-each循环中遍历keys或values"></a>方法二：在for-each循环中遍历keys或values</h2><p>如果只需要map中的键或者值，你可以通过性能稍好的keySet()或values()来实现遍历，而不是用entrySet()。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line"><span class="comment">//遍历map中的键</span></span><br><span class="line"><span class="keyword">for</span> (Integer key : map.keySet()) &#123;</span><br><span class="line">    System.out.println(<span class="string">"Key = "</span> + key);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//遍历map中的值</span></span><br><span class="line"><span class="keyword">for</span> (Integer value : map.values()) &#123;</span><br><span class="line">    System.out.println(<span class="string">"Value = "</span> + value);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="方法三：使用Iterator遍历"><a href="#方法三：使用Iterator遍历" class="headerlink" title="方法三：使用Iterator遍历"></a>方法三：使用Iterator遍历</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Map&lt;Integer, Integer&gt; map = <span class="keyword">new</span> HashMap&lt;Integer, Integer&gt;();</span><br><span class="line"><span class="comment">// 使用泛型</span></span><br><span class="line">Iterator&lt;Map.Entry&lt;Integer, Integer&gt;&gt; entries = map.entrySet().iterator();</span><br><span class="line"><span class="keyword">while</span> (entries.hasNext()) &#123;</span><br><span class="line">    Map.Entry&lt;Integer, Integer&gt; entry = entries.next();</span><br><span class="line">    System.out.println(<span class="string">"Key = "</span> + entry.getKey() + <span class="string">", Value = "</span> + entry.getValue());</span><br><span class="line">&#125;<span class="number">1234567</span></span><br></pre></td></tr></table></figure><p>你也可以在<code>keySet</code>和<code>values</code>上应用同样的方法。<br>该种方式看起来冗余却有其优点所在。首先，在老版本java中这是惟一遍历map的方式。另一个好处是，你可以在<code>遍历时调用iterator.remove()来**删除** entries，另两个方法则不能。</code></p><h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>(1) 扩容是一个特别耗性能的操作，所以当程序员在使用HashMap的时候，估算map的大小，初始化的时候给一个大致的数值，避免map进行频繁的扩容。</p><p>(2) 负载因子是可以修改的，也<code>可以大于1</code>，但是建议不要轻易修改，除非情况非常特殊。</p><p>(3) HashMap是线程不安全的，不要在并发的环境中同时操作HashMap，建议使用ConcurrentHashMap。</p><p>(4) JDK1.8引入红黑树大程度优化了HashMap的性能。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文转载自：&lt;a href=&quot;https://zhuanlan.zhihu.com/p/21673805&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Java 8系列之重新认识HashMap&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;摘要&quot;&gt;&lt;a href=&quot;#摘要&quot; class=&quot;headerlink&quot; title=&quot;摘要&quot;&gt;&lt;/a&gt;&lt;strong&gt;摘要&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;HashMap是Java程序员使用频率最高的用于映射(键值对)处理的数据类型。随着JDK（Java Developmet Kit）版本的更新，JDK1.8对HashMap底层的实现进行了优化，例如引入红黑树的数据结构和扩容的优化等。本文结合JDK1.7和JDK1.8的区别，深入探讨HashMap的结构实现和功能原理。&lt;/p&gt;
    
    </summary>
    
      <category term="Java" scheme="http://changsk.top/categories/Java/"/>
    
    
      <category term="HashMap" scheme="http://changsk.top/tags/HashMap/"/>
    
      <category term="java" scheme="http://changsk.top/tags/java/"/>
    
  </entry>
  
</feed>
